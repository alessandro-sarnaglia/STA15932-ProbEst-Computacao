---
title: "Probabilidade e Estat√≠stica"
subtitle: "Vari√°veis Aleat√≥rias"
author: "Prof. Dr. Alessandro JQ Sarnaglia"
lang: "pt"
format:
  revealjs:
    width: 1280
    height: 720
    min-scale: 0.05
    fig-width: 5.5
    fig-height: 5.5
    theme: [custom.scss]
    css: [fonts.css, style.css]
    callout-icon: false
    toc: true
    toc-depth: 3
    toc-expand: 3
    number-sections: true
    number-depth: 3
    footer: "[Voltar üîô](../index.html)"
    menu:
      useTextContentForMissingTitles: false
editor: source
filters:
  - parse-latex
---

# Defini√ß√£o

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1:** Uma amostra de $n$ componentes √© submetida a testes para verificar os defeituosos e os n√£o defeituosos. Nesse experimento, podemos definir o espa√ßo amostral
$$
\Omega = \{\omega = (z_1, \ldots, z_n) : z_i \in \{S,F\} \},
$$
em que $S =$ "componente defeituoso" e $F =$ "componente n√£o defeituoso".

::: 

::: {.callout-caution}
## Observa√ß√£o

Como visto acima, o espa√ßo amostral pode assumir formas bem abstratas. No entanto, em muitos casos, √© de interesse associar um valor num√©rico a cada resultado de $\Omega$.
:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1 (cont.):** No exemplo anterior, suponha $n=3$, ent√£o
$$
\Omega = \{(FFF),(SFF),(FSF),(FFS),(SSF),(SFS),(FSS),(SSS)\}.
$$
Pode ser interesse registrar apenas o n√∫mero de componentes defeituosos e n√£o as falhas individuais (se $n$ grande por exemplo). Assim, ter√≠amos $X(\omega) =$ "n√∫mero de componentes defeituosos em $\omega$" e:

::: incremental

-   $X(FFF) = 0$;
-   $X(SFF) = X(FSF) = X(FFS) = 1$;
-   $X(SSF) = X(SFS) = X(FSS) = 2$; e
-   $X(SSS) = 3$.

:::

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

O tipo de situa√ß√£o acima nos leva a defini√ß√£o de [**vari√°veis aleat√≥rias**]{style="color:red;"}.
:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o - Vari√°veis Aleat√≥rias

Seja $\Omega$ espa√ßo amostral de um experimento aleat√≥rio. Uma **vari√°vel aleat√≥ria** (va) √© qualquer regra que associe um valor num√©rico real a cada resultado de $\Omega$.
:::

::: {.callout-caution}
## Observa√ß√µes

Da defini√ß√£o de va, podemos fazer os seguintes apontamentos:

1.    Vari√°veis aleat√≥rias normalmente s√£o denotadas por letras mai√∫sculas do final do alfabeto, tais como $X$, $Y$, $Z$, entre outras;
2.    Matematicamente, podemos definir $X$ como va se $X : \Omega \to \mathbb{R}$;
3.    Podemos tamb√©m escrever $X(\omega) = x$ para dizer que $x$ √© o valor atribu√≠do a $\omega$ pela va $X$.
:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=55%}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1 (cont.):**

<figure style="width:90%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_variavel_aleatoria0.png">
</figure>

:::

:::

::: {.column #vcenter width=45%}

:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=55%}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1 (cont.):**

<figure style="width:90%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_variavel_aleatoria1.png">
</figure>

:::

:::

::: {.column #vcenter width=45%}

:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=55%}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1 (cont.):**

<figure style="width:90%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_variavel_aleatoria2.png">
</figure>

:::

:::

::: {.column #vcenter width=45%}

:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=55%}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1 (cont.):**

<figure style="width:90%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_variavel_aleatoria3.png">
</figure>

:::

:::

::: {.column #vcenter width=45%}

:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=55%}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1 (cont.):**

<figure style="width:90%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_variavel_aleatoria4.png">
</figure>

:::

:::

::: {.column #vcenter width=45%}

:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=55%}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1 (cont.):**

<figure style="width:90%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_variavel_aleatoria5.png">
</figure>

:::

:::

::: {.column #vcenter width=45%}
::: {.callout-caution}
## Observa√ß√£o

Os valores de $\text{Im}(X)$ induzem uma parti√ß√£o de $\Omega$. No exemplo, vimos:

-   $[X=0] = \{(FFF)\}$;
-   $[X=1] = \{(FFS), (FSF), (SFF)\}$;
-   $[X=2] = \{(FSS), (SFS), (SSF)\}$; e
-   $[X=3] = \{(SSS)\}$.

:::
:::

:::



## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

A qualquer va $X$, podemos associar um contradom√≠nio (normalmente o conjunto $\mathbb{R}$) e uma [**imagem**]{style="color:red;"}, que denotaremos por $\text{Im}(X)$.

:::

::: {.callout-note}
## Defini√ß√£o

O conjunto de todos poss√≠veis valores que uma va $X$ pode assumir √© denominado **imagem** de $X$ e √© denotado por $\text{Im}(X)$.

:::

::: {.callout-caution}
## Observa√ß√£o

No exemplo anterior, temos que $\text{Im}(X) = \{0,1,2,3\}$.
:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Similarmente a estat√≠stica descritiva, podemos classificar as va's de acordo com o seu conjunto imagem.

:::

::: {.callout-note}
## Defini√ß√£o

Dada uma va $X$, dizemos que:

-   $X$ √© va **discreta** (vad) se $\text{Im}(X)$ for conjunto finito ou infinito enumer√°vel;
-   $X$ √© va **cont√≠nua** (vac) se $\text{Im}(X)$ for conjunto n√£o enumer√°vel.

:::

::: {.callout-caution}
## Observa√ß√£o

Agora, fica claro que a va $X$ do exemplo anterior se trata de uma **vad**.

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 2:** Uma linha de produ√ß√£o √© observada at√© a produ√ß√£o da primeira pe√ßa defeituosa. Seja $S =$ "Pe√ßa defeituosa" e $F =$ "Pe√ßa normal". Ent√£o temos que
$$
\Omega = \{(S), (FS), (FFS), (FFFS), \ldots\}.
$$

::: columns

::: {.column #vcenter width=60%}

A este experimento, podemos associar a va $X =$ "N√∫mero de pe√ßas produzidas". Nesse caso, ter√≠amos
$$
\text{Im}(X) = \{1, 2, 3, \ldots\}.
$$

:::

::: {.column #vcenter width=40%}

<figure style="width:90%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_variavel_aleatoria_discreta.png">
</figure>

:::

:::

:::

::: {.callout-caution}
## Observa√ß√£o

Embora $\text{Im}(X)$ seja infinito, ele √© um conjunto enumer√°vel, de modo que $X$ √© **vad**.

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

::: columns

::: {.column #vcenter width=60%}

**Exemplo 3:** Um ponto de uma regi√£o circular de raio unit√°rio √© sorteado. Nesse caso, podemos definir $\Omega = \{\omega = (z_1,z_2) : z_1^2 + z_2^2 \leq 1\}$.

[Nesse espa√ßo amostral, um evento $A$, √© uma [**regi√£o**]{style="color:red;"} de pontos, $A\subset\Omega$.]{style="visibility:hidden;"}

[A este experimento, poder√≠amos associar a vari√°vel aleat√≥ria $X =$ "Dist√¢ncia de $\omega$ √† origem". Isto √© $X(\omega) = (z_1^2 - z_2^2)^{1/2}$. Note que, nesse caso $\text{Im}(X) = [0,1]$.]{style="visibility:hidden;"}

:::

::: {.column #vcenter width=40%}

<figure style="width:95%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_variavel_aleatoria_continua0.svg">
</figure>

:::

:::

:::

::: {style="visibility:hidden"}

::: {.callout-caution}
## Observa√ß√£o

Como $\text{Im}(X)$ √© conjunto n√£o enumer√°vel, classificamos $X$ como uma **vac**.

:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

::: columns

::: {.column #vcenter width=60%}

**Exemplo 3:** Um ponto de uma regi√£o circular de raio unit√°rio √© sorteado. Nesse caso, podemos definir $\Omega = \{\omega = (z_1,z_2) : z_1^2 + z_2^2 \leq 1\}$.

Nesse espa√ßo amostral, um evento $A$, √© uma [**regi√£o**]{style="color:red;"} de pontos, $A\subset\Omega$.

[A este experimento, poder√≠amos associar a vari√°vel aleat√≥ria $X =$ "Dist√¢ncia de $\omega$ √† origem". Isto √© $X(\omega) = (z_1^2 - z_2^2)^{1/2}$. Note que, nesse caso $\text{Im}(X) = [0,1]$.]{style="visibility:hidden;"}

:::

::: {.column #vcenter width=40%}

<figure style="width:95%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_variavel_aleatoria_continua1.svg">
</figure>

:::

:::

:::

::: {style="visibility:hidden"}

::: {.callout-caution}
## Observa√ß√£o

Como $\text{Im}(X)$ √© conjunto n√£o enumer√°vel, classificamos $X$ como uma **vac**.

:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

::: columns

::: {.column #vcenter width=60%}

**Exemplo 3:** Um ponto de uma regi√£o circular de raio unit√°rio √© sorteado. Nesse caso, podemos definir $\Omega = \{\omega = (z_1,z_2) : z_1^2 + z_2^2 \leq 1\}$.

Nesse espa√ßo amostral, um evento $A$, √© uma [**regi√£o**]{style="color:red;"} de pontos, $A\subset\Omega$.

A este experimento, poder√≠amos associar a vari√°vel aleat√≥ria $X =$ "Dist√¢ncia de $\omega$ √† origem". Isto √© $X(\omega) = (z_1^2 + z_2^2)^{1/2}$. Note que, nesse caso $\text{Im}(X) = [0,1]$.

:::

::: {.column #vcenter width=40%}

<figure style="width:95%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_variavel_aleatoria_continua2.svg">
</figure>

:::

:::

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Como $\text{Im}(X)$ √© conjunto n√£o enumer√°vel, classificamos $X$ como uma **vac**.

:::

:::

## Fun√ß√£o de distribui√ß√£o acumulada

::: {.callout-caution}
## Observa√ß√£o

Um evento aleat√≥rio muito importante para modelagem de va's √© $[X \leq x]$. A probabilidade deste evento nos diz o quanto de probabilidade a va $X$ acumula at√© o valor $x$.

:::

::: {.callout-note}
## Defini√ß√£o

A **fun√ß√£o de distribui√ß√£o acumulada** (fda) √© definida por $F_X(x) = P(X \leq x)$
:::

::: {.callout-caution}
## Observa√ß√£o

Ao se partir de uma medida de probabilidade definida em $\Omega$, para o calcular $F_X(x)$, devemos encontrar a probabilidade (em $\Omega$) do evento $A_x = \{\omega \in \Omega: X(\omega) \leq x\}$. Isto √©, $F_X(x) = P(X \leq x) = P(A_x)$.

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 1 (cont.) {.unnumbered .unlisted}

Se supomos que $\Omega$ √© equiprov√°vel. Teremos que

$$
F_X(x) = \begin{cases}
0, & x < 0;\\
P(X=0) = \frac{1}{8}, & 0 \leq x < 1;\\
P(X=0) + P(X=1) = \frac{1}{8} + \frac{3}{8} = \frac{4}{8}, & 1 \leq x < 2;\\
P(X=0) + P(X=1) + P(X=2) = \frac{1}{8} + \frac{3}{8} + \frac{3}{8} = \frac{7}{8}, & 2 \leq x < 3;\\
P(X=0) + P(X=1) + P(X=2) + P(X=3) = \frac{1}{8} + \frac{3}{8} + \frac{3}{8} + \frac{1}{8} = 1, & x \geq 3;\\
\end{cases}
$$

## {.unnumbered .unlisted}

### Exemplo 1 (cont.) {.unnumbered .unlisted}

<figure style="width:50%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_fda0.png">
</figure>


## {.unnumbered .unlisted}

### Exemplo 1 (cont.) {.unnumbered .unlisted}

<figure style="width:50%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_fda1.png">
</figure>

## {.unnumbered .unlisted}

### Exemplo 1 (cont.) {.unnumbered .unlisted}

<figure style="width:50%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_fda2.png">
</figure>

## {.unnumbered .unlisted}

### Exemplo 1 (cont.) {.unnumbered .unlisted}

<figure style="width:50%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_fda3.png">
</figure>

## {.unnumbered .unlisted}

### Exemplo 1 (cont.) {.unnumbered .unlisted}

<figure style="width:50%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_fda4.png">
</figure>


## {.unnumbered .unlisted}

### Exemplo 1 (cont.) {.unnumbered .unlisted}

<figure style="width:50%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_fda5.png">
</figure>

::: {.callout-caution}
## Observa√ß√£o

No caso discreto, os tamanhos dos saltos de $F_X(x)$ nos d√° os valores de $P(X=x)$.
:::

## 1.1 Fun√ß√£o de distribui√ß√£o acumulada {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Se $X$ √© vad, a fun√ß√£o $p_X(x) = P(X=x)$, $x \in \text{Im}(X)$, √© chamada [**fun√ß√£o massa de probabilidade**]{style="color:red;"} (fmp).
:::

::: fragment

::: {.callout-warning}
## Propriedades

A fmp $p_X(x)$ de um uma vad $X$ satisfaz:

::: incremental

1.    $p_X(x) \geq 0$;
2.    $\textstyle \sum_{x} p_X(x) = 1$.

:::

:::

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Assim, vemos que, para vari√°veis aleat√≥rias discretas, a fda $F_X(x)$ nos fornece a fmp $p_X(x)$ e vice-versa.
:::

:::

## 1.1 Fun√ß√£o de distribui√ß√£o acumulada {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

A fmp √© um modelo te√≥rico para as **frequ√™ncias relativas** vistas em estat√≠stica descritiva.
:::

::: fragment

<figure style="width:70%; margin-left:auto; margin-right:auto">
  <img src="figs/ilustracao_frequencia_fmp.png">
</figure>

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

Supondo que nenhum ponto de $\Omega$ √© privilegiado, podemos definir a medida de probabilidade de $A$ como
$$\textstyle P(A) = \frac{\text{√Årea}(A)}{\text{√Årea}(\Omega)} = \frac{\text{√Årea}(A)}{\pi}.$$
Nesse caso, as probabilidades de dois eventos de mesma √°rea ser√£o as mesmas (equiprobabilidade).  

::: columns

::: {.column #vcenter width=65%}

[Usando essa medida de probabilidade, para calcular a fda de $X$, precisamos encontrar a √°rea da regi√£o $[X \leq x]$. Veja na ilustra√ß√£o ao lado.]{style="visibility:hidden;"}

[Logo, a fda de $X$ √© dada por
$$
\textstyle F_X(x) = P(X \leq x) = \begin{cases}
0, & x < 0;\\
\frac{\text{√Årea}(X \leq x)}{\pi} = \frac{\pi x^2}{\pi} = x^2, & 0\leq x < 1;\\
1, & x \geq 1.
\end{cases}
$$
]{style="visibility:hidden;"}

:::

::: {.column #vcenter width=35%}

<figure style="width:60%; margin-left:auto; margin-right:auto;visibility:hidden;">
  <img src="figs/ilustracao_fda_vac0.png">
</figure>

:::

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

Supondo que nenhum ponto de $\Omega$ √© privilegiado, podemos definir a medida de probabilidade de $A$ como
$$\textstyle P(A) = \frac{\text{√Årea}(A)}{\text{√Årea}(\Omega)} = \frac{\text{√Årea}(A)}{\pi}.$$
Nesse caso, as probabilidades de dois eventos de mesma √°rea ser√£o as mesmas (equiprobabilidade).  

::: columns

::: {.column #vcenter width=65%}

Usando essa medida de probabilidade, para calcular a fda de $X$, precisamos encontrar a √°rea da regi√£o $[X \leq x]$. Veja na ilustra√ß√£o ao lado.

[Logo, a fda de $X$ √© dada por
$$
\textstyle F_X(x) = P(X \leq x) = \begin{cases}
0, & x < 0;\\
\frac{\text{√Årea}(X \leq x)}{\pi} = \frac{\pi x^2}{\pi} = x^2, & 0\leq x < 1;\\
1, & x \geq 1.
\end{cases}
$$
]{style="visibility:hidden;"}

:::

::: {.column #vcenter width=35%}

<figure style="width:60%; margin-left:auto; margin-right:auto">
  <img src="figs/ilustracao_fda_vac0.png">
</figure>

:::

:::



## {.unnumbered .unlisted .smaller}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

Supondo que nenhum ponto de $\Omega$ √© privilegiado, podemos definir a medida de probabilidade de $A$ como
$$\textstyle P(A) = \frac{\text{√Årea}(A)}{\text{√Årea}(\Omega)} = \frac{\text{√Årea}(A)}{\pi}.$$
Nesse caso, as probabilidades de dois eventos de mesma √°rea ser√£o as mesmas (equiprobabilidade).  

::: columns

::: {.column #vcenter width=65%}

Usando essa medida de probabilidade, para calcular a fda de $X$, precisamos encontrar a √°rea da regi√£o $[X \leq x]$. Veja na ilustra√ß√£o ao lado.

[Logo, a fda de $X$ √© dada por
$$
\textstyle F_X(x) = P(X \leq x) = \begin{cases}
0, & x < 0;\\
\frac{\text{√Årea}(X \leq x)}{\pi} = \frac{\pi x^2}{\pi} = x^2, & 0\leq x < 1;\\
1, & x \geq 1.
\end{cases}
$$
]{style="visibility:hidden;"}

:::

::: {.column #vcenter width=35%}

<figure style="width:60%; margin-left:auto; margin-right:auto">
  <img src="figs/ilustracao_fda_vac1.png">
</figure>

:::

:::


## {.unnumbered .unlisted .smaller}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

Supondo que nenhum ponto de $\Omega$ √© privilegiado, podemos definir a medida de probabilidade de $A$ como
$$\textstyle P(A) = \frac{\text{√Årea}(A)}{\text{√Årea}(\Omega)} = \frac{\text{√Årea}(A)}{\pi}.$$
Nesse caso, as probabilidades de dois eventos de mesma √°rea ser√£o as mesmas (equiprobabilidade).  

::: columns

::: {.column #vcenter width=65%}

Usando essa medida de probabilidade, para calcular a fda de $X$, precisamos encontrar a √°rea da regi√£o $[X \leq x]$. Veja na ilustra√ß√£o ao lado.

[Logo, a fda de $X$ √© dada por
$$
\textstyle F_X(x) = P(X \leq x) = \begin{cases}
0, & x < 0;\\
\frac{\text{√Årea}(X \leq x)}{\pi} = \frac{\pi x^2}{\pi} = x^2, & 0\leq x < 1;\\
1, & x \geq 1.
\end{cases}
$$
]{style="visibility:hidden;"}

:::

::: {.column #vcenter width=35%}

<figure style="width:60%; margin-left:auto; margin-right:auto">
  <img src="figs/ilustracao_fda_vac2.png">
</figure>

:::

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

Supondo que nenhum ponto de $\Omega$ √© privilegiado, podemos definir a medida de probabilidade de $A$ como
$$\textstyle P(A) = \frac{\text{√Årea}(A)}{\text{√Årea}(\Omega)} = \frac{\text{√Årea}(A)}{\pi}.$$
Nesse caso, as probabilidades de dois eventos de mesma √°rea ser√£o as mesmas (equiprobabilidade).  

::: columns

::: {.column #vcenter width=65%}

Usando essa medida de probabilidade, para calcular a fda de $X$, precisamos encontrar a √°rea da regi√£o $[X \leq x]$. Veja na ilustra√ß√£o ao lado.

[Logo, a fda de $X$ √© dada por
$$
\textstyle F_X(x) = P(X \leq x) = \begin{cases}
0, & x < 0;\\
\frac{\text{√Årea}(X \leq x)}{\pi} = \frac{\pi x^2}{\pi} = x^2, & 0\leq x < 1;\\
1, & x \geq 1.
\end{cases}
$$
]{style="visibility:hidden;"}

:::

::: {.column #vcenter width=35%}

<figure style="width:60%; margin-left:auto; margin-right:auto">
  <img src="figs/ilustracao_fda_vac3.png">
</figure>

:::

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

Supondo que nenhum ponto de $\Omega$ √© privilegiado, podemos definir a medida de probabilidade de $A$ como
$$\textstyle P(A) = \frac{\text{√Årea}(A)}{\text{√Årea}(\Omega)} = \frac{\text{√Årea}(A)}{\pi}.$$
Nesse caso, as probabilidades de dois eventos de mesma √°rea ser√£o as mesmas (equiprobabilidade).  

::: columns

::: {.column #vcenter width=65%}

Usando essa medida de probabilidade, para calcular a fda de $X$, precisamos encontrar a √°rea da regi√£o $[X \leq x]$. Veja na ilustra√ß√£o ao lado.

Logo, a fda de $X$ √© dada por
$$
\textstyle F_X(x) = P(X \leq x) = \begin{cases}
0, & x < 0;\\
\frac{\text{√Årea}(X \leq x)}{\pi} = \frac{\pi x^2}{\pi} = x^2, & 0\leq x < 1;\\
1, & x \geq 1.
\end{cases}
$$

:::

::: {.column #vcenter width=35%}

<figure style="width:60%; margin-left:auto; margin-right:auto">
  <img src="figs/ilustracao_fda_vac3.png">
</figure>

:::

:::

## {.unnumbered .unlisted}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

<figure style="width:40%; margin-left:auto; margin-right:auto">
  <img src="figs/ilustracao_fda_vac_grafico0.png">
</figure>

## {.unnumbered .unlisted}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

<figure style="width:40%; margin-left:auto; margin-right:auto">
  <img src="figs/ilustracao_fda_vac_grafico1.png">
</figure>

## {.unnumbered .unlisted}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

<figure style="width:40%; margin-left:auto; margin-right:auto">
  <img src="figs/ilustracao_fda_vac_grafico2.png">
</figure>


::: {.callout-caution}
## Observa√ß√£o

Observe que n√£o h√° pontos de descontinuidade para a fda de uma va cont√≠nua. Portanto, a fda de uma vac n√£o fornece probabilidades diretamente.
:::

## 1.1 Fun√ß√£o de distribui√ß√£o acumulada {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Tomando a derivada da fda de uma vac, obtemos a chamada [**fun√ß√£o densidade de probabilidade**]{style="color:red;"}.
:::

::: fragment

::: {.callout-note}
## Defini√ß√£o

Se $X$ √© vac com fda $F_X(x)$, a sua **fun√ß√£o densidade de probabilidade** (fdp) √© definida por $f_X(x) = \frac{dF_X(x)}{dx}$.
:::

:::

::: fragment

::: {.callout-warning}
## Propriedades

A fdp $f_X(x)$ de uma vac $X$ satisfaz:

::: incremental

1.    $f_X(x) \geq 0$, $x\in \mathbb{R}$;
2.    $\int_{-\infty}^\infty f_X(x)dx = 1$.

:::

:::

:::

## 1.1 Fun√ß√£o de distribui√ß√£o acumulada {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

A fdp √© um modelo te√≥rico para as **densidades** de faixas vistas em estat√≠stica descritiva.
:::

::: fragment

<figure style="width:70%; margin-left:auto; margin-right:auto">
  <img src="figs/ilustracao_densidade_fdp.png">
</figure>

:::

## 1.1 Fun√ß√£o de distribui√ß√£o acumulada {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Note que o tratamento probabil√≠stico para obter a fda, bem como o seu comportamento, dependem do tipo de va em quest√£o.
:::

::: fragment

::: {.callout-warning}
## Propriedades

Seja $F_X(x)$ fda de uma va $X$, ent√£o

::: incremental

1.    $\lim_{x\to-\infty} F_X(x) = 0$ e $\lim_{x\to\infty} F_X(x) = 1$;
2.    $x < x' \Rightarrow F_X(x) \leq F_X(x')$, isto √©, $F_X(\cdot)$ √© n√£o decrescente; e
3.    se $X$ √© vad, $P(X=x) = F_X(x) - \lim_{x'\uparrow x} F_X(x')$, isto √©, a fmp $p_X(x)$ √© o tamanho do salto de $F_X(\cdot)$ em $x$.
4.    se $X$ √© vac, $f_X(x) = \frac{dF_X(x)}{dx}$, isto √©, a fdp $f_X(x)$ √© a derivada de $F_X(\cdot)$ em $x$.

:::

:::

:::

# Vari√°veis aleat√≥rias discretas

## 2 Vari√°veis aleat√≥rias discretas {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√µes

::: incremental

1. Vimos que, se o modelo probabil√≠stico √© concebido sobre um espa√ßo amostral $\Omega$ abstrato e $X : \Omega \to \mathbb{R}$, ent√£o a fmp pode ser obtida por
$$p_X(x) = P(X = x) = P(A_x),$$
em que $A_x = \{\omega \in \Omega : X(\omega) = x\}$. Isto √©, a fmp de $X$ √© **induzida** pela medida de probabilidade em $\Omega$;
2. Muito frequentemente, a constru√ß√£o de um modelo probabil√≠stico em $\Omega$ √© muito complicada, o que dificultaria a determina√ß√£o da fmp induzida.
3. Para contornar esse problema, levando em considera√ß√£o o comportamento da vad em estudo, podemos especificar diretamente uma fmp para a vad, desde que atenda as propriedades j√° vistas:
    + $p_X(x) \geq 0$;
    + $\sum_{x\in\text{Im}(X)} p_X(x) = 1$.

:::

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 4 {.unnumbered .unlisted}

Suponha que em um estoque existem seis lotes de um produto: tr√™s com $0$ itens defeituosos; dois com $1$ defeituoso; e um com $2$ defeituosos. Um lote ser√° sorteado entre os seis e ser√° enviado a um cliente. Seja $X=$ "n√∫mero de itens defeituosos no lote recebido pelo cliente". [Nesse caso, podemos especificar]{.fragment fragment-index=1}

::: {.fragment fragment-index=1}

::: columns

::: {.column #vcenter width=45%}

<div style="text-align: center;">
<table>
  <tr style="border-top:solid;">
    <td style="border-right:solid 1pt;">$x$</td>
    <td style="text-align: center;">$0$</td>
    <td style="text-align: center;">$1$</td>
    <td style="text-align: center;">$2$</td>
    <td style="text-align: center;border-left:solid 1pt;">Total</td>
  </tr>
  <tr style="border-top:solid 1pt;border-bottom:solid;">
    <td style="border-right:solid 1pt;">$p_X(x)$ </td>
    <td style="text-align: center;">$\frac{3}{6}$</td>
    <td style="text-align: center;">$\frac{2}{6}$</td>
    <td style="text-align: center;">$\frac{1}{6}$</td>
    <td style="text-align: center;border-left:solid 1pt;">$1$</td>
  </tr>
</table>
</div>

:::

::: {.column #vcenter width=10%}

<p style="text-align:center;">
ou ainda
</p>

:::

::: {.column #vcenter width=45%}

<div style="text-align: center;">
<table>
  <tr style="border-top:solid;">
    <td style="border-right:solid 1pt;">$x$</td>
    <td style="text-align: center;">$0$</td>
    <td style="text-align: center;">$1$</td>
    <td style="text-align: center;">$2$</td>
    <td style="text-align: center;border-left:solid 1pt;">Total</td>
  </tr>
  <tr style="border-top:solid 1pt;border-bottom:solid;">
    <td style="border-right:solid 1pt;">$p_X(x)$ </td>
    <td style="text-align: center;">$\frac{1}{2}$</td>
    <td style="text-align: center;">$\frac{1}{3}$</td>
    <td style="text-align: center;">$\frac{1}{6}$</td>
    <td style="text-align: center;border-left:solid 1pt;">$1$</td>
  </tr>
</table>
</div>

:::

:::

:::

::: {.fragment fragment-index=2}

Se n√£o sabemos a quantidade de lotes em estoque, a especifica√ß√£o acima n√£o √© pratic√°vel, pois n√£o sabemos o comportamento probabil√≠stico do experimento ($\Omega$ √© equiprov√°vel, mas desconhecido).

:::

::: {.fragment fragment-index=3}

Nesse caso, se ainda assumirmos que os lotes tem no m√°ximo 2 itens defeituosos, podemos especificar uma fmp arbitr√°ria para a vad $X$, como, por exemplo

<div style="text-align: center;">
<table>
  <tr style="border-top:solid;">
    <td style="border-right:solid 1pt;">$x$</td>
    <td style="text-align: center;">$0$</td>
    <td style="text-align: center;">$1$</td>
    <td style="text-align: center;">$2$</td>
    <td style="text-align: center;border-left:solid 1pt;">Total</td>
  </tr>
  <tr style="border-top:solid 1pt;border-bottom:solid;">
    <td style="border-right:solid 1pt;">$p_X(x)$ </td>
    <td style="text-align: center;">$0.7$</td>
    <td style="text-align: center;">$0.2$</td>
    <td style="text-align: center;">$0.1$</td>
    <td style="text-align: center;border-left:solid 1pt;">$1$</td>
  </tr>
</table>
</div>

:::

::: {.fragment fragment-index=4}

Note que $p_X(0), p_X(1), p_X(2) \geq 0$ e que $\sum_{x=0}^2 p_X(x) = 1$, de modo que $p_X(x)$ √© uma fmp v√°lida.

:::

## 2 Vari√°veis aleat√≥rias discretas {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

No exemplo anterior, especificamos de maneira arbitr√°ria uma fmp $p_X(x)$ para a vad $X$. No entanto, podemos ser mais flex√≠veis e propor uma [**fam√≠lia**]{style="color:red;"} de fmp's que dependa de [**par√¢metros**]{style="color:red;"}.

:::

::: {.fragment fragment-index=1 style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 4 (cont.):** 

Para flexibilizar o nosso modelo probabil√≠stico, podemos especificar a seguinte [**forma**]{style="color:red;"} para a fmp:

::: columns

::: {.column #vcenter width=30%}

<div style="text-align: center;">
<table>
  <tr style="border-top:solid;">
    <td style="border-right:solid 1pt;">$x$</td>
    <td style="text-align: center;">$0$</td>
    <td style="text-align: center;">$1$</td>
    <td style="text-align: center;">$2$</td>
    <td style="text-align: center;border-left:solid 1pt;">Total</td>
  </tr>
  <tr style="border-top:solid 1pt;border-bottom:solid;">
    <td style="border-right:solid 1pt;">$p_X(x)$ </td>
    <td style="text-align: center;">$\alpha$</td>
    <td style="text-align: center;">$\beta$</td>
    <td style="text-align: center;">$\gamma$</td>
    <td style="text-align: center;border-left:solid 1pt;">$1$</td>
  </tr>
</table>
</div>

:::

::: {.column #vcenter width=70%}

::: {.fragment fragment-index=2}

Para $p_X(x)$ ser uma fmp, precisamos impor as seguintes restri√ß√µes:

::: incremental
- $0 \leq \alpha \leq 1$;
- $0 \leq \beta \leq 1-\alpha$; e
- $\gamma = 1-\alpha-\beta$ (isto √©, $\gamma$ √© fixo).
:::

:::

:::

:::

::: fragment

Nesse caso, dizemos que $\alpha$ e $\beta$ s√£o **par√¢metros** (livres) da fam√≠lia de fmp's $p_X(x)$.

:::

::: 

## 2 Vari√°veis aleat√≥rias discretas {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Se a forma de $p_X(x)$ depende de um valor (ou vetor de valores) $\theta$, dizemos que $\theta$ √© um **par√¢metro** (ou vetor param√©trico) da fam√≠lia $p_X(x)$.
:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Nesse caso, podemos escrever $p_X(x; \theta)$ para enfatizar que se trata de uma fam√≠lia de fmp's e que sua forma s√≥ √© completamente conhecida se soubermos o valor do par√¢metro $\theta$ que indexa a fam√≠lia.

:::

:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 4 (cont.):** Nesse exemplo, podemos agrupar os par√¢metros no vetor $\theta = (\alpha, \beta)$. Note que, a fmp induzida pela medida equiprov√°vel em $\Omega$ e a fmp arbitrariamente especificada posteriormente s√£o membros particulares dessa fam√≠lia, em que $\theta = (\frac{1}{2}, \frac{1}{3})$ e $\theta = (0.7, 0.2)$, respectivamente.

:::

## 2 Vari√°veis aleat√≥rias discretas {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Como j√° visto anteriormente, a fda pode ser obtida acumulando as probabilidades da fmp.
:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

::: columns

::: {.column #vcenter width=50%}

**Exemplo 4 (cont.):** A fda para a fam√≠lia de fmp's neste caso √©
$$
F_X(x) = F_X(x; \theta) = \begin{cases}
0, & x < 0;\\
\alpha, & 0\leq x < 1;\\
\alpha + \beta, & 1\leq x < 2;\\
1, & x \geq 2;\\
\end{cases}
$$

:::

::: {.column #vcenter width=50%}

<figure style="width:90%; display:block; margin-left: auto; margin-right: auto;">
  <img src="figs/ilustracao_fda_exemplo4.png">
</figure>

:::

:::

:::

## 2 Vari√°veis aleat√≥rias discretas {.unnumbered .unlisted}

::: {.callout-tip}
## Exerc√≠cio

Considere a seguinte fun√ß√£o de $x$ que depende de um vetor de par√¢metros $\theta = (\theta_1, \theta_2, \theta_3, \theta_4)$:
$$
p_X(x;\theta) = \begin{cases}
\theta_1, & x=0;\\
\theta_2, & x=1;\\
\theta_3, & x=2;\\
\theta_4, & x=3.
\end{cases}
$$

Pede-se:

1. Quais restri√ß√µes necessitamos impor sobre $\theta = (\theta_1, \theta_2, \theta_3, \theta_4)$ para garantir que $p_X(x;\theta)$ seja de fato fam√≠lia de fmp's?
2. Qual a condi√ß√£o adicional sobre $\theta$ para que $p_X(x;\theta)$ seja sim√©trica? Qual √© o ponto de simetria?
3. Determine e esboce a fda associada a fam√≠lia $p_X(x;\theta)$.
:::


## Esperan√ßa e vari√¢ncia de vad's

::: {.callout-caution}
## Observa√ß√£o

Vimos que a fmp √© um modelo te√≥rico para as frequ√™ncias relativas vistas em estat√≠stica descritiva. Assim, fazendo uso da fmp, √© natural calcularmos valores te√≥ricos para a m√©dia e a vari√¢ncia de uma vad $X$.
:::

::: {.callout-note}
## Defini√ß√£o

Seja $X$ vad com imagem $\text{Im}(X)$ e fmp $p_X(x;\theta)$, sua **m√©dia**, tamb√©m chamada de **esperan√ßa** ou **valor esperado**, √© definida por 
$$\mu = \mu_X = E(X) = \sum_{x\in\text{Im}(X)} x\cdot p_X(x;\theta).$$
:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√µes

::: incremental

1. A f√≥rmula para o c√°lculo de $\mu$ √© muito similar √†quela vista em estat√≠stica descritiva, no entanto, agora a fmp $p_X(x;\theta)$ toma o lugar da frequ√™ncia relativa que teria sido efetivamente observada;
2. De maneira similar a estat√≠stica descritiva, $\mu$ √© calculada como uma m√©dia **ponderada** com pesos dados por $p_X(x;\theta)$;
3. Naturalmente, para fam√≠lias de fmp's, pelo fato de $p_X(x;\theta)$ ser indexada por $\theta$, a sua esperan√ßa tamb√©m ser√° fun√ß√£o de $\theta$.

:::

:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 4 (cont.):** Utilizando a f√≥rmula de esperan√ßa, obtemos
$$\mu_X = 0p_X(0;\theta) + 1p_X(1;\theta) + 2p_X(2;\theta) = \beta + 2(1-\alpha-\beta) = 2-2\alpha - \beta.$$

Se $\alpha = \frac{1-\beta}{2}$, vemos que a fmp √© sim√©trica em torno de $1$ e $\mu_X = 1$.

:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√µes

::: incremental

1. Quando est√° claro a que va $X$ a esperan√ßa se refere, usaremos $\mu$ em vez de $\mu_X$;
2. No Exemplo 4, se hipotetizarmos uma popula√ß√£o em que a vad $X$ com valores $0, 1$ e $2$ associados as frequ√™ncias relativas $\alpha$, $\beta$, $1-\alpha-\beta$, respectivamente, ent√£o $\mu = 2-2\alpha - \beta$ ser√° a m√©dia populacional. Por isso podemos nos referir a $\mu$ por m√©dia populacional ou te√≥rica;
3. No Exemplo 4, tomando $\theta = (\frac{1}{2}, \frac{1}{3})$, obtemos $\mu = 2-2\frac{1}{2} - \frac{1}{3} = \frac{2}{3} \approx 0.67$, que n√£o √© um valor poss√≠vel de $X$. A palavra esperado deve ser interpretada com cautela porque uma pessoa n√£o espera ver um valor de $X = 0.67$ quando um √∫nico estoque √© selecionado.

:::

:::


## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 5:** Seja $X$ o n√∫mero de entrevistas que um estudante faz para conseguir um emprego e suponha que a sua seja $p_X(x) = \frac{k}{x^2}$, $x = 1, 2, 3, \ldots$, e $p_X(x) = 0$ caso contr√°rio. A constante $k$ deve ser tal que $k^{-1} = \sum_{x=1}^\infty\frac{1}{x^2}$. √â poss√≠vel mostrar que $\sum_{x=1}^\infty\frac{1}{x^2} < +\infty$, portanto $p_X(x)$ √© de fato uma fmp.

::: {.fragment fragment-index=1}

Agora, o seu valor esperado √©
$$
\textstyle \mu = \sum_{x=1}^\infty x \cdot p_X(x) = \sum_{x=1}^\infty x\cdot\frac{k}{x^2} = k\sum_{x=1}^\infty \frac{1}{x}.
$$
O √∫ltimo termo √© a soma harm√¥nica, que diverge, isto √©, $\mu = +\infty$.

:::

:::

::: {.fragment fragment-index=2}

::: {.callout-caution}
## Observa√ß√£o

Dizemos que $p_X(x)$ tem **caudas longas** (as probabilidades da cauda decrescem muito lentamente). Ao selecionar uma amostra dessa vari√°vel, a m√©dia amostras tender√° a crescer indefinidamente com o tamanho da amostra.

:::

:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Frequentemente, temos interesse na esperan√ßa de $Y = h(X)$, em vez de $X$. Pela defini√ß√£o poder√≠amos obter $\mu_Y = \sum_y y \cdot p_Y(y)$, necessitando da fmp de $Y$. No entanto, existe uma maneira mais direta.
:::

::: {.fragment fragment-index=1 style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 6:** Seja $X$ vad e $Y = X^2$. [Por exemplo: ]{.fragment fragment-index=2}

::: columns

::: {.column #vcenter width=50%}

::: {.fragment fragment-index=2}
<div style="text-align: center;">
Se a fmp de $X$ for:
<table>
  <tr style="border-top:solid;">
    <td style="border-right:solid 1pt;">$x$</td>
    <td style="text-align: center;">$-2$</td>
    <td style="text-align: center;">$0$</td>
    <td style="text-align: center;">$2$</td>
    <td style="text-align: center;border-left:solid 1pt;">Total</td>
  </tr>
  <tr style="border-top:solid 1pt;border-bottom:solid;">
    <td style="border-right:solid 1pt;">$p_X(x)$ </td>
    <td style="text-align: center;">$p_{-2}$</td>
    <td style="text-align: center;">$p_{0}$</td>
    <td style="text-align: center;">$p_{2}$</td>
    <td style="text-align: center;border-left:solid 1pt;">$1$</td>
  </tr>
</table>
</div>

:::

:::

::: {.column #vcenter width=50%}

::: {.fragment fragment-index=3}

<div style="text-align: center;">
A fmp de $Y$ ser√°:
<table>
  <tr style="border-top:solid;">
    <td style="border-right:solid 1pt;">$x$</td>
    <td style="text-align: center;">$0$</td>
    <td style="text-align: center;">$4$</td>
    <td style="text-align: center;border-left:solid 1pt;">Total</td>
  </tr>
  <tr style="border-top:solid 1pt;border-bottom:solid;">
    <td style="border-right:solid 1pt;">$p_Y(y)$ </td>
    <td style="text-align: center;">$p_{0}$</td>
    <td style="text-align: center;">$p_{-2}+p_{2}$</td>
    <td style="text-align: center;border-left:solid 1pt;">$1$</td>
  </tr>
</table>
</div>

:::

:::

:::

[Logo,
$$\textstyle \mu_Y = \sum_y y\cdot p_Y(y) = 0p_0 + 4(p_{-2} + p_2) = (-2)^2p_{-2} + 0^2p_{0} + 2^2p_{2} = \sum_x h(x)\cdot p_X(x) = E[h(X)].$$
]{.fragment fragment-index=4}

:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Assim, se $X$ for vad com fmp $p_X(x)$ e $Y = h(X)$, ent√£o a esperan√ßa de $Y$ √©
$$\mu_Y = E[h(X)] = \sum_x h(x)\cdot p_X(x).$$
Isto √©, substitu√≠mos os $x$ pelos $h(x)$ no c√°lculo.

:::

::: fragment

::: {.callout-warning}
## Propriedade

Seja $X$ vad com esperan√ßa $\mu_X$ e $Y = aX+b$, com $a, b$ constantes, ent√£o
$$\mu_{Y} = \mu_{aX+b} = E(aX + b) = a E(X) + b = a\mu_X + b.$$
:::

:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

√â verdade que $E(aX + b) = a E(X) + b$. Mas, n√£o necessariamente vale que  $E[h(X)] = h[E(X)]$.

:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 6 (cont.):** Sejam $p_{-2} = p_2 = \frac{1}{4}$ e $p_0 = \frac{1}{2}$. [Ent√£o, temos
$$\textstyle E(X) = -2\frac{1}{4} + 0\frac{1}{2} + 2\frac{1}{4} = 0$$]{.fragment}
[e
$$\textstyle E(X^2) = (-2)^2\frac{1}{4} + 0^2\frac{1}{2} + 2^2\frac{1}{4} = 2.$$]{.fragment}

::: fragment

Assim, $E(X^2) = 2 \neq [E(X)]^2 = 0$.

:::

:::


## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Seja $X$ vad com fmp $p_X(x)$ e esperan√ßa $\mu$. A vari√¢ncia de $X$, denotada por $V(X)$, √© definida por
$$\textstyle V(X) = \sum_{x}(x - \mu)^2\cdot p_X(x) = E[(X - \mu)^2].$$
O desvio padr√£o (DP) de $X$ √© definido por $DP(X) = \sqrt{V(X)}.$ A vari√¢ncia pode ser denotada por $\sigma^2_X$, ou apenas $\sigma^2$, e o DP por $\sigma_X$, ou apenas $\sigma$.

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Note que a vari√¢ncia √© definida como a esperan√ßa de $h(X) = (X-\mu)^2$. Isto √©, quanto **esperamos** que a vari√°vel $X$ se desvie de sua esperan√ßa $\mu$.
:::

:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 6 (cont.):** Suponha agora que $p_2 = \frac{\alpha}{4}$, $p_{-2} = \frac{1-\alpha}{4}$ e $p_0 = \frac{1}{2}$, com $0 < \alpha < 1$. [Ent√£o,
$$\textstyle E(X) = \mu = -2\frac{1-\alpha}{4} + 2\frac{\alpha}{4} = \alpha - \frac{1}{2}.$$]{.fragment}
[Ent√£o, a vari√¢ncia √© dada por
$$\textstyle V(X) = \sigma^2 = \sum_{x}(x - \mu)^2\cdot p_X(x) = \sum_{x}[x-(\alpha - \frac{1}{2})]^2 p_X(x).$$]{.fragment}
[Depois de algumas √°lgebras obtemos $\sigma^2_X = 1-(\alpha-\frac{1}{2})^2$.]{.fragment}

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

O c√°lculo dos desvios quadr√°ticos $(x-\mu)^2$ para obter $\sigma^2$ pode ser tedioso. Felizmente, temos uma f√≥rmula que pode simplificar a sua determina√ß√£o.

:::

:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: fragment

::: {.callout-warning}
## Propriedades

::: incremental

1. Seja $X$ vad com fmp $p_X(x)$ e esperan√ßa $\mu$. Ent√£o
$$\begin{align*}
\sigma^2 &= \textstyle \sum_{x}(x - \mu)^2\cdot p_X(x) = \sum_{x}(x^2 - 2\mu x + \mu^2)\cdot p_X(x)\\
&= \textstyle \sum_{x}x^2p_X(x) - 2\mu \sum_{x}x p_X(x) + \mu^2 \sum_{x}p_X(x) = E(X^2) - 2\mu\mu + \mu^2 = E(X^2) - \mu^2.
\end{align*}$$
2. Seja $X$ vad com esperan√ßa $\mu_X$ e $Y = aX+b$, com $a, b$ constantes, ent√£o
$$\sigma_{Y}^2 = \sigma_{aX+b}^2 = a^2 \sigma_X^2.$$
:::

:::

:::

::: fragment

::: {.callout-caution}
## Observa√ß√µes

::: incremental
- A Propriedade 1 pode ser utilizada para facilmente se chegar a vari√¢ncia do exemplo anterior;
- A Propriedade 2 mostra que a vari√¢ncia s√≥ √© afetada por mudan√ßas em $a$ (escala), e n√£o em $b$ (loca√ß√£o).
:::

:::

:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 7:** Seja $X$ o n√∫mero obtido no arremesso de um dado honesto. Um jogo consiste de voc√™ pagar $Y = \frac{1}{X}$ e receber um pr√™mio de $\frac{1}{\mu_X}$ independente do resultado do dado. [Ser√° que o jogo √© vantajoso para o jogador?]{.fragment fragment-index=1}

[Note que $\mu_X = (1+2+\cdots+6)\frac{1}{6} = 3.5$, de onde vem que o pr√™mio √© sempre $\frac{1}{3.5} \approx 0.2857$.]{.fragment fragment-index=2}

[Por outro lado, temos
$$\textstyle \mu_Y = E(\frac{1}{Y}) = (1+\frac{1}{2}+\cdots+\frac{1}{6})\frac{1}{6} = \frac{1}{6}\frac{(60+30+20+15+12+10)}{60} = \frac{147}{360} = 0.4083.$$]{.fragment fragment-index=3}

[Assim, isso significa, em m√©dia, pagar $0.4083$ para jogar um jogo que oferece pr√™mio fixo de $0.2857$.]{.fragment fragment-index=4}

:::

::: fragment

::: {.callout-tip}
## Exerc√≠cios

Qual seria a vari√¢ncia do valor pago?
:::

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 8 {.unnumbered .unlisted}

Uma loja de computadores comprou 3 computadores de certo tipo a R\$ $1000$ cada. Eles ser√£o vendidos a R\$
$1500$ cada. Ap√≥s um per√≠odo, o fabricante aceita os n√£o vendidos por R\$ 400 cada. Seja $X$ o n√∫mero de computadores vendidos e suponha que $p_X(0) = 0.1$, $p_X(1) = 0.2$, $p_X(2)=0.3$ e $p_X(3) = 0.4$. [Note que
$$\mu_X = 0\cdot0.1 + 1\cdot0.2 + 2\cdot0.3 + 3\cdot0.4 = 2$$
e
$$\sigma^2_X = 0^2\cdot0.1 + 1^2\cdot0.2 + 2^2\cdot0.3 + 3^2\cdot0.4 - 2^2 = 0.2 + 4\cdot0.3 + 9\cdot0.4 - 4 = 5 - 4 = 1.$$]{.fragment}

[Por sua vez, o lucro no per√≠odo seria de
$$L = h(X) = 1500X - 3000 + 400(3-X) = 1100X - 1800.$$]{.fragment}

[Logo, o lucro esperado ser√° $\mu_L = 1100\mu_x-1800 = 1100\cdot 2 - 1800 = 400$ e a vari√¢ncia do lucro ser√° de $\sigma_L = 1100^2\sigma^2_X = 1100^2\cdot 1 = 1100^2$. O desvio-padr√£o do lucro √© de $\sigma_L = \sqrt{1100^2} = 1100$.]{.fragment}

## Modelos probabil√≠sticos discretos

# Vari√°veis aleat√≥rias cont√≠nuas

## Esperan√ßa e vari√¢ncia de vac's

## Modelos probabil√≠sticos cont√≠nuos

# Vetores Aleat√≥rios Bidimensionais

## Covari√¢ncia e Correla√ß√£o

# Fun√ß√µes de Vari√°veis Aleat√≥rias

# FIM {.unnumbered .unlisted}

# APAGAR DPS 1 {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

:::

::: {.callout-note}
## Defini√ß√£o

:::

::: {.callout-warning}
## Propriedades

:::

::: {.callout-tip}
## Exerc√≠cios

:::

::: {.callout-important}
## Problema

:::


::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo:** 

::: 

# APAGAR DPS 2 {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=45%}
1
:::

::: {.column #vcenter width=55%}
2

3

4
:::

:::



```{=latex}
\begin{align*}
\Omega &= \{(1,1), (1,2), \ldots, (4,4)\}\\
       &= \{(x,y) : x,y = 1,\ldots,4\}.
\end{align*}
```


# FIM {.unnumbered .unlisted}
