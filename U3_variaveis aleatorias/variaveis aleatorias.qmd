---
title: "Probabilidade e Estat√≠stica"
subtitle: "Vari√°veis Aleat√≥rias"
author: "Prof. Dr. Alessandro JQ Sarnaglia"
lang: "pt"
format:
  revealjs:
    width: 1280
    height: 720
    min-scale: 0.05
    fig-width: 5.5
    fig-height: 5.5
    theme: [custom.scss]
    css: [fonts.css, style.css]
    callout-icon: false
    toc: true
    toc-depth: 3
    toc-expand: 3
    number-sections: true
    number-depth: 3
    footer: "[Voltar üîô](../index.html)"
    menu:
      useTextContentForMissingTitles: false
editor: source
filters:
  - parse-latex
---

$$
\newcommand{\invisible}[1]{\color{white}{#1}}
$$


# Defini√ß√£o

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1:** Uma amostra de $n$ componentes √© submetida a testes para verificar os defeituosos e os n√£o defeituosos. Nesse experimento, podemos definir o espa√ßo amostral
$$
\Omega = \{\omega = (z_1, \ldots, z_n) : z_i \in \{S,F\} \},
$$
em que $S =$ "componente defeituoso" e $F =$ "componente n√£o defeituoso".

::: 

::: {.callout-caution}
## Observa√ß√£o

Como visto acima, o espa√ßo amostral pode assumir formas bem abstratas. No entanto, em muitos casos, √© de interesse associar um valor num√©rico a cada resultado de $\Omega$.
:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1 (cont.):** No exemplo anterior, suponha $n=3$, ent√£o
$$
\Omega = \{(FFF),(SFF),(FSF),(FFS),(SSF),(SFS),(FSS),(SSS)\}.
$$
Pode ser interesse registrar apenas o n√∫mero de componentes defeituosos e n√£o as falhas individuais (se $n$ grande por exemplo). Assim, ter√≠amos $X(\omega) =$ "n√∫mero de componentes defeituosos em $\omega$" e:

::: incremental

-   $X(FFF) = 0$;
-   $X(SFF) = X(FSF) = X(FFS) = 1$;
-   $X(SSF) = X(SFS) = X(FSS) = 2$; e
-   $X(SSS) = 3$.

:::

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

O tipo de situa√ß√£o acima nos leva a defini√ß√£o de [**vari√°veis aleat√≥rias**]{style="color:red;"}.
:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o - Vari√°veis Aleat√≥rias

Seja $\Omega$ espa√ßo amostral de um experimento aleat√≥rio. Uma **vari√°vel aleat√≥ria** (va) √© qualquer regra que associe um valor num√©rico real a cada resultado de $\Omega$.
:::

::: {.callout-caution}
## Observa√ß√µes

Da defini√ß√£o de va, podemos fazer os seguintes apontamentos:

1.    Vari√°veis aleat√≥rias normalmente s√£o denotadas por letras mai√∫sculas do final do alfabeto, tais como $X$, $Y$, $Z$, entre outras;
2.    Matematicamente, podemos definir $X$ como va se $X : \Omega \to \mathbb{R}$;
3.    Podemos tamb√©m escrever $X(\omega) = x$ para dizer que $x$ √© o valor atribu√≠do a $\omega$ pela va $X$.
:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=55%}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1 (cont.):**

<figure style="width:90%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_variavel_aleatoria0.png">
</figure>

:::

:::

::: {.column #vcenter width=45%}

:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=55%}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1 (cont.):**

<figure style="width:90%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_variavel_aleatoria1.png">
</figure>

:::

:::

::: {.column #vcenter width=45%}

:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=55%}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1 (cont.):**

<figure style="width:90%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_variavel_aleatoria2.png">
</figure>

:::

:::

::: {.column #vcenter width=45%}

:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=55%}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1 (cont.):**

<figure style="width:90%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_variavel_aleatoria3.png">
</figure>

:::

:::

::: {.column #vcenter width=45%}

:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=55%}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1 (cont.):**

<figure style="width:90%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_variavel_aleatoria4.png">
</figure>

:::

:::

::: {.column #vcenter width=45%}

:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=55%}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1 (cont.):**

<figure style="width:90%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_variavel_aleatoria5.png">
</figure>

:::

:::

::: {.column #vcenter width=45%}
::: {.callout-caution}
## Observa√ß√£o

Os valores de $\text{Im}(X)$ induzem uma parti√ß√£o de $\Omega$. No exemplo, vimos:

-   $[X=0] = \{(FFF)\}$;
-   $[X=1] = \{(FFS), (FSF), (SFF)\}$;
-   $[X=2] = \{(FSS), (SFS), (SSF)\}$; e
-   $[X=3] = \{(SSS)\}$.

:::
:::

:::



## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

A qualquer va $X$, podemos associar um contradom√≠nio (normalmente o conjunto $\mathbb{R}$) e uma [**imagem**]{style="color:red;"}, que denotaremos por $\text{Im}(X)$.

:::

::: {.callout-note}
## Defini√ß√£o

O conjunto de todos poss√≠veis valores que uma va $X$ pode assumir √© denominado **imagem** de $X$ e √© denotado por $\text{Im}(X)$.

:::

::: {.callout-caution}
## Observa√ß√£o

No exemplo anterior, temos que $\text{Im}(X) = \{0,1,2,3\}$.
:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Similarmente a estat√≠stica descritiva, podemos classificar as va's de acordo com o seu conjunto imagem.

:::

::: {.callout-note}
## Defini√ß√£o

Dada uma va $X$, dizemos que:

-   $X$ √© va **discreta** (vad) se $\text{Im}(X)$ for conjunto finito ou infinito enumer√°vel;
-   $X$ √© va **cont√≠nua** (vac) se $\text{Im}(X)$ for conjunto n√£o enumer√°vel.

:::

::: {.callout-caution}
## Observa√ß√£o

Agora, fica claro que a va $X$ do exemplo anterior se trata de uma **vad**.

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 2:** Uma linha de produ√ß√£o √© observada at√© a produ√ß√£o da primeira pe√ßa defeituosa. Seja $S =$ "Pe√ßa defeituosa" e $F =$ "Pe√ßa normal". Ent√£o temos que
$$
\Omega = \{(S), (FS), (FFS), (FFFS), \ldots\}.
$$

::: columns

::: {.column #vcenter width=60%}

A este experimento, podemos associar a va $X =$ "N√∫mero de pe√ßas produzidas". Nesse caso, ter√≠amos
$$
\text{Im}(X) = \{1, 2, 3, \ldots\}.
$$

:::

::: {.column #vcenter width=40%}

<figure style="width:90%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_variavel_aleatoria_discreta.png">
</figure>

:::

:::

:::

::: {.callout-caution}
## Observa√ß√£o

Embora $\text{Im}(X)$ seja infinito, ele √© um conjunto enumer√°vel, de modo que $X$ √© **vad**.

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

::: columns

::: {.column #vcenter width=60%}

**Exemplo 3:** Um ponto de uma regi√£o circular de raio unit√°rio √© sorteado. Nesse caso, podemos definir $\Omega = \{\omega = (z_1,z_2) : z_1^2 + z_2^2 \leq 1\}$.

[Nesse espa√ßo amostral, um evento $A$, √© uma [**regi√£o**]{style="color:red;"} de pontos, $A\subset\Omega$.]{style="visibility:hidden;"}

[A este experimento, poder√≠amos associar a vari√°vel aleat√≥ria $X =$ "Dist√¢ncia de $\omega$ √† origem". Isto √© $X(\omega) = (z_1^2 - z_2^2)^{1/2}$. Note que, nesse caso $\text{Im}(X) = [0,1]$.]{style="visibility:hidden;"}

:::

::: {.column #vcenter width=40%}

<figure style="width:95%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_variavel_aleatoria_continua0.svg">
</figure>

:::

:::

:::

::: {style="visibility:hidden"}

::: {.callout-caution}
## Observa√ß√£o

Como $\text{Im}(X)$ √© conjunto n√£o enumer√°vel, classificamos $X$ como uma **vac**.

:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

::: columns

::: {.column #vcenter width=60%}

**Exemplo 3:** Um ponto de uma regi√£o circular de raio unit√°rio √© sorteado. Nesse caso, podemos definir $\Omega = \{\omega = (z_1,z_2) : z_1^2 + z_2^2 \leq 1\}$.

Nesse espa√ßo amostral, um evento $A$, √© uma [**regi√£o**]{style="color:red;"} de pontos, $A\subset\Omega$.

[A este experimento, poder√≠amos associar a vari√°vel aleat√≥ria $X =$ "Dist√¢ncia de $\omega$ √† origem". Isto √© $X(\omega) = (z_1^2 - z_2^2)^{1/2}$. Note que, nesse caso $\text{Im}(X) = [0,1]$.]{style="visibility:hidden;"}

:::

::: {.column #vcenter width=40%}

<figure style="width:95%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_variavel_aleatoria_continua1.svg">
</figure>

:::

:::

:::

::: {style="visibility:hidden"}

::: {.callout-caution}
## Observa√ß√£o

Como $\text{Im}(X)$ √© conjunto n√£o enumer√°vel, classificamos $X$ como uma **vac**.

:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

::: columns

::: {.column #vcenter width=60%}

**Exemplo 3:** Um ponto de uma regi√£o circular de raio unit√°rio √© sorteado. Nesse caso, podemos definir $\Omega = \{\omega = (z_1,z_2) : z_1^2 + z_2^2 \leq 1\}$.

Nesse espa√ßo amostral, um evento $A$, √© uma [**regi√£o**]{style="color:red;"} de pontos, $A\subset\Omega$.

A este experimento, poder√≠amos associar a vari√°vel aleat√≥ria $X =$ "Dist√¢ncia de $\omega$ √† origem". Isto √© $X(\omega) = (z_1^2 + z_2^2)^{1/2}$. Note que, nesse caso $\text{Im}(X) = [0,1]$.

:::

::: {.column #vcenter width=40%}

<figure style="width:95%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_variavel_aleatoria_continua2.svg">
</figure>

:::

:::

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Como $\text{Im}(X)$ √© conjunto n√£o enumer√°vel, classificamos $X$ como uma **vac**.

:::

:::

## Fun√ß√£o de distribui√ß√£o acumulada

::: {.callout-caution}
## Observa√ß√£o

Um evento aleat√≥rio muito importante para modelagem de va's √© $[X \leq x]$. A probabilidade deste evento nos diz o quanto de probabilidade a va $X$ acumula at√© o valor $x$.

:::

::: {.callout-note}
## Defini√ß√£o

A **fun√ß√£o de distribui√ß√£o acumulada** (fda) √© definida por $F_X(x) = P(X \leq x)$
:::

::: {.callout-caution}
## Observa√ß√£o

Ao se partir de uma medida de probabilidade definida em $\Omega$, para o calcular $F_X(x)$, devemos encontrar a probabilidade (em $\Omega$) do evento $A_x = \{\omega \in \Omega: X(\omega) \leq x\}$. Isto √©, $F_X(x) = P(X \leq x) = P(A_x)$.

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 1 (cont.) {.unnumbered .unlisted}

Se supomos que $\Omega$ √© equiprov√°vel. Teremos que

$$
F_X(x) = \begin{cases}
0, & x < 0;\\
P(X=0) = \frac{1}{8}, & 0 \leq x < 1;\\
P(X=0) + P(X=1) = \frac{1}{8} + \frac{3}{8} = \frac{4}{8}, & 1 \leq x < 2;\\
P(X=0) + P(X=1) + P(X=2) = \frac{1}{8} + \frac{3}{8} + \frac{3}{8} = \frac{7}{8}, & 2 \leq x < 3;\\
P(X=0) + P(X=1) + P(X=2) + P(X=3) = \frac{1}{8} + \frac{3}{8} + \frac{3}{8} + \frac{1}{8} = 1, & x \geq 3;\\
\end{cases}
$$

## {.unnumbered .unlisted}

### Exemplo 1 (cont.) {.unnumbered .unlisted}

<figure style="width:50%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_fda0.png">
</figure>


## {.unnumbered .unlisted}

### Exemplo 1 (cont.) {.unnumbered .unlisted}

<figure style="width:50%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_fda1.png">
</figure>

## {.unnumbered .unlisted}

### Exemplo 1 (cont.) {.unnumbered .unlisted}

<figure style="width:50%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_fda2.png">
</figure>

## {.unnumbered .unlisted}

### Exemplo 1 (cont.) {.unnumbered .unlisted}

<figure style="width:50%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_fda3.png">
</figure>

## {.unnumbered .unlisted}

### Exemplo 1 (cont.) {.unnumbered .unlisted}

<figure style="width:50%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_fda4.png">
</figure>


## {.unnumbered .unlisted}

### Exemplo 1 (cont.) {.unnumbered .unlisted}

<figure style="width:50%; margin-left:auto; margin-right:auto;">
  <img src="figs/ilustracao_fda5.png">
</figure>

::: {.callout-caution}
## Observa√ß√£o

No caso discreto, os tamanhos dos saltos de $F_X(x)$ nos d√° os valores de $P(X=x)$.
:::

## 1.1 Fun√ß√£o de distribui√ß√£o acumulada {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Se $X$ √© vad, a fun√ß√£o $p_X(x) = P(X=x)$, $x \in \text{Im}(X)$, √© chamada [**fun√ß√£o massa de probabilidade**]{style="color:red;"} (fmp).
:::

::: fragment

::: {.callout-warning}
## Propriedades

A fmp $p_X(x)$ de um uma vad $X$ satisfaz:

::: incremental

1.    $p_X(x) \geq 0$;
2.    $\textstyle \sum_{x} p_X(x) = 1$.

:::

:::

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Assim, vemos que, para vari√°veis aleat√≥rias discretas, a fda $F_X(x)$ nos fornece a fmp $p_X(x)$ e vice-versa.
:::

:::

## 1.1 Fun√ß√£o de distribui√ß√£o acumulada {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

A fmp √© um modelo te√≥rico para as **frequ√™ncias relativas** vistas em estat√≠stica descritiva.
:::

::: fragment

<figure style="width:70%; margin-left:auto; margin-right:auto">
  <img src="figs/ilustracao_frequencia_fmp.png">
</figure>

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

Supondo que nenhum ponto de $\Omega$ √© privilegiado, podemos definir a medida de probabilidade de $A$ como
$$\textstyle P(A) = \frac{\text{√Årea}(A)}{\text{√Årea}(\Omega)} = \frac{\text{√Årea}(A)}{\pi}.$$
Nesse caso, as probabilidades de dois eventos de mesma √°rea ser√£o as mesmas (equiprobabilidade).  

::: columns

::: {.column #vcenter width=65%}

[Usando essa medida de probabilidade, para calcular a fda de $X$, precisamos encontrar a √°rea da regi√£o $[X \leq x]$. Veja na ilustra√ß√£o ao lado.]{style="visibility:hidden;"}

[Logo, a fda de $X$ √© dada por
$$
\textstyle F_X(x) = P(X \leq x) = \begin{cases}
0, & x < 0;\\
\frac{\text{√Årea}(X \leq x)}{\pi} = \frac{\pi x^2}{\pi} = x^2, & 0\leq x < 1;\\
1, & x \geq 1.
\end{cases}
$$
]{style="visibility:hidden;"}

:::

::: {.column #vcenter width=35%}

<figure style="width:60%; margin-left:auto; margin-right:auto;visibility:hidden;">
  <img src="figs/ilustracao_fda_vac0.png">
</figure>

:::

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

Supondo que nenhum ponto de $\Omega$ √© privilegiado, podemos definir a medida de probabilidade de $A$ como
$$\textstyle P(A) = \frac{\text{√Årea}(A)}{\text{√Årea}(\Omega)} = \frac{\text{√Årea}(A)}{\pi}.$$
Nesse caso, as probabilidades de dois eventos de mesma √°rea ser√£o as mesmas (equiprobabilidade).  

::: columns

::: {.column #vcenter width=65%}

Usando essa medida de probabilidade, para calcular a fda de $X$, precisamos encontrar a √°rea da regi√£o $[X \leq x]$. Veja na ilustra√ß√£o ao lado.

[Logo, a fda de $X$ √© dada por
$$
\textstyle F_X(x) = P(X \leq x) = \begin{cases}
0, & x < 0;\\
\frac{\text{√Årea}(X \leq x)}{\pi} = \frac{\pi x^2}{\pi} = x^2, & 0\leq x < 1;\\
1, & x \geq 1.
\end{cases}
$$
]{style="visibility:hidden;"}

:::

::: {.column #vcenter width=35%}

<figure style="width:60%; margin-left:auto; margin-right:auto">
  <img src="figs/ilustracao_fda_vac0.png">
</figure>

:::

:::



## {.unnumbered .unlisted .smaller}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

Supondo que nenhum ponto de $\Omega$ √© privilegiado, podemos definir a medida de probabilidade de $A$ como
$$\textstyle P(A) = \frac{\text{√Årea}(A)}{\text{√Årea}(\Omega)} = \frac{\text{√Årea}(A)}{\pi}.$$
Nesse caso, as probabilidades de dois eventos de mesma √°rea ser√£o as mesmas (equiprobabilidade).  

::: columns

::: {.column #vcenter width=65%}

Usando essa medida de probabilidade, para calcular a fda de $X$, precisamos encontrar a √°rea da regi√£o $[X \leq x]$. Veja na ilustra√ß√£o ao lado.

[Logo, a fda de $X$ √© dada por
$$
\textstyle F_X(x) = P(X \leq x) = \begin{cases}
0, & x < 0;\\
\frac{\text{√Årea}(X \leq x)}{\pi} = \frac{\pi x^2}{\pi} = x^2, & 0\leq x < 1;\\
1, & x \geq 1.
\end{cases}
$$
]{style="visibility:hidden;"}

:::

::: {.column #vcenter width=35%}

<figure style="width:60%; margin-left:auto; margin-right:auto">
  <img src="figs/ilustracao_fda_vac1.png">
</figure>

:::

:::


## {.unnumbered .unlisted .smaller}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

Supondo que nenhum ponto de $\Omega$ √© privilegiado, podemos definir a medida de probabilidade de $A$ como
$$\textstyle P(A) = \frac{\text{√Årea}(A)}{\text{√Årea}(\Omega)} = \frac{\text{√Årea}(A)}{\pi}.$$
Nesse caso, as probabilidades de dois eventos de mesma √°rea ser√£o as mesmas (equiprobabilidade).  

::: columns

::: {.column #vcenter width=65%}

Usando essa medida de probabilidade, para calcular a fda de $X$, precisamos encontrar a √°rea da regi√£o $[X \leq x]$. Veja na ilustra√ß√£o ao lado.

[Logo, a fda de $X$ √© dada por
$$
\textstyle F_X(x) = P(X \leq x) = \begin{cases}
0, & x < 0;\\
\frac{\text{√Årea}(X \leq x)}{\pi} = \frac{\pi x^2}{\pi} = x^2, & 0\leq x < 1;\\
1, & x \geq 1.
\end{cases}
$$
]{style="visibility:hidden;"}

:::

::: {.column #vcenter width=35%}

<figure style="width:60%; margin-left:auto; margin-right:auto">
  <img src="figs/ilustracao_fda_vac2.png">
</figure>

:::

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

Supondo que nenhum ponto de $\Omega$ √© privilegiado, podemos definir a medida de probabilidade de $A$ como
$$\textstyle P(A) = \frac{\text{√Årea}(A)}{\text{√Årea}(\Omega)} = \frac{\text{√Årea}(A)}{\pi}.$$
Nesse caso, as probabilidades de dois eventos de mesma √°rea ser√£o as mesmas (equiprobabilidade).  

::: columns

::: {.column #vcenter width=65%}

Usando essa medida de probabilidade, para calcular a fda de $X$, precisamos encontrar a √°rea da regi√£o $[X \leq x]$. Veja na ilustra√ß√£o ao lado.

[Logo, a fda de $X$ √© dada por
$$
\textstyle F_X(x) = P(X \leq x) = \begin{cases}
0, & x < 0;\\
\frac{\text{√Årea}(X \leq x)}{\pi} = \frac{\pi x^2}{\pi} = x^2, & 0\leq x < 1;\\
1, & x \geq 1.
\end{cases}
$$
]{style="visibility:hidden;"}

:::

::: {.column #vcenter width=35%}

<figure style="width:60%; margin-left:auto; margin-right:auto">
  <img src="figs/ilustracao_fda_vac3.png">
</figure>

:::

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

Supondo que nenhum ponto de $\Omega$ √© privilegiado, podemos definir a medida de probabilidade de $A$ como
$$\textstyle P(A) = \frac{\text{√Årea}(A)}{\text{√Årea}(\Omega)} = \frac{\text{√Årea}(A)}{\pi}.$$
Nesse caso, as probabilidades de dois eventos de mesma √°rea ser√£o as mesmas (equiprobabilidade).  

::: columns

::: {.column #vcenter width=65%}

Usando essa medida de probabilidade, para calcular a fda de $X$, precisamos encontrar a √°rea da regi√£o $[X \leq x]$. Veja na ilustra√ß√£o ao lado.

Logo, a fda de $X$ √© dada por
$$
\textstyle F_X(x) = P(X \leq x) = \begin{cases}
0, & x < 0;\\
\frac{\text{√Årea}(X \leq x)}{\pi} = \frac{\pi x^2}{\pi} = x^2, & 0\leq x < 1;\\
1, & x \geq 1.
\end{cases}
$$

:::

::: {.column #vcenter width=35%}

<figure style="width:60%; margin-left:auto; margin-right:auto">
  <img src="figs/ilustracao_fda_vac3.png">
</figure>

:::

:::

## {.unnumbered .unlisted}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

<figure style="width:40%; margin-left:auto; margin-right:auto">
  <img src="figs/ilustracao_fda_vac_grafico0.png">
</figure>

## {.unnumbered .unlisted}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

<figure style="width:40%; margin-left:auto; margin-right:auto">
  <img src="figs/ilustracao_fda_vac_grafico1.png">
</figure>

## {.unnumbered .unlisted}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

<figure style="width:40%; margin-left:auto; margin-right:auto">
  <img src="figs/ilustracao_fda_vac_grafico2.png">
</figure>


::: {.callout-caution}
## Observa√ß√£o

Observe que n√£o h√° pontos de descontinuidade para a fda de uma va cont√≠nua. Portanto, a fda de uma vac n√£o fornece probabilidades diretamente.
:::

## 1.1 Fun√ß√£o de distribui√ß√£o acumulada {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Tomando a derivada da fda de uma vac, obtemos a chamada [**fun√ß√£o densidade de probabilidade**]{style="color:red;"}.
:::

::: fragment

::: {.callout-note}
## Defini√ß√£o

Se $X$ √© vac com fda $F_X(x)$, a sua **fun√ß√£o densidade de probabilidade** (fdp) √© definida por $f_X(x) = \frac{dF_X(x)}{dx}$.
:::

:::

::: fragment

::: {.callout-warning}
## Propriedades

A fdp $f_X(x)$ de uma vac $X$ satisfaz:

::: incremental

1.    $f_X(x) \geq 0$, $x\in \mathbb{R}$;
2.    $\int_{-\infty}^\infty f_X(x)dx = 1$.

:::

:::

:::

## 1.1 Fun√ß√£o de distribui√ß√£o acumulada {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

A fdp √© um modelo te√≥rico para as **densidades** de faixas vistas em estat√≠stica descritiva.
:::

::: fragment

<figure style="width:70%; margin-left:auto; margin-right:auto">
  <img src="figs/ilustracao_densidade_fdp.png">
</figure>

:::

## 1.1 Fun√ß√£o de distribui√ß√£o acumulada {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Note que o tratamento probabil√≠stico para obter a fda, bem como o seu comportamento, dependem do tipo de va em quest√£o.
:::

::: fragment

::: {.callout-warning}
## Propriedades

Seja $F_X(x)$ fda de uma va $X$, ent√£o

::: incremental

1.    $\lim_{x\to-\infty} F_X(x) = 0$ e $\lim_{x\to\infty} F_X(x) = 1$;
2.    $x < x' \Rightarrow F_X(x) \leq F_X(x')$, isto √©, $F_X(\cdot)$ √© n√£o decrescente; e
3.    se $X$ √© vad, $P(X=x) = F_X(x) - \lim_{x'\uparrow x} F_X(x')$, isto √©, a fmp $p_X(x)$ √© o tamanho do salto de $F_X(\cdot)$ em $x$.
4.    se $X$ √© vac, $f_X(x) = \frac{dF_X(x)}{dx}$, isto √©, a fdp $f_X(x)$ √© a derivada de $F_X(\cdot)$ em $x$.

:::

:::

:::

# Vari√°veis aleat√≥rias discretas

## 2 Vari√°veis aleat√≥rias discretas {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√µes

::: incremental

1. Vimos que, se o modelo probabil√≠stico √© concebido sobre um espa√ßo amostral $\Omega$ abstrato e $X : \Omega \to \mathbb{R}$, ent√£o a fmp pode ser obtida por
$$p_X(x) = P(X = x) = P(A_x),$$
em que $A_x = \{\omega \in \Omega : X(\omega) = x\}$. Isto √©, a fmp de $X$ √© **induzida** pela medida de probabilidade em $\Omega$;
2. Muito frequentemente, a constru√ß√£o de um modelo probabil√≠stico em $\Omega$ √© muito complicada, o que dificultaria a determina√ß√£o da fmp induzida.
3. Para contornar esse problema, levando em considera√ß√£o o comportamento da vad em estudo, podemos especificar diretamente uma fmp para a vad, desde que atenda as propriedades j√° vistas:
    + $p_X(x) \geq 0$;
    + $\sum_{x\in\text{Im}(X)} p_X(x) = 1$.

:::

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 4 {.unnumbered .unlisted}

Suponha que em um estoque existem seis lotes de um produto: tr√™s com $0$ itens defeituosos; dois com $1$ defeituoso; e um com $2$ defeituosos. Um lote ser√° sorteado entre os seis e ser√° enviado a um cliente. Seja $X=$ "n√∫mero de itens defeituosos no lote recebido pelo cliente". [Nesse caso, podemos especificar]{.fragment fragment-index=1}

::: {.fragment fragment-index=1}

::: columns

::: {.column #vcenter width=45%}

<div style="text-align: center;">
<table>
  <tr style="border-top:solid;">
    <td style="border-right:solid 1pt;">$x$</td>
    <td style="text-align: center;">$0$</td>
    <td style="text-align: center;">$1$</td>
    <td style="text-align: center;">$2$</td>
    <td style="text-align: center;border-left:solid 1pt;">Total</td>
  </tr>
  <tr style="border-top:solid 1pt;border-bottom:solid;">
    <td style="border-right:solid 1pt;">$p_X(x)$ </td>
    <td style="text-align: center;">$\frac{3}{6}$</td>
    <td style="text-align: center;">$\frac{2}{6}$</td>
    <td style="text-align: center;">$\frac{1}{6}$</td>
    <td style="text-align: center;border-left:solid 1pt;">$1$</td>
  </tr>
</table>
</div>

:::

::: {.column #vcenter width=10%}

<p style="text-align:center;">
ou ainda
</p>

:::

::: {.column #vcenter width=45%}

<div style="text-align: center;">
<table>
  <tr style="border-top:solid;">
    <td style="border-right:solid 1pt;">$x$</td>
    <td style="text-align: center;">$0$</td>
    <td style="text-align: center;">$1$</td>
    <td style="text-align: center;">$2$</td>
    <td style="text-align: center;border-left:solid 1pt;">Total</td>
  </tr>
  <tr style="border-top:solid 1pt;border-bottom:solid;">
    <td style="border-right:solid 1pt;">$p_X(x)$ </td>
    <td style="text-align: center;">$\frac{1}{2}$</td>
    <td style="text-align: center;">$\frac{1}{3}$</td>
    <td style="text-align: center;">$\frac{1}{6}$</td>
    <td style="text-align: center;border-left:solid 1pt;">$1$</td>
  </tr>
</table>
</div>

:::

:::

:::

::: {.fragment fragment-index=2}

Se n√£o sabemos a quantidade de lotes em estoque, a especifica√ß√£o acima n√£o √© pratic√°vel, pois n√£o sabemos o comportamento probabil√≠stico do experimento ($\Omega$ √© equiprov√°vel, mas desconhecido).

:::

::: {.fragment fragment-index=3}

Nesse caso, se ainda assumirmos que os lotes tem no m√°ximo 2 itens defeituosos, podemos especificar uma fmp arbitr√°ria para a vad $X$, como, por exemplo

<div style="text-align: center;">
<table>
  <tr style="border-top:solid;">
    <td style="border-right:solid 1pt;">$x$</td>
    <td style="text-align: center;">$0$</td>
    <td style="text-align: center;">$1$</td>
    <td style="text-align: center;">$2$</td>
    <td style="text-align: center;border-left:solid 1pt;">Total</td>
  </tr>
  <tr style="border-top:solid 1pt;border-bottom:solid;">
    <td style="border-right:solid 1pt;">$p_X(x)$ </td>
    <td style="text-align: center;">$0.7$</td>
    <td style="text-align: center;">$0.2$</td>
    <td style="text-align: center;">$0.1$</td>
    <td style="text-align: center;border-left:solid 1pt;">$1$</td>
  </tr>
</table>
</div>

:::

::: {.fragment fragment-index=4}

Note que $p_X(0), p_X(1), p_X(2) \geq 0$ e que $\sum_{x=0}^2 p_X(x) = 1$, de modo que $p_X(x)$ √© uma fmp v√°lida.

:::

## 2 Vari√°veis aleat√≥rias discretas {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

No exemplo anterior, especificamos de maneira arbitr√°ria uma fmp $p_X(x)$ para a vad $X$. No entanto, podemos ser mais flex√≠veis e propor uma [**fam√≠lia**]{style="color:red;"} de fmp's que dependa de [**par√¢metros**]{style="color:red;"}.

:::

::: {.fragment fragment-index=1 style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 4 (cont.):** 

Para flexibilizar o nosso modelo probabil√≠stico, podemos especificar a seguinte [**forma**]{style="color:red;"} para a fmp:

::: columns

::: {.column #vcenter width=30%}

<div style="text-align: center;">
<table>
  <tr style="border-top:solid;">
    <td style="border-right:solid 1pt;">$x$</td>
    <td style="text-align: center;">$0$</td>
    <td style="text-align: center;">$1$</td>
    <td style="text-align: center;">$2$</td>
    <td style="text-align: center;border-left:solid 1pt;">Total</td>
  </tr>
  <tr style="border-top:solid 1pt;border-bottom:solid;">
    <td style="border-right:solid 1pt;">$p_X(x)$ </td>
    <td style="text-align: center;">$\alpha$</td>
    <td style="text-align: center;">$\beta$</td>
    <td style="text-align: center;">$\gamma$</td>
    <td style="text-align: center;border-left:solid 1pt;">$1$</td>
  </tr>
</table>
</div>

:::

::: {.column #vcenter width=70%}

::: {.fragment fragment-index=2}

Para $p_X(x)$ ser uma fmp, precisamos impor as seguintes restri√ß√µes:

::: incremental
- $0 \leq \alpha \leq 1$;
- $0 \leq \beta \leq 1-\alpha$; e
- $\gamma = 1-\alpha-\beta$ (isto √©, $\gamma$ √© fixo).
:::

:::

:::

:::

::: fragment

Nesse caso, dizemos que $\alpha$ e $\beta$ s√£o **par√¢metros** (livres) da fam√≠lia de fmp's $p_X(x)$.

:::

::: 

## 2 Vari√°veis aleat√≥rias discretas {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Se a forma de $p_X(x)$ depende de um valor (ou vetor de valores) $\theta$, dizemos que $\theta$ √© um **par√¢metro** (ou vetor param√©trico) da fam√≠lia $p_X(x)$.
:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Nesse caso, podemos escrever $p_X(x; \theta)$ para enfatizar que se trata de uma fam√≠lia de fmp's e que sua forma s√≥ √© completamente conhecida se soubermos o valor do par√¢metro $\theta$ que indexa a fam√≠lia.

:::

:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 4 (cont.):** Nesse exemplo, podemos agrupar os par√¢metros no vetor $\theta = (\alpha, \beta)$. Note que, a fmp induzida pela medida equiprov√°vel em $\Omega$ e a fmp arbitrariamente especificada posteriormente s√£o membros particulares dessa fam√≠lia, em que $\theta = (\frac{1}{2}, \frac{1}{3})$ e $\theta = (0.7, 0.2)$, respectivamente.

:::

## 2 Vari√°veis aleat√≥rias discretas {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Como j√° visto anteriormente, a fda pode ser obtida acumulando as probabilidades da fmp.
:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

::: columns

::: {.column #vcenter width=50%}

**Exemplo 4 (cont.):** A fda para a fam√≠lia de fmp's neste caso √©
$$
F_X(x) = F_X(x; \theta) = \begin{cases}
0, & x < 0;\\
\alpha, & 0\leq x < 1;\\
\alpha + \beta, & 1\leq x < 2;\\
1, & x \geq 2;\\
\end{cases}
$$

:::

::: {.column #vcenter width=50%}

<figure style="width:90%; display:block; margin-left: auto; margin-right: auto;">
  <img src="figs/ilustracao_fda_exemplo4.png">
</figure>

:::

:::

:::

## 2 Vari√°veis aleat√≥rias discretas {.unnumbered .unlisted}

::: {.callout-tip}
## Exerc√≠cio

Considere a seguinte fun√ß√£o de $x$ que depende de um vetor de par√¢metros $\theta = (\theta_1, \theta_2, \theta_3, \theta_4)$:
$$
p_X(x;\theta) = \begin{cases}
\theta_1, & x=0;\\
\theta_2, & x=1;\\
\theta_3, & x=2;\\
\theta_4, & x=3.
\end{cases}
$$

Pede-se:

1. Quais restri√ß√µes necessitamos impor sobre $\theta = (\theta_1, \theta_2, \theta_3, \theta_4)$ para garantir que $p_X(x;\theta)$ seja de fato fam√≠lia de fmp's?
2. Qual a condi√ß√£o adicional sobre $\theta$ para que $p_X(x;\theta)$ seja sim√©trica? Qual √© o ponto de simetria?
3. Determine e esboce a fda associada a fam√≠lia $p_X(x;\theta)$.
:::


## Esperan√ßa e vari√¢ncia de vad's

::: {.callout-caution}
## Observa√ß√£o

Vimos que a fmp √© um modelo te√≥rico para as frequ√™ncias relativas vistas em estat√≠stica descritiva. Assim, fazendo uso da fmp, √© natural calcularmos valores te√≥ricos para a m√©dia e a vari√¢ncia de uma vad $X$.
:::

::: {.callout-note}
## Defini√ß√£o

Seja $X$ vad com imagem $\text{Im}(X)$ e fmp $p_X(x;\theta)$, sua **m√©dia**, tamb√©m chamada de **esperan√ßa** ou **valor esperado**, √© definida por 
$$\mu = \mu_X = E(X) = \sum_{x\in\text{Im}(X)} x\cdot p_X(x;\theta).$$
:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√µes

::: incremental

1. A f√≥rmula para o c√°lculo de $\mu$ √© muito similar √†quela vista em estat√≠stica descritiva, no entanto, agora a fmp $p_X(x;\theta)$ toma o lugar da frequ√™ncia relativa que teria sido efetivamente observada;
2. De maneira similar a estat√≠stica descritiva, $\mu$ √© calculada como uma m√©dia **ponderada** com pesos dados por $p_X(x;\theta)$;
3. Naturalmente, para fam√≠lias de fmp's, pelo fato de $p_X(x;\theta)$ ser indexada por $\theta$, a sua esperan√ßa tamb√©m ser√° fun√ß√£o de $\theta$.

:::

:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 4 (cont.):** Utilizando a f√≥rmula de esperan√ßa, obtemos
$$\mu_X = 0p_X(0;\theta) + 1p_X(1;\theta) + 2p_X(2;\theta) = \beta + 2(1-\alpha-\beta) = 2-2\alpha - \beta.$$

Se $\alpha = \frac{1-\beta}{2}$, vemos que a fmp √© sim√©trica em torno de $1$ e $\mu_X = 1$.

:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√µes

::: incremental

1. Quando est√° claro a que va $X$ a esperan√ßa se refere, usaremos $\mu$ em vez de $\mu_X$;
2. No Exemplo 4, se hipotetizarmos uma popula√ß√£o em que a vad $X$ com valores $0, 1$ e $2$ associados as frequ√™ncias relativas $\alpha$, $\beta$, $1-\alpha-\beta$, respectivamente, ent√£o $\mu = 2-2\alpha - \beta$ ser√° a m√©dia populacional. Por isso podemos nos referir a $\mu$ por m√©dia populacional ou te√≥rica;
3. No Exemplo 4, tomando $\theta = (\frac{1}{2}, \frac{1}{3})$, obtemos $\mu = 2-2\frac{1}{2} - \frac{1}{3} = \frac{2}{3} \approx 0.67$, que n√£o √© um valor poss√≠vel de $X$. A palavra esperado deve ser interpretada com cautela porque uma pessoa n√£o espera ver um valor de $X = 0.67$ quando um √∫nico estoque √© selecionado.

:::

:::


## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 5:** Seja $X$ o n√∫mero de entrevistas que um estudante faz para conseguir um emprego e suponha que a sua seja $p_X(x) = \frac{k}{x^2}$, $x = 1, 2, 3, \ldots$, e $p_X(x) = 0$ caso contr√°rio. A constante $k$ deve ser tal que $k^{-1} = \sum_{x=1}^\infty\frac{1}{x^2}$. √â poss√≠vel mostrar que $\sum_{x=1}^\infty\frac{1}{x^2} < +\infty$, portanto $p_X(x)$ √© de fato uma fmp.

::: {.fragment fragment-index=1}

Agora, o seu valor esperado √©
$$
\textstyle \mu = \sum_{x=1}^\infty x \cdot p_X(x) = \sum_{x=1}^\infty x\cdot\frac{k}{x^2} = k\sum_{x=1}^\infty \frac{1}{x}.
$$
O √∫ltimo termo √© a soma harm√¥nica, que diverge, isto √©, $\mu = +\infty$.

:::

:::

::: {.fragment fragment-index=2}

::: {.callout-caution}
## Observa√ß√£o

Dizemos que $p_X(x)$ tem **caudas longas** (as probabilidades da cauda decrescem muito lentamente). Ao selecionar uma amostra dessa vari√°vel, a m√©dia amostras tender√° a crescer indefinidamente com o tamanho da amostra.

:::

:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Frequentemente, temos interesse na esperan√ßa de $Y = h(X)$, em vez de $X$. Pela defini√ß√£o poder√≠amos obter $\mu_Y = \sum_y y \cdot p_Y(y)$, necessitando da fmp de $Y$. No entanto, existe uma maneira mais direta.
:::

::: {.fragment fragment-index=1 style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 6:** Seja $X$ vad e $Y = X^2$. [Por exemplo: ]{.fragment fragment-index=2}

::: columns

::: {.column #vcenter width=50%}

::: {.fragment fragment-index=2}
<div style="text-align: center;">
Se a fmp de $X$ for:
<table>
  <tr style="border-top:solid;">
    <td style="border-right:solid 1pt;">$x$</td>
    <td style="text-align: center;">$-2$</td>
    <td style="text-align: center;">$0$</td>
    <td style="text-align: center;">$2$</td>
    <td style="text-align: center;border-left:solid 1pt;">Total</td>
  </tr>
  <tr style="border-top:solid 1pt;border-bottom:solid;">
    <td style="border-right:solid 1pt;">$p_X(x)$ </td>
    <td style="text-align: center;">$p_{-2}$</td>
    <td style="text-align: center;">$p_{0}$</td>
    <td style="text-align: center;">$p_{2}$</td>
    <td style="text-align: center;border-left:solid 1pt;">$1$</td>
  </tr>
</table>
</div>

:::

:::

::: {.column #vcenter width=50%}

::: {.fragment fragment-index=3}

<div style="text-align: center;">
A fmp de $Y$ ser√°:
<table>
  <tr style="border-top:solid;">
    <td style="border-right:solid 1pt;">$x$</td>
    <td style="text-align: center;">$0$</td>
    <td style="text-align: center;">$4$</td>
    <td style="text-align: center;border-left:solid 1pt;">Total</td>
  </tr>
  <tr style="border-top:solid 1pt;border-bottom:solid;">
    <td style="border-right:solid 1pt;">$p_Y(y)$ </td>
    <td style="text-align: center;">$p_{0}$</td>
    <td style="text-align: center;">$p_{-2}+p_{2}$</td>
    <td style="text-align: center;border-left:solid 1pt;">$1$</td>
  </tr>
</table>
</div>

:::

:::

:::

[Logo,
$$\textstyle \mu_Y = \sum_y y\cdot p_Y(y) = 0p_0 + 4(p_{-2} + p_2) = (-2)^2p_{-2} + 0^2p_{0} + 2^2p_{2} = \sum_x h(x)\cdot p_X(x) = E[h(X)].$$
]{.fragment fragment-index=4}

:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Assim, se $X$ for vad com fmp $p_X(x)$ e $Y = h(X)$, ent√£o a esperan√ßa de $Y$ √©
$$\mu_Y = E[h(X)] = \sum_x h(x)\cdot p_X(x).$$
Isto √©, substitu√≠mos os $x$ pelos $h(x)$ no c√°lculo.

:::

::: fragment

::: {.callout-warning}
## Propriedade

Seja $X$ vad com esperan√ßa $\mu_X$ e $Y = aX+b$, com $a, b$ constantes, ent√£o
$$\mu_{Y} = \mu_{aX+b} = E(aX + b) = a E(X) + b = a\mu_X + b.$$
:::

:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

√â verdade que $E(aX + b) = a E(X) + b$. Mas, n√£o necessariamente vale que  $E[h(X)] = h[E(X)]$.

:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 6 (cont.):** Sejam $p_{-2} = p_2 = \frac{1}{4}$ e $p_0 = \frac{1}{2}$. [Ent√£o, temos
$$\textstyle E(X) = -2\frac{1}{4} + 0\frac{1}{2} + 2\frac{1}{4} = 0$$]{.fragment}
[e
$$\textstyle E(X^2) = (-2)^2\frac{1}{4} + 0^2\frac{1}{2} + 2^2\frac{1}{4} = 2.$$]{.fragment}

::: fragment

Assim, $E(X^2) = 2 \neq [E(X)]^2 = 0$.

:::

:::


## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Seja $X$ vad com fmp $p_X(x)$ e esperan√ßa $\mu$. A vari√¢ncia de $X$, denotada por $V(X)$, √© definida por
$$\textstyle V(X) = \sum_{x}(x - \mu)^2\cdot p_X(x) = E[(X - \mu)^2].$$
O desvio padr√£o (DP) de $X$ √© definido por $DP(X) = \sqrt{V(X)}.$ A vari√¢ncia pode ser denotada por $\sigma^2_X$, ou apenas $\sigma^2$, e o DP por $\sigma_X$, ou apenas $\sigma$.

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Note que a vari√¢ncia √© definida como a esperan√ßa de $h(X) = (X-\mu)^2$. Isto √©, quanto **esperamos** que a vari√°vel $X$ se desvie de sua esperan√ßa $\mu$.
:::

:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 6 (cont.):** Suponha agora que $p_2 = \frac{\alpha}{2}$, $p_{-2} = \frac{1-\alpha}{2}$ e $p_0 = \frac{1}{2}$, com $0 < \alpha < 1$. [Ent√£o,
$$\textstyle E(X) = \mu = -2\frac{1-\alpha}{2} + 2\frac{\alpha}{2} = 2\alpha - 1.$$]{.fragment}
[Ent√£o, a vari√¢ncia √© dada por
$$\textstyle V(X) = \sigma^2 = \sum_{x}(x - \mu)^2\cdot p_X(x) = \sum_{x}[x-(2\alpha - 1)]^2 p_X(x).$$]{.fragment}
[Depois de algumas √°lgebras obtemos $\sigma^2_X = 1+4\alpha(1-\alpha)$.]{.fragment}

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

O c√°lculo dos desvios quadr√°ticos $(x-\mu)^2$ para obter $\sigma^2$ pode ser tedioso. Felizmente, temos uma f√≥rmula que pode simplificar a sua determina√ß√£o.

:::

:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: fragment

::: {.callout-warning}
## Propriedades

::: incremental

1. Seja $X$ vad com fmp $p_X(x)$ e esperan√ßa $\mu$. Ent√£o
$$\begin{align*}
\sigma^2 &= \textstyle \sum_{x}(x - \mu)^2\cdot p_X(x) = \sum_{x}(x^2 - 2\mu x + \mu^2)\cdot p_X(x)\\
&= \textstyle \sum_{x}x^2p_X(x) - 2\mu \sum_{x}x p_X(x) + \mu^2 \sum_{x}p_X(x) = E(X^2) - 2\mu\mu + \mu^2 = E(X^2) - \mu^2.
\end{align*}$$
2. Seja $X$ vad com esperan√ßa $\mu_X$ e $Y = aX+b$, com $a, b$ constantes, ent√£o
$$\sigma_{Y}^2 = \sigma_{aX+b}^2 = a^2 \sigma_X^2.$$
:::

:::

:::

::: fragment

::: {.callout-caution}
## Observa√ß√µes

::: incremental
- A Propriedade 1 pode ser utilizada para facilmente se chegar a vari√¢ncia do exemplo anterior;
- A Propriedade 2 mostra que a vari√¢ncia s√≥ √© afetada por mudan√ßas em $a$ (escala), e n√£o em $b$ (loca√ß√£o).
:::

:::

:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 7:** Seja $X$ o n√∫mero obtido no arremesso de um dado honesto. Um jogo consiste de voc√™ pagar $Y = \frac{1}{X}$ e receber um pr√™mio de $\frac{1}{\mu_X}$ independente do resultado do dado. [Ser√° que o jogo √© vantajoso para o jogador?]{.fragment fragment-index=1}

[Note que $\mu_X = (1+2+\cdots+6)\frac{1}{6} = 3.5$, de onde vem que o pr√™mio √© sempre $\frac{1}{3.5} \approx 0.2857$.]{.fragment fragment-index=2}

[Por outro lado, temos
$$\textstyle \mu_Y = E(Y) = E(\frac{1}{X}) = (1+\frac{1}{2}+\cdots+\frac{1}{6})\frac{1}{6} = \frac{1}{6}\frac{(60+30+20+15+12+10)}{60} = \frac{147}{360} = 0.4083.$$]{.fragment fragment-index=3}

[Assim, isso significa, em m√©dia, pagar $0.4083$ para jogar um jogo que oferece pr√™mio fixo de $0.2857$.]{.fragment fragment-index=4}

:::

::: fragment

::: {.callout-tip}
## Exerc√≠cios

Qual seria a vari√¢ncia do valor pago?
:::

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 8 {.unnumbered .unlisted}

Uma loja de computadores comprou 3 computadores de certo tipo a R\$ $1000$ cada. Eles ser√£o vendidos a R\$
$1500$ cada. Ap√≥s um per√≠odo, o fabricante aceita os n√£o vendidos por R\$ 400 cada. Seja $X$ o n√∫mero de computadores vendidos e suponha que $p_X(0) = 0.1$, $p_X(1) = 0.2$, $p_X(2)=0.3$ e $p_X(3) = 0.4$. [Note que
$$\mu_X = 0\cdot0.1 + 1\cdot0.2 + 2\cdot0.3 + 3\cdot0.4 = 2$$
e
$$\sigma^2_X = 0^2\cdot0.1 + 1^2\cdot0.2 + 2^2\cdot0.3 + 3^2\cdot0.4 - 2^2 = 0.2 + 4\cdot0.3 + 9\cdot0.4 - 4 = 5 - 4 = 1.$$]{.fragment}

[Por sua vez, o lucro no per√≠odo seria de
$$L = h(X) = 1500X - 3000 + 400(3-X) = 1100X - 1800.$$]{.fragment}

[Logo, o lucro esperado ser√° $\mu_L = 1100\mu_x-1800 = 1100\cdot 2 - 1800 = 400$ e a vari√¢ncia do lucro ser√° de $\sigma_L = 1100^2\sigma^2_X = 1100^2\cdot 1 = 1100^2$. O desvio-padr√£o do lucro √© de $\sigma_L = \sqrt{1100^2} = 1100$.]{.fragment}

## Modelos probabil√≠sticos discretos

::: {.callout-caution}
## Observa√ß√£o

Em muitas situa√ß√µes, lidamos com experimentos cujo resultado √© dicot√¥mico (possui apenas dois resultados) ou pode ser dicotomizado.
:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 9:** Um exerc√≠cio possui 5 alternativas de resposta. Um estudante decide responder o exerc√≠cio aleatoriamente. Duas poss√≠veis formas de escrever o espa√ßo amostral s√£o:

<table>
<tr class=fragment><td>$\Omega = \{a, b, c, d, e\}$</td> <td>(do ponto de vista de todas alternativas poss√≠veis)</td></tr>
<tr class=fragment style="border-bottom:none;"><td>$\Omega = \{s,f\}$</td> <td>(do ponto de vista de se a alternativa est√° correta ($s$) ou errada $f$)</td></tr>
</table>

[Note que o segundo espa√ßo amostral √© escrita de maneira dicotomizada.]{.fragment}
:::

## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Dizemos que um experimento aleat√≥rio √© um experimento de Bernoulli se seu espa√ßo amostral √© dicot√¥mico e pode ser escrito como $\Omega = \{s,f\}$, em que costumamos denominar $s =$ sucesso e $f =$ fracasso. Normalmente, denotamos a probabilidade de sucesso por $P(\{s\}) = p$, $0\leq p\leq 1$.
:::

::: fragment

::: {.callout-note}
## Defini√ß√£o

Num experimento de Bernoulli com $P(\{s\}) = p$, podemos definir a vad
$$X = \begin{cases}
1, & \text{ se } \ \ s;\\
0, & \text{ se } \ \ f.
\end{cases}$$
Nesse caso, dizemos que $X$ tem distribui√ß√£o **Bernoulli** com probabilidade de sucesso $p$ e usamos a nota√ß√£o $X \sim \text{Ber}(p)$.
:::

:::

## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedade

Se $X \sim \text{Ber}(p)$, ent√£o

<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$\mu = E(X) = p$</td> <td>e</td> <td>$\sigma^2 = V(X) = p(1-p).$</td>
  </tr>
</table>

:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 9 (cont.):** Defina a vad $X$ como $X = 1$, se a alternativa est√° correta, e $X = 0$, se a alternativa est√° errada. Ent√£o $X \sim \text{Ber}(p)$, com $p = \frac{1}{5}$.

:::

::: fragment

::: {.callout-caution}
## Observa√ß√µes

::: incremental

1. No Exemplo 9, definimos como sucesso o aluno acertar a quest√£o, mas esse n√£o precisa ser o caso. A classifica√ß√£o do que ser√° entendido como **sucesso** depender√° do problema em quest√£o.
2. O experimento de Bernoulli pode ser utilizado para constru√ß√£o de vad's mais complexas.

:::

:::

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 9 (cont.) {.unnumbered .unlisted}

Se o estudante responde aleatoriamente uma prova com 4 exerc√≠cios de 5 alternativas cada, tratam-se de 4 realiza√ß√µes **independentes** de um experimento de Bernoulli com $P(\{s\}) = p = \frac{1}{5}$. 

::: {.fragment fragment-index=1}

Defina $X =$ "n√∫mero de exerc√≠cios respondidos corretamente". Note que $\text{Im}(X) = \{0,1,2,3,4\}$. A fmp de $X$ √© dada por

<table>
  <tr>
    <td style="border-top:solid;border-bottom:solid;">$\omega$</td>
    <td style="text-align:center;border-top:solid;border-bottom:solid">$X(\omega)$</td>
    <td style="text-align:center;border-top:solid;border-bottom:solid">$P(\{\omega\})$</td>
    <td style="text-align:center;border-top:none;border-bottom:none;visibility:hidden;">$P(X = x)$</td>
  </tr>
  <tr>
    <td>[$(ffff)$]{.fragment fragment-index=2}</td>
    <td style="text-align:center;">[$0$]{.fragment fragment-index=2}</td>
    <td style="text-align:center;">[$p^0(1-p)^4$]{.fragment fragment-index=2}</td>
    <td style="text-align:center;visibility:hidden;">$p^0(1-p)^4$</td>
  </tr>
  <tr>
    <td>[$(sfff)$, $(fsff)$, $(ffsf)$, $(fffs)$]{.fragment fragment-index=3}</td>
    <td style="text-align:center;">[$1$]{.fragment fragment-index=3}</td>
    <td style="text-align:center;">[$p^1(1-p)^3$]{.fragment fragment-index=3}</td>
    <td style="text-align:center;visibility:hidden;">$4p^1(1-p)^3$</td>
  </tr>
  <tr>
    <td>[$(ssff)$, $(sfsf)$, $(sffs)$, $(fssf)$, $(fsfs)$, $(ffss)$]{.fragment fragment-index=4}</td>
    <td style="text-align:center;">[$2$]{.fragment fragment-index=4}</td>
    <td style="text-align:center;">[$p^2(1-p)^2$]{.fragment fragment-index=4}</td>
    <td style="text-align:center;visibility:hidden;">$6p^2(1-p)^2$</td>
  </tr>
  <tr>
    <td>[$(sssf)$, $(ssfs)$, $(sfss)$, $(fsss)$]{.fragment fragment-index=5}</td>
    <td style="text-align:center;">[$3$]{.fragment fragment-index=5}</td>
    <td style="text-align:center;">[$p^3(1-p)^1$]{.fragment fragment-index=5}</td>
    <td style="text-align:center;visibility:hidden;">$4p^3(1-p)^1$</td>
  </tr>
  <tr style="border-bottom:none">
    <td style="border-bottom:solid">[$(ssss)$]{.fragment fragment-index=6}</td>
    <td style="text-align:center;border-bottom:solid">[$4$]{.fragment fragment-index=6}</td>
    <td style="text-align:center;border-bottom:solid">[$p^4(1-p)^0$]{.fragment fragment-index=6}</td>
    <td style="text-align:center;border-bottom:none;visibility:hidden;">$p^4(1-p)^0$</td>
  </tr>
</table>

:::

[Nesse caso, dizemos que $X$ tem distribui√ß√£o **Binomial** com $4$ repeti√ß√µes e probabilidade de sucesso $\frac{1}{5}$.]{style="visibility:hidden"}

## {.unnumbered .unlisted .smaller}

### Exemplo 9 (cont.) {.unnumbered .unlisted}

Se o estudante responde aleatoriamente uma prova com 4 exerc√≠cios de 5 alternativas cada, tratam-se de 4 realiza√ß√µes **independentes** de um experimento de Bernoulli com $P(\{s\}) = p = \frac{1}{5}$. 

Defina $X =$ "n√∫mero de exerc√≠cios respondidos corretamente". Note que $\text{Im}(X) = \{0,1,2,3,4\}$. A fmp de $X$ √© dada por

<table>
  <tr>
    <td style="border-top:solid;border-bottom:solid;">$\omega$</td>
    <td style="text-align:center;border-top:solid;border-bottom:solid">$X(\omega)$</td>
    <td style="text-align:center;border-top:solid;border-bottom:solid">$P(\{\omega\})$</td>
    <td style="text-align:center;border-top:solid;border-bottom:solid;background-color:lightgray;">$P(X = x)$</td>
  </tr>
  <tr>
    <td>$(ffff)$</td>
    <td style="text-align:center;">$0$</td>
    <td style="text-align:center;">$p^0(1-p)^4$</td>
    <td style="text-align:center;background-color:lightgray;">$p^0(1-p)^4$</td>
  </tr>
  <tr>
    <td>$(sfff)$, $(fsff)$, $(ffsf)$, $(fffs)$</td>
    <td style="text-align:center;">$1$</td>
    <td style="text-align:center;">$p^1(1-p)^3$</td>
    <td style="text-align:center;background-color:lightgray;">$4p^1(1-p)^3$</td>
  </tr>
  <tr>
    <td>$(ssff)$, $(sfsf)$, $(sffs)$, $(fssf)$, $(fsfs)$, $(ffss)$</td>
    <td style="text-align:center;">$2$</td>
    <td style="text-align:center;">$p^2(1-p)^2$</td>
    <td style="text-align:center;background-color:lightgray;">$6p^2(1-p)^2$</td>
  </tr>
  <tr>
    <td>$(sssf)$, $(ssfs)$, $(sfss)$, $(fsss)$</td>
    <td style="text-align:center;">$3$</td>
    <td style="text-align:center;">$p^3(1-p)^1$</td>
    <td style="text-align:center;background-color:lightgray;">$4p^3(1-p)^1$</td>
  </tr>
  <tr style="border-bottom:none">
    <td style="border-bottom:solid">$(ssss)$</td>
    <td style="text-align:center;border-bottom:solid">$4$</td>
    <td style="text-align:center;border-bottom:solid">$p^4(1-p)^0$</td>
    <td style="text-align:center;border-bottom:solid;background-color:lightgray;">$p^4(1-p)^0$</td>
  </tr>
</table>

::: fragment

Nesse caso, dizemos que $X$ tem distribui√ß√£o **Binomial** com $4$ repeti√ß√µes e probabilidade de sucesso $\frac{1}{5}$.

:::

## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Considere $n$ repeti√ß√µes independentes de um experimento de Bernoulli com probabilidade de sucesso $p$ e seja $X =$ "n√∫mero de sucessos nas $n$ repeti√ß√µes". Dizemos que $X$ tem distribui√ß√£o **Binomial** com $n$ repeti√ß√µes e probabilidade de sucesso $p$, denotada por $X \sim \text{Bin}(n,p)$. A fmp de $X$ √©
$$p_X(x) = P(X = x) = {n \choose x} p^x (1-p)^{n-x}, \ \ x=0,1,2,\ldots,n.$$
:::

::: {.callout-caution}
## Observa√ß√£o

Note que, se $X_i \sim \text{Ber}(p)$ √© a va Bernoulli associada √† $i$-√©sima repeti√ß√£o, ent√£o podemos escrever $X = \sum_{i=1}^nX_i$. Isto √©, a va Binomial pode ser vista como soma de $n$ va's Bernoulli indendentes com a mesma probabilidade de sucesso.
:::

## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedade

Se $X \sim \text{Bin}(n,p)$, ent√£o

<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$\mu = E(X) = np$</td> <td>e</td> <td>$\sigma^2 = V(X) = np(1-p).$</td>
  </tr>
</table>

:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 9 (cont.):** Como a prova tem $n=4$ quest√µes, cada uma com $5$ alternativas ($p=\frac{1}{5}$), temos que $\mu = E(X) = np = 4 \cdot \frac{1}{5} = 0.8$ e $\sigma^2 = V(X) = np(1-p) = 4 \cdot \frac{1}{5} \cdot \frac{4}{5} = 0.64$. Logo, $\sigma = 0.8$. Portanto, em m√©dia, o estudante acerta menos do que 1 das 4 quest√µes.

::: fragment

A probabilidade de ele acertar mais da metade da prova √©
$$\textstyle P(X > 2) = P(X = 3) + P(X = 4) = {4 \choose 3} (\frac{1}{5})^3 (\frac{4}{5})^{1} + {4 \choose 4} (\frac{1}{5})^4 (\frac{4}{5})^{0} = 0.0256 + 0.0016 = 0.0272.$$

:::

:::

## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

```{r fig.width=10, fig.align='center'}
n <- 20; x <- 0:n; p <- 0.2
par(family = "Times New Roman")
plot(x, dbinom(x = x, size = n, prob = p), type='h', xlab='', ylab='', main='', lwd=3)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(p)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = bquote(paste("Bin(",italic(n)==.(n),', ',italic(p)==.(p),")")), side = 3, line = 1.3, cex = 2)
```


## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

```{r fig.width=10, fig.align='center'}
n <- 20; x <- 0:n; p <- 0.5
par(family = "Times New Roman")
plot(x, dbinom(x = x, size = n, prob = p), type='h', xlab='', ylab='', main='', lwd=3)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(p)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = bquote(paste("Bin(",italic(n)==.(n),', ',italic(p)==.(p),")")), side = 3, line = 1.3, cex = 2)
```

## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

```{r fig.width=10, fig.align='center'}
n <- 20; x <- 0:n; p <- 0.8
par(family = "Times New Roman")
plot(x, dbinom(x = x, size = n, prob = p), type='h', xlab='', ylab='', main='', lwd=3)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(p)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = bquote(paste("Bin(",italic(n)==.(n),', ',italic(p)==.(p),")")), side = 3, line = 1.3, cex = 2)
```


## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 10:** Um lote cont√©m 10 pe√ßas, sendo 3 defeituosas. Ser√£o sorteadas para inspe√ß√£o 4 pe√ßas do lote. Seja $X =$ "n√∫mero de pe√ßas defeituosas na amostra". Se a amostra resulta em no m√°ximo 1 pe√ßa defeituosa, o lote √© classificado como conforme.

Se a sele√ß√£o √© feita [**com reposi√ß√£o**]{style='color:red;'}, ent√£o estamos contando o n√∫mero de sucessos (pe√ßas defeituosas) em 4 repeti√ß√µes independentes de um experimento de Bernoulli. Assim, $X \sim \text{Bin}(n=4, p=\frac{3}{10})$. Logo, a probabilidade do lote ser conforme √©
$$\textstyle P(X \leq 1) = P(X = 0) + P(X = 1) = {4 \choose 0}(\frac{7}{10})^4 + {4 \choose 1}(\frac{3}{10})(\frac{7}{10})^3 = 0.2401 + 0.4116 = 0.6517.$$

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

No Exemplo 10, a distribui√ß√£o Binomial s√≥ foi apropriada para a vari√°vel $X$ pelo fato da sele√ß√£o ser **com reposi√ß√£o**. Como veremos a seguir, $X$ ter√° outra distribui√ß√£o quando a sele√ß√£o √© **sem reposi√ß√£o**.
:::

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 11 {.unnumbered .unlisted}

Uma urna cont√©m $M$ objetos do Tipo 1 e $N-M$ do Tipo 2. Desses, ser√£o selecionados $n$ [**sem reposi√ß√£o**]{style="color:red;"}. Seja $X =$ "objetos do Tipo 1 nos $n$ selecionados". [Vamos determinar $p_X(x) = P(X=x)$.]{.fragment fragment-index=1} [Abaixo s√£o apresentadas a quantidade de maneiras que observamos $x$ objetos do Tipo 1 e $n-x$ do Tipo 2:]{.fragment fragment-index=2}

::: {.fragment fragment-index=2}

<table>
  <tr style='border-top:solid;border-bottom:solid'>
    <td style='border-right:solid 1pt'>Objeto</td>
    <td style='border-right:solid 1pt;text-align:center' colspan=4>Tipo 1</td>
    <td style='text-align:center' colspan=4>Tipo 2</td>
  </tr>
  <tr>
    <td style='border-right:solid 1pt'>Retirada</td>
    <td style='border-right:dotted 1pt;text-align:center'>$1$</td>
    <td style='border-right:dotted 1pt;text-align:center'>$2$</td>
    <td style='border-right:dotted 1pt;text-align:center'>$\cdots$</td>
    <td style='border-right:solid 1pt;text-align:center'>$x$</td>
    <td style='border-right:dotted 1pt;text-align:center'>$x+1$</td>
    <td style='border-right:dotted 1pt;text-align:center'>$x+2$</td>
    <td style='border-right:dotted 1pt;text-align:center'>$\cdots$</td>
    <td style='text-align:center'>$n$</td>
  </tr>
  <tr style='border-top:solid 1pt;border-bottom:solid'>
    <td style='border-right:solid 1pt'>Maneiras</td>
    <td style='border-right:dotted 1pt;text-align:center'>$M$</td>
    <td style='border-right:dotted 1pt;text-align:center'>$M-1$</td>
    <td style='border-right:dotted 1pt;text-align:center'>$\cdots$</td>
    <td style='border-right:solid 1pt;text-align:center'>$M-x+1$</td>
    <td style='border-right:dotted 1pt;text-align:center'>$N-M$</td>
    <td style='border-right:dotted 1pt;text-align:center'>$N-M-1$</td>
    <td style='border-right:dotted 1pt;text-align:center'>$\cdots$</td>
    <td style='text-align:center'>$N-M-n+x+1$</td>
  </tr>
</table>

:::

[Pela regra do produto, obtemos $\frac{M!}{(M-x)!}\frac{(N-M)!}{(N-M-(n-x))!}$.]{.fragment fragment-index=3} [Como a ordem em que os objetos s√£o selecionados n√£o importa, precisamos dividir essa quantidade pelas $x!$ permuta√ß√µes dos objetos do Tipo 1 e pelas $(n-x)!$ do Tipo 2, o que resulta em ${M \choose x} {N-M \choose n-x}$ maneiras favor√°veis a $\{X = x\}$.]{.fragment fragment-index=4} [Sem nenhuma restri√ß√£o, obtemos $N(N-1)\cdots(N-n+1) = \frac{N!}{(N-n)!}$.]{.fragment fragment-index=5} [Descontando as $n!$ permuta√ß√µes, temos ${N \choose n}$ elementos em $\Omega$.]{.fragment fragment-index=6} [Assim,
$$p_X(x) = P(X = x) = \frac{ {M \choose x} {M-M \choose n-x} }{ {N \choose n} }, \ \ \max\{0, n-(N-M)\} \leq x \leq \min\{n,M\}.$$]{.fragment fragment-index=7}

## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Sejam $N$ itens, $M$ do Tipo 1 e $N-M$ do Tipo 2, dos quais $n$ s√£o selecionados **sem reposi√ß√£o**. Seja $X =$ "itens do Tipo 1 na amostra". Dizemos que $X$ tem distribui√ß√£o hipergeom√©trica com par√¢metros $N$ (total), $M$ (itens do Tipo 1) e $n$ (tamanho da amostra) e denotamos por $X \sim \text{Hip}(N,M,n)$. A fmp de $X$ √©
$$p_X(x) = \frac{ {M \choose x} {N-M \choose n-x} }{ {N \choose n} }, \ \ \max\{0, n-(N-M)\} \leq x \leq \min\{n,M\}.$$
:::

::: fragment

::: {.callout-warning}
## Propriedade

Se $X \sim \text{Hip}(N,M,n)$ e $p = \frac{M}{N}$ √© a propor√ß√£o de itens do Tipo 1, ent√£o

<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$\mu = E(X) = np$</td> <td>e</td> <td>$\sigma^2 = V(X) = np(1-p)(\frac{N-n}{N-1}).$</td>
  </tr>
</table>

:::

:::

## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 10 (cont.):** Se a sele√ß√£o fosse realizada [**sem reposi√ß√£o**]{style="color:red;"}, ent√£o $X \sim \text{Hip}(N=10, M=3, n=4)$, logo a probabilidade do lote ser conforme √©
$$P(X \leq 1) = P(X=0) + P(X=1) = \frac{ {3 \choose 0} {7 \choose 4} }{ {10 \choose 4} } + \frac{ {3 \choose 1} {7 \choose 3} }{ {10 \choose 4} } = 0.1667 + 0.5 = 0.6667.$$

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Note o efeito do tipo de sele√ß√£o em algumas caracter√≠sticas da vad $X$:

<table style="margin-bottom: 12pt !important;">
  <tr style='border-top:solid;border-bottom:solid'>
    <td style='border-right:solid 1pt;'>Sele√ß√£o</td>
    <td>$P(X \leq 1)$</td>
    <td>$E(X)$</td>
    <td>$V(X)$</td>
  </tr>
  <tr>
    <td style='border-right:solid 1pt;'>Com reposi√ß√£o</td>
    <td>$0.6517$</td>
    <td>$1.2\ \ [np]$</td>
    <td>$0.84\ \ [np(1-p)]$</td>
  </tr>
  <tr style='border-bottom:solid;'>
    <td style='border-right:solid 1pt;'>Sem reposi√ß√£o</td>
    <td>$0.6667$</td>
    <td>$1.2 \ \ [np]$</td>
    <td>$0.56 \ \ [np(1-p)(\frac{N-n}{N-1})]$</td>
  </tr>
</table>

:::

:::

## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}


```{r fig.width=6, fig.height=4.5, fig.align='center', fig.ncol=2}
M <- 3; N <- 10; n <- 4; x <- 0:n
y1 <- dbinom(x, n, M/N)
y2 <- dhyper(x, M, N-M, n)
MM <- max(y1,y2)
par(family = "Times New Roman")
plot(x, y1, type='h', xlab='', ylab='', main='', lwd=3, ylim=c(0,MM))
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(p)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = bquote(paste("Bin(",italic(n)==.(n),', ',italic(p)==.(M/N),")")), side = 3, line = 1.3, cex = 2)
plot(x, y2, type='h', xlab='', ylab='', main='', lwd=3, ylim=c(0,MM))
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(p)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = bquote(paste("Hip(",italic(N)==.(N),', ',italic(M)==.(M),', ',italic(n)==.(n),")")), side = 3, line = 1.3, cex = 2)
```

## {.unnumbered .unlisted .smaller}

### Exemplo 12 {.unnumbered .unlisted}

Um sistema de transa√ß√µes **independentes** possui 3 computadores que operam de modo redundante:

- se o 1¬∫ apresenta falha de transa√ß√£o (com probabilidade $p$), o 2¬∫ entra em opera√ß√£o;
- se o 2¬∫ apresenta falha de transa√ß√£o (com probabilidade $p$), o 3¬∫ entra em opera√ß√£o;
- se o 3¬∫ apresenta falha de transa√ß√£o (com probabilidade $p$), o sistema √© interrompido;

[Tratam-se de repeti√ß√µes independentes de um experimento de Bernoulli com $P(\{s\}) = p$ at√© obter o 3¬∫ sucesso.]{.fragment fragment-index=1} [Seja $X =$ "n√∫mero de transa√ß√µes realizadas". Note que $\text{Im}(X) = \{3,4,\ldots\}$.]{.fragment fragment-index=2} [Veja a seguinte tabela:]{.fragment fragment-index=3}

::: {.fragment fragment-index=3}

<table>
  <tr style="border-top:solid;border-bottom:solid">
    <td style="text-align:left;border-right:solid 1pt;">$\omega$</td>
    <td style="text-align:center;border-right:solid 1pt;">$x$</td>
    <td style="text-align:center;border-right:solid 1pt;">$P(\{\omega\})$</td>
    <td style="text-align:center;">$P(X=x)$</td>
  </tr>
  <tr>
    <td style="text-align:left;border-right:solid 1pt;">$(sss)$</td>
    <td style="text-align:center;border-right:solid 1pt;">$3$</td>
    <td style="text-align:center;border-right:solid 1pt;">$p^3$</td>
    <td style="text-align:center;">$p^3$</td>
  </tr>
  <tr>
    <td style="text-align:left;border-right:solid 1pt;">$(ssfs)$, $(sfss)$, $(fsss)$</td>
    <td style="text-align:center;border-right:solid 1pt;">$4$</td>
    <td style="text-align:center;border-right:solid 1pt;">$(1-p)p^3$</td>
    <td style="text-align:center;">$3(1-p)p^3$</td>
  </tr>
  <tr>
    <td style="text-align:left;border-right:solid 1pt;">$(ssffs)$, $(sfsfs)$, $(fssfs)$, $(sffss)$, $(fsfss)$, $(ffsss)$</td>
    <td style="text-align:center;border-right:solid 1pt;">$5$</td>
    <td style="text-align:center;border-right:solid 1pt;">$(1-p)^2p^3$</td>
    <td style="text-align:center;">$6(1-p)^2p^3$</td>
  </tr>
  <tr style="border-bottom:solid">
    <td style="text-align:left;border-right:solid 1pt;">$\vdots$</td>
    <td style="text-align:center;border-right:solid 1pt;">$\vdots$</td>
    <td style="text-align:center;border-right:solid 1pt;">$\vdots$</td>
    <td style="text-align:center;">$\vdots$</td>
  </tr>
</table>

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 12 (cont.) {.unnumbered .unlisted}

Assim, notando que a √∫ltima repeti√ß√£o tem que ser $s$, um exemplo de $\omega$ favor√°vel a $[X = x]$ √©
$$\omega = (\underbrace{ssff\ldots f}_{x-1}s),$$
cuja probabilidade √© $P(\{\omega\}) = (1-p)^{x-3}p^3$. [Os outros resultados favor√°veis a $[X=x]$ t√™m a mesma probabilidade e s√£o contados verificando de quantas formas podemos posicionar os dois sucessos dentre as primeiras $x-1$ repeti√ß√µes.]{.fragment fragment-index=1} [Para o 1¬∫ $s$, temos $x-1$ posi√ß√µes e, para o 2¬∫ $s$, temos $x-2$ posi√ß√µes.]{.fragment fragment-index=2}

[Pela regra da multiplica√ß√£o ter√≠amos $(x-1)(x-2) = \frac{(x-1)!}{(x-3)!}$ maneiras poss√≠veis.]{.fragment fragment-index=3} [Como a ordem que escolhemos a posi√ß√£o n√£o importa (escolher 1 e 2 √© o mesmo que 2 e 1, por exemplo), precisamos descontar as $2!$ permuta√ß√µes poss√≠veis entre as duas, o que resulta em $\frac{(x-1)!}{2!(x-3)!} = { x-1 \choose 2 }$ maneiras poss√≠veis.]{.fragment fragment-index=4} [Assim
$$P(X = x) = { x-1 \choose 2 } (1-p)^{x-3} p^x, \ \ \ x = 3, 4, 5, \ldots.$$]{.fragment fragment-index=5}

## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Um experimento de Bernoulli com $P(\{s\}) = p$ √© repetido **independentemente** at√© a ocorr√™ncia do $k$-√©simo sucesso. Seja $X =$ "n√∫mero de repeti√ß√µes realizadas". Dizemos que $X$ tem distribui√ß√£o Binomial Negativa com $k$ sucessos e probabilidade de sucesso $p$, denotada por $X \sim \text{BN}(k,p)$. A fmp de $X$ √©
$$p_X(x) = P(X = x) = { x-1 \choose k-1 } (1-p)^{x-k} p^k, \ \ \ x = k, k+1, k+2, \ldots.$$
:::

::: fragment

::: {.callout-warning}
## Propriedades

Se $X \sim \text{BN}(k,p)$, ent√£o

<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$\mu = E(X) = \frac{k}{p}$</td> <td>e</td> <td>$\sigma^2 = V(X) = k\frac{(1-p)}{p^2}.$</td>
  </tr>
</table>
:::

:::

## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√µes

::: incremental

1. No Exemplo 12, temos que $X \sim \text{BN}(k=3, p)$. Se $p = 0.01$, por exemplo, ter√≠amos $\mu = E(X) = \frac{3}{0.01} = 300$, $\sigma^2 = V(X) = 3\frac{0.99}{0.01^2} = 29700$ e $\sigma \approx 172.34$. Em m√©dia, s√£o realizadas $300$ transa√ß√µes at√© a terceira falha com DP de $172.34$. Al√©m disso, $P(X > \mu) = P(X > 300) \approx 0.4221$;
2. A distribui√ß√£o BN tamb√©m pode ser definida como a distribui√ß√£o do n√∫mero de fracassos (em vez de repeti√ß√µes) at√© o $k$-√©simo sucesso. Nesse caso, sua fmp √©
$$\textstyle p_X(x) = { x + k -1 \choose k-1 } (1-p)^{x} p^k, \ \ \ x = 0, 1, 2, \ldots,$$
e sua esperan√ßa e vari√¢ncia s√£o, respectivamente, $\mu = k\frac{(1-p)}{p}$ e $\sigma^2 = k\frac{(1-p)}{p^2}$;
3. Se $X \sim \text{BN}(k = 1, p)$, dizemos que $X$ tem distribui√ß√£o geom√©trica, cuja nota√ß√£o √© $X \sim \text{Geo}(p)$;
4. Se $X \sim \text{BN}(k, p)$, ent√£o $X = \sum_{j=1}^k X_j$, em que $X_1,\ldots,X_k \sim \text{Geo}(p)$ independentes.
5. Bin: repeti√ß√µes fixas e sucessos aleat√≥rios; BN: sucessos fixos e repeti√ß√µes aleat√≥rias.

:::

:::

# Vari√°veis aleat√≥rias cont√≠nuas

## 3 Vari√°veis aleat√≥rias cont√≠nuas {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Anteriormente, definimos uma vac $X$ como sendo aquelas cuja imagem $\text{Im}(X)$ √© n√£o enumer√°vel. De agora em diante, as vac's ser√£o restringidas √†quelas em que a fda √© [**absolutamente cont√≠nua**]{style="color:red"}.
:::

::: {.callout-note}
## Defini√ß√£o

Diremos que $X$ √© va **cont√≠nua** (vac) se sua imagem $\text{Im}(X)$ √© n√£o enumer√°vel e se sua fda $F_X(x) = P(X \leq x)$ √© **absolutamente cont√≠nua**. Neste caso, podemos escrever
$$F_X(x) = \int_{-\infty}^x f_X(t)dt,$$
em que $f_X(\cdot)$ √© denominada **fun√ß√£o densidade de probabilidade** (fdp).
:::

## 3 Vari√°veis aleat√≥rias cont√≠nuas {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedades
Seja $X$ vac com fda $F_X(\cdot)$ e fdp $f_X(\cdot)$, ent√£o:

::: incremental

1. sua fdp satisfaz:
    + $f_X(\cdot) \geq 0$;
    + $\int_{-\infty}^\infty f_X(x)dx$.
2. a probabilidade do intervalo $(a,b]$, $a<b$, √© dada por
$$\textstyle P(a < X \leq b) = F_X(b) - F_X(a) = \int_a^b f_X(x) dx;$$
3. a probabilidade de um ponto $x$ √© $P(X=x) = 0$;
4. valem as igualdades $P(a < X \leq b) = P(a \leq X \leq b) = P(a \leq X < b) = P(a < X < b)$, sendo que o mesmo n√£o √© v√°lido no caso discreto.

:::

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 13 {.unnumbered .unlisted}

Tempo de avan√ßo √© a diferen√ßa entre o instante em que um carro termina de passar por um ponto e o instante em que o pr√≥ximo carro come√ßa a passar por esse ponto. Seja $X =$ "tempo de avan√ßo para dois carros escolhidos ao acaso". O artigo "*The Statistical Properties of Freeway Traffic*" sugeriu a fdp
$$f_X(x) = 0.15e^{-0.15(x-0.5)} \mathbb{I}(x \geq 0.5) = \begin{cases}
0.15e^{-0.15(x-0.5)}, & x \geq 0.5;\\
0, & x < 0.5,
\end{cases}$$
em que $\mathbb{I}(A) = 1$, se a condi√ß√£o $A$ √© v√°lida, e $\mathbb{I}(A) = 0$, caso contr√°rio.

::: fragment

Note que $f_X(x) \geq 0$ e que $\int_{-\infty}^\infty f_X(x)dx = 1$. Vamos encontrar $P(X > 5)$. Note que
$$P(X > 5) = \int_{5}^\infty f_X(x) dx = \int_{5}^\infty 0.15e^{-0.15(x-0.5)} dx = \left[\left.-e^{-0.15(x-0.5)}\right|_5^\infty\right] = e^{-0.675} \approx 0.5092.$$

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 13 (cont.) {.unnumbered .unlisted}

Veja abaixo a representa√ß√£o da fdp e a da probabilidade $P(X > 5)$:

```{r fig.width=8, fig.height=4.5, fig.align='center'}
MM <- 25
x <- seq(-1,MM,0.01)
y <- as.numeric(x >= 0.5)*0.15*exp(-0.15*(x-0.5))
par(family = "Times New Roman", mar=c(5,4,1,2))
plot(x[x<0.5], y[x<0.5], type='n', xlab='', ylab='', main='', lwd=3,
     ylim=range(y)+c(-.1*diff(range(y)),.13*diff(range(y))),
     xlim=range(x)+c(-.02*diff(range(x)),.08*diff(range(x))))
polygon(x=c(5, 5, x[x > 5], MM),
        y=c(0, 0.15*exp(-0.675), y[x > 5], 0), col='lightblue', border=NA)
arrows(y0 = min(y)-.1*diff(range(y)), y1 = max(y)+.13*diff(range(y)), x0=0, x1=0, length = .1)
arrows(x0 = min(x)-.02*diff(range(x)), x1 = max(x)+.08*diff(range(x)), y0=0, y1=0, length = .1)
arrows(x0 = 10, x1 = 15, y0=0.02, y1=0.075, length = .1)
text(x=15, y=.075, labels=expression(italic(P)(italic(X) > 5)%~~%0.5092), pos = 4, cex=1.5)
lines(x[x >= 0.5], y[x >= 0.5], lwd=3)
lines(x[x < 0.5], y[x < 0.5], lwd=3)
lines(c(5, 5), c(0, 0.15*exp(-0.675)), lty=3, lwd=1.5)
lines(c(.5, .5), c(0, 0.15), lty=3, lwd=1.5)
lines(c(.5, .5), c(0, -0.005), lwd=1.5)
text(x=0.5, y=-0.007, labels = '0.5', adj=c(0.3,1), cex=.8)
lines(c(5, 5), c(0, -0.005), lwd=1.5)
text(x=5, y=-0.007, labels = '5', adj=c(0.5,1), cex=.8)
points(x=c(0.5, 0.5), y=c(0, 0.15), pch=c(21,21), bg=c('white','black'))
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
```

## 3 Vari√°veis aleat√≥rias cont√≠nuas {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

√â importante refor√ßar que podemos obter a fdp $f_X(\cdot)$ da fda $F_X(\cdot)$ e vice-versa, por meio de
$$\textstyle f_X(x) = \frac{d}{dx}F_X(x)\ \ \ \ \text{e} \ \ \ \ F_X(x) = \int_{-\infty}^x f_X(t)dt.$$
:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):** No caso, dada a fdp, podemos obter a fda como a antiderivada de $f_X(x)$
[$$\textstyle F_X(x) = \int_{-\infty}^{0.5}0dt + \int_{0.5}^x 0.15e^{-0.15(t-0.5)}dt = 0 + \left[\left.-e^{-0.15(t-0.5)}\right|_{0.5}^x\right] = 1-e^{-0.15(x-0.5)}.$$]{.fragment}
[Agora, a fda pode ser utilizada para obter a probabilidade anterior:
$$\textstyle P(X > 5) = 1- P(X \leq 5) = 1- F_X(5) = 1-[1-e^{-0.15(5-0.5)}] = e^{-0.675} \approx 0.5092.$$]{.fragment}
:::

## 3 Vari√°veis aleat√≥rias cont√≠nuas {.unnumbered .unlisted}


::: {.callout-caution}
## Observa√ß√£o

A inversa de $F_X(x)$ pode ser utilizada para encontrar os quantis.
:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):** Vimos que $F_X(x) = 1-e^{-0.15(x-0.5)}$. Vamos determinar a mediana de $X$, denotada por $\tilde{\mu}_X$. Para $\tilde{\mu}_X$ ser a mediana, devemos ter $F_X(\tilde{\mu}_X) = 0.5$. [Logo
$$1-e^{-0.15(\tilde{\mu}_X-0.5)} = 0.5 \Rightarrow e^{-0.15(\tilde{\mu}_X-0.5)} = 0.5 \Rightarrow \tilde{\mu}_X = 0.5 -\frac{20}{3}\log(0.5) \approx 5.121.$$]{.fragment}
:::

::: fragment

::: {.callout-tip}
## Exerc√≠cio

Encontre o quantil de ordem $p$, denotado por $Q_p$, isto √©, o valor tal que $F_X(Q_p) = p$.
:::

:::

## Esperan√ßa e vari√¢ncia de vac's

::: {.callout-caution}
## Observa√ß√£o

Em Estat√≠stica Descritiva, ao tratar de distribui√ß√µes intervalares, uma aproxima√ß√£o para a m√©dia era
$$\textstyle \bar{x} \approx \sum_{i}x_i^{(m)} f_i = \sum_{i}x_i^{(m)} d_i h_i,$$
em que $x_i^{(m)}$, $f_i$, $d_i$ e $h_i$ s√£o, respectivamente, o ponto m√©dio, a frequ√™ncia relativa, a [**densidade**]{style="color:red"} e o [**comprimento**]{style="color:red"} do intervalo $i$. Como a fdp $f_X(x)$ √© um modelo te√≥rico para as densidades $d_i$ no intervalo de comprimento infinitesimal $dx$ em torno de $x$, isso motiva a seguinte defini√ß√£o de esperan√ßa.
:::

::: fragment

::: {.callout-note}
## Defini√ß√£o

Seja $X$ vac com fdp $f_X(x)$, ent√£o a sua esperan√ßa √© definida por
$$\textstyle \mu = \mu_X = E(X) = \int_{-\infty}^\infty xf_X(x)dx.$$
:::

:::

## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedade

Da mesma forma que no caso discreto, se $X$ √© vac e $Y = h(X)$, ent√£o
$$\textstyle \mu_Y = E(Y) = E[h(X)] = \int_{-\infty}^\infty h(x) f_X(x) dx.$$
:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

A propriedade acima contorna a necessidade de obter $f_Y(y)$ para calcular $\mu_Y = E(Y) = \int_{-\infty}^\infty y f_X(y)dy$.
:::

:::

::: fragment

::: {.callout-note}
## Defini√ß√£o

Seja $X$ vac com fdp $f_X(x)$, ent√£o a sua vari√¢ncia √© definida por
$$\textstyle \sigma^2 = \sigma^2_X = V(X) = E[(X-\mu)^2] = \int_{-\infty}^\infty (x-\mu)^2f_X(x)dx.$$
:::

:::

## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedade

Da mesma forma que no caso discreto, se $X$ √© vac, temos a seguinte forma alternativa para a vari√¢ncia:
$$\textstyle \sigma^2 = E(X^2) - \mu^2, \ \ \ \ \  E(X^2) = \int_{-\infty}^\infty x^2 f_X(x) dx.$$
:::

:::fragment

::: {.callout-warning}
## Propriedades

Da mesma forma que no caso discreto, se $X$ √© vac e $a$ e $b$ s√£o constantes, ent√£o:

::: incremental

1. $\mu_{aX+b} = E(aX + b) = aE(X) + b = a\mu_X + b$;
2. $\sigma_{aX+b}^2 = V(aX + b) = a^2V(X) = a^2\sigma_X^2$;
3. $\sigma_{aX+b} = DP(aX + b) = aDP(X) = a\sigma_X$.

:::

:::

:::

## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):**

Vamos calcular $\mu$. [Tomando $s = 0.15(x - 0.5)$, ent√£o $0.15x = s+0.15\cdot0.5$, $ds = 0.15dx$.]{style="color:white"} [Portanto, 
$$\begin{align*}
\mu &=\textstyle \int_{-\infty}^{0.5} x\cdot 0 dx + \int_{-0.5}^{\infty} x0.15e^{-0.15(x-0.5)} dx \invisible{ = \int_{0}^\infty (s+0.15\cdot0.5)e^{-s}\frac{ds}{0.15}} \\
&\textstyle\invisible{= \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5\int_{0}^\infty e^{-s}ds} \invisible{ = \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5.} \\
\end{align*}$$]{style="color:white"}

[Na integral ap√≥s a √∫ltima igualdade, fazendo $u = s$ e $dv = e^{-s}ds$, vem que $du=ds$ e $v = -e^{-s}$.]{style="color:white"} [Logo
$$\textstyle \mu = 0.5 + \frac{1}{0.15}\{[-\frac{s}{e^s}|_0^\infty] + \int_0^{\infty}e^{-s}ds\} \invisible{ = 0.5 + \frac{20}{3}[0 + 1] = \frac{3 + 40}{6}} \invisible{ = \frac{43}{6} \approx 7.1667.}$$]{style="color:white"}

[Note que obtivemos $\mu = 7.1667 > \tilde\mu = 5.121$, o que reflete a assimetria √† direita da fdp.]{style="color:white"}

:::

::: {style="visibility:hidden"}

::: {.callout-tip}
## Exerc√≠cios

Calcule $\sigma^2$ para a vac $X$ do Exemplo 13.
:::

:::



## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):**

Vamos calcular $\mu$. Tomando $s = 0.15(x - 0.5)$, ent√£o $0.15x = s+0.15\cdot0.5$, $ds = 0.15dx$. [Portanto, 
$$\begin{align*}
\mu &=\textstyle \int_{-\infty}^{0.5} x\cdot 0 dx + \int_{-0.5}^{\infty} x0.15e^{-0.15(x-0.5)} dx \invisible{ = \int_{0}^\infty (s+0.15\cdot0.5)e^{-s}\frac{ds}{0.15}} \\
&\textstyle\invisible{= \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5\int_{0}^\infty e^{-s}ds} \invisible{ = \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5.} \\
\end{align*}$$]{style="color:white"}

[Na integral ap√≥s a √∫ltima igualdade, fazendo $u = s$ e $dv = e^{-s}ds$, vem que $du=ds$ e $v = -e^{-s}$.]{style="color:white"} [Logo
$$\textstyle \mu = 0.5 + \frac{1}{0.15}\{[-\frac{s}{e^s}|_0^\infty] + \int_0^{\infty}e^{-s}ds\} \invisible{ = 0.5 + \frac{20}{3}[0 + 1] = \frac{3 + 40}{6}} \invisible{ = \frac{43}{6} \approx 7.1667.}$$]{style="color:white"}

[Note que obtivemos $\mu = 7.1667 > \tilde\mu = 5.121$, o que reflete a assimetria √† direita da fdp.]{style="color:white"}

:::

::: {style="visibility:hidden"}

::: {.callout-tip}
## Exerc√≠cios

Calcule $\sigma^2$ para a vac $X$ do Exemplo 13.
:::

:::


## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):**

Vamos calcular $\mu$. Tomando $s = 0.15(x - 0.5)$, ent√£o $0.15x = s+0.15\cdot0.5$, $ds = 0.15dx$. Portanto, 
$$\begin{align*}
\mu &=\textstyle \int_{-\infty}^{0.5} x\cdot 0 dx + \int_{-0.5}^{\infty} x0.15e^{-0.15(x-0.5)} dx \invisible{ = \int_{0}^\infty (s+0.15\cdot0.5)e^{-s}\frac{ds}{0.15}}\\
&\textstyle \invisible{= \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5\int_{0}^\infty e^{-s}ds} \invisible{ = \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5.}\\
\end{align*}$$

[Na integral ap√≥s a √∫ltima igualdade, fazendo $u = s$ e $dv = e^{-s}ds$, vem que $du=ds$ e $v = -e^{-s}$.]{style="color:white"} [Logo
$$\textstyle \mu = 0.5 + \frac{1}{0.15}\{[-\frac{s}{e^s}|_0^\infty] + \int_0^{\infty}e^{-s}ds\} \invisible{ = 0.5 + \frac{20}{3}[0 + 1] = \frac{3 + 40}{6}} \invisible{ = \frac{43}{6} \approx 7.1667.}$$]{style="color:white"}

[Note que obtivemos $\mu = 7.1667 > \tilde\mu = 5.121$, o que reflete a assimetria √† direita da fdp.]{style="color:white"}

:::

::: {style="visibility:hidden"}

::: {.callout-tip}
## Exerc√≠cios

Calcule $\sigma^2$ para a vac $X$ do Exemplo 13.
:::

:::



## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):**

Vamos calcular $\mu$. Tomando $s = 0.15(x - 0.5)$, ent√£o $0.15x = s+0.15\cdot0.5$, $ds = 0.15dx$. Portanto, 
$$\begin{align*}
\mu &=\textstyle \int_{-\infty}^{0.5} x\cdot 0 dx + \int_{-0.5}^{\infty} x0.15e^{-0.15(x-0.5)} dx = \int_{0}^\infty (s+0.15\cdot0.5)e^{-s}\frac{ds}{0.15}\\
&\textstyle\invisible{=\frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5\int_{0}^\infty e^{-s}ds} \invisible{ = \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5.}\\
\end{align*}$$

[Na integral ap√≥s a √∫ltima igualdade, fazendo $u = s$ e $dv = e^{-s}ds$, vem que $du=ds$ e $v = -e^{-s}$.]{style="color:white"} [Logo
$$\textstyle \mu = 0.5 + \frac{1}{0.15}\{[-\frac{s}{e^s}|_0^\infty] + \int_0^{\infty}e^{-s}ds\} \invisible{ = 0.5 + \frac{20}{3}[0 + 1] = \frac{3 + 40}{6}} \invisible{ = \frac{43}{6} \approx 7.1667.}$$]{style="color:white"}

[Note que obtivemos $\mu = 7.1667 > \tilde\mu = 5.121$, o que reflete a assimetria √† direita da fdp.]{style="color:white"}

:::

::: {style="visibility:hidden"}

::: {.callout-tip}
## Exerc√≠cios

Calcule $\sigma^2$ para a vac $X$ do Exemplo 13.
:::

:::

## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):**

Vamos calcular $\mu$. Tomando $s = 0.15(x - 0.5)$, ent√£o $0.15x = s+0.15\cdot0.5$, $ds = 0.15dx$. Portanto, 
$$\begin{align*}
\mu &=\textstyle \int_{-\infty}^{0.5} x\cdot 0 dx + \int_{-0.5}^{\infty} x0.15e^{-0.15(x-0.5)} dx = \int_{0}^\infty (s+0.15\cdot0.5)e^{-s}\frac{ds}{0.15}\\
&=\textstyle \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5\int_{0}^\infty e^{-s}ds \invisible{ = \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5.}\\
\end{align*}$$

[Na integral ap√≥s a √∫ltima igualdade, fazendo $u = s$ e $dv = e^{-s}ds$, vem que $du=ds$ e $v = -e^{-s}$.]{style="color:white"} [Logo
$$\textstyle \mu = 0.5 + \frac{1}{0.15}\{[-\frac{s}{e^s}|_0^\infty] + \int_0^{\infty}e^{-s}ds\} \invisible{ = 0.5 + \frac{20}{3}[0 + 1] = \frac{3 + 40}{6}} \invisible{ = \frac{43}{6} \approx 7.1667.}$$]{style="color:white"}

[Note que obtivemos $\mu = 7.1667 > \tilde\mu = 5.121$, o que reflete a assimetria √† direita da fdp.]{style="color:white"}

:::

::: {style="visibility:hidden"}

::: {.callout-tip}
## Exerc√≠cios

Calcule $\sigma^2$ para a vac $X$ do Exemplo 13.
:::

:::


## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):**

Vamos calcular $\mu$. Tomando $s = 0.15(x - 0.5)$, ent√£o $0.15x = s+0.15\cdot0.5$, $ds = 0.15dx$. Portanto, 
$$\begin{align*}
\mu &=\textstyle \int_{-\infty}^{0.5} x\cdot 0 dx + \int_{-0.5}^{\infty} x0.15e^{-0.15(x-0.5)} dx = \int_{0}^\infty (s+0.15\cdot0.5)e^{-s}\frac{ds}{0.15}\\
&=\textstyle \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5\int_{0}^\infty e^{-s}ds = \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5.\\
\end{align*}$$

[Na integral ap√≥s a √∫ltima igualdade, fazendo $u = s$ e $dv = e^{-s}ds$, vem que $du=ds$ e $v = -e^{-s}$.]{style="color:white"} [Logo
$$\textstyle \mu = 0.5 + \frac{1}{0.15}\{[-\frac{s}{e^s}|_0^\infty] + \int_0^{\infty}e^{-s}ds\} \invisible{ = 0.5 + \frac{20}{3}[0 + 1] = \frac{3 + 40}{6}} \invisible{ = \frac{43}{6} \approx 7.1667.}$$]{style="color:white"}

[Note que obtivemos $\mu = 7.1667 > \tilde\mu = 5.121$, o que reflete a assimetria √† direita da fdp.]{style="color:white"}

:::

::: {style="visibility:hidden"}

::: {.callout-tip}
## Exerc√≠cios

Calcule $\sigma^2$ para a vac $X$ do Exemplo 13.
:::

:::



## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):**

Vamos calcular $\mu$. Tomando $s = 0.15(x - 0.5)$, ent√£o $0.15x = s+0.15\cdot0.5$, $ds = 0.15dx$. Portanto, 
$$\begin{align*}
\mu &=\textstyle \int_{-\infty}^{0.5} x\cdot 0 dx + \int_{-0.5}^{\infty} x0.15e^{-0.15(x-0.5)} dx = \int_{0}^\infty (s+0.15\cdot0.5)e^{-s}\frac{ds}{0.15}\\
&=\textstyle \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5\int_{0}^\infty e^{-s}ds = \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5.\\
\end{align*}$$

Na integral ap√≥s a √∫ltima igualdade, fazendo $u = s$ e $dv = e^{-s}ds$, vem que $du=ds$ e $v = -e^{-s}$. [Logo
$$\textstyle \mu = 0.5 + \frac{1}{0.15}\{[-\frac{s}{e^s}|_0^\infty] + \int_0^{\infty}e^{-s}ds\} \invisible{ = 0.5 + \frac{20}{3}[0 + 1] = \frac{3 + 40}{6}} \invisible{ = \frac{43}{6} \approx 7.1667.}$$]{style="color:white"}

[Note que obtivemos $\mu = 7.1667 > \tilde\mu = 5.121$, o que reflete a assimetria √† direita da fdp.]{style="color:white"}

:::

::: {style="visibility:hidden"}

::: {.callout-tip}
## Exerc√≠cios

Calcule $\sigma^2$ para a vac $X$ do Exemplo 13.
:::

:::

## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):**

Vamos calcular $\mu$. Tomando $s = 0.15(x - 0.5)$, ent√£o $0.15x = s+0.15\cdot0.5$, $ds = 0.15dx$. Portanto, 
$$\begin{align*}
\mu &=\textstyle \int_{-\infty}^{0.5} x\cdot 0 dx + \int_{-0.5}^{\infty} x0.15e^{-0.15(x-0.5)} dx = \int_{0}^\infty (s+0.15\cdot0.5)e^{-s}\frac{ds}{0.15}\\
&=\textstyle \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5\int_{0}^\infty e^{-s}ds = \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5.\\
\end{align*}$$

Na integral ap√≥s a √∫ltima igualdade, fazendo $u = s$ e $dv = e^{-s}ds$, vem que $du=ds$ e $v = -e^{-s}$. Logo
$$\textstyle \mu = 0.5 + \frac{1}{0.15}\{[-\frac{s}{e^s}|_0^\infty] + \int_0^{\infty}e^{-s}ds\} \invisible{ = 0.5 + \frac{20}{3}[0 + 1] = \frac{3 + 40}{6}} \invisible{ = \frac{43}{6} \approx 7.1667.}$$

[Note que obtivemos $\mu = 7.1667 > \tilde\mu = 5.121$, o que reflete a assimetria √† direita da fdp.]{style="color:white"}

:::

::: {style="visibility:hidden"}

::: {.callout-tip}
## Exerc√≠cios

Calcule $\sigma^2$ para a vac $X$ do Exemplo 13.
:::

:::


## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):**

Vamos calcular $\mu$. Tomando $s = 0.15(x - 0.5)$, ent√£o $0.15x = s+0.15\cdot0.5$, $ds = 0.15dx$. Portanto, 
$$\begin{align*}
\mu &=\textstyle \int_{-\infty}^{0.5} x\cdot 0 dx + \int_{-0.5}^{\infty} x0.15e^{-0.15(x-0.5)} dx = \int_{0}^\infty (s+0.15\cdot0.5)e^{-s}\frac{ds}{0.15}\\
&=\textstyle \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5\int_{0}^\infty e^{-s}ds = \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5.\\
\end{align*}$$

Na integral ap√≥s a √∫ltima igualdade, fazendo $u = s$ e $dv = e^{-s}ds$, vem que $du=ds$ e $v = -e^{-s}$. Logo
$$\textstyle \mu = 0.5 + \frac{1}{0.15}\{[-\frac{s}{e^s}|_0^\infty] + \int_0^{\infty}e^{-s}ds\} = 0.5 + \frac{20}{3}[0 + 1] = \frac{3 + 40}{6} \invisible{ = \frac{43}{6} \approx 7.1667.}$$

[Note que obtivemos $\mu = 7.1667 > \tilde\mu = 5.121$, o que reflete a assimetria √† direita da fdp.]{style="color:white"}

:::

::: {style="visibility:hidden"}

::: {.callout-tip}
## Exerc√≠cios

Calcule $\sigma^2$ para a vac $X$ do Exemplo 13.
:::

:::




## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):**

Vamos calcular $\mu$. Tomando $s = 0.15(x - 0.5)$, ent√£o $0.15x = s+0.15\cdot0.5$, $ds = 0.15dx$. Portanto, 
$$\begin{align*}
\mu &=\textstyle \int_{-\infty}^{0.5} x\cdot 0 dx + \int_{-0.5}^{\infty} x0.15e^{-0.15(x-0.5)} dx = \int_{0}^\infty (s+0.15\cdot0.5)e^{-s}\frac{ds}{0.15}\\
&=\textstyle \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5\int_{0}^\infty e^{-s}ds = \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5.\\
\end{align*}$$

Na integral ap√≥s a √∫ltima igualdade, fazendo $u = s$ e $dv = e^{-s}ds$, vem que $du=ds$ e $v = -e^{-s}$. Logo
$$\textstyle \mu = 0.5 + \frac{1}{0.15}\{[-\frac{s}{e^s}|_0^\infty] + \int_0^{\infty}e^{-s}ds\} = 0.5 + \frac{20}{3}[0 + 1] = \frac{3 + 40}{6} = \frac{43}{6} \approx 7.1667.$$

[Note que obtivemos $\mu = 7.1667 > \tilde\mu = 5.121$, o que reflete a assimetria √† direita da fdp.]{.fragment}

:::

::: fragment

::: {.callout-tip}
## Exerc√≠cios

Calcule $\sigma^2$ para a vac $X$ do Exemplo 13.
:::

:::



## Modelos probabil√≠sticos cont√≠nuos

# Vetores Aleat√≥rios Bidimensionais

## Covari√¢ncia e Correla√ß√£o

# Fun√ß√µes de Vari√°veis Aleat√≥rias

# FIM {.unnumbered .unlisted}

# APAGAR DPS 1 {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

:::

::: {.callout-note}
## Defini√ß√£o

:::

::: {.callout-warning}
## Propriedades

:::

::: {.callout-tip}
## Exerc√≠cios

:::

::: {.callout-important}
## Problema

:::


::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo:** 

::: 

# APAGAR DPS 2 {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=45%}
1
:::

::: {.column #vcenter width=55%}
2

3

4
:::

:::



```{=latex}
\begin{align*}
\Omega &= \{(1,1), (1,2), \ldots, (4,4)\}\\
       &= \{(x,y) : x,y = 1,\ldots,4\}.
\end{align*}
```


# FIM {.unnumbered .unlisted}
