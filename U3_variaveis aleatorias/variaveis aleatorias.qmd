---
title: "Probabilidade e Estat√≠stica"
subtitle: "Vari√°veis Aleat√≥rias"
author: "Prof. Dr. Alessandro JQ Sarnaglia"
lang: "pt"
format:
  revealjs:
    width: 1280
    height: 720
    min-scale: 0.05
    fig-width: 5.5
    fig-height: 5.5
    theme: [custom.scss]
    css: [fonts.css, style.css]
    callout-icon: false
    toc: true
    toc-depth: 3
    toc-expand: 3
    number-sections: true
    number-depth: 3
    footer: "[Voltar üîô](../index.html)"
    menu:
      useTextContentForMissingTitles: false
editor: source
filters:
  - parse-latex
---


# Defini√ß√£o

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1:** Uma amostra de $n$ componentes √© submetida a testes para verificar os defeituosos e os n√£o defeituosos. Nesse experimento, podemos definir o espa√ßo amostral
$$
\newcommand{\invisible}[1]{\color{white}{#1}}
\Omega = \{\omega = (z_1, \ldots, z_n) : z_i \in \{S,F\} \},
$$
em que $S =$ "componente defeituoso" e $F =$ "componente n√£o defeituoso".

::: 

::: {.callout-caution}
## Observa√ß√£o

Como visto acima, o espa√ßo amostral pode assumir formas bem abstratas. No entanto, em muitos casos, √© de interesse associar um valor num√©rico a cada resultado de $\Omega$.
:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1 (cont.):** No exemplo anterior, suponha $n=3$, ent√£o
$$
\Omega = \{(FFF),(SFF),(FSF),(FFS),(SSF),(SFS),(FSS),(SSS)\}.
$$
Pode ser interesse registrar apenas o n√∫mero de componentes defeituosos e n√£o as falhas individuais (se $n$ grande por exemplo). Assim, ter√≠amos $X(\omega) =$ "n√∫mero de componentes defeituosos em $\omega$" e:

::: incremental

-   $X(FFF) = 0$;
-   $X(SFF) = X(FSF) = X(FFS) = 1$;
-   $X(SSF) = X(SFS) = X(FSS) = 2$; e
-   $X(SSS) = 3$.

:::

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

O tipo de situa√ß√£o acima nos leva a defini√ß√£o de [**vari√°veis aleat√≥rias**]{style="color:red;"}.
:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o - Vari√°veis Aleat√≥rias

Seja $\Omega$ espa√ßo amostral de um experimento aleat√≥rio. Uma **vari√°vel aleat√≥ria** (va) √© qualquer regra que associe um valor num√©rico real a cada resultado de $\Omega$.
:::

::: {.callout-caution}
## Observa√ß√µes

Da defini√ß√£o de va, podemos fazer os seguintes apontamentos:

1.    Vari√°veis aleat√≥rias normalmente s√£o denotadas por letras mai√∫sculas do final do alfabeto, tais como $X$, $Y$, $Z$, entre outras;
2.    Matematicamente, podemos definir $X$ como va se $X : \Omega \to \mathbb{R}$;
3.    Podemos tamb√©m escrever $X(\omega) = x$ para dizer que $x$ √© o valor atribu√≠do a $\omega$ pela va $X$.
:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=55%}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1 (cont.):**

<figure>
  <img src="figs/ilustracao_variavel_aleatoria0.png" style="display: block;margin-left: auto;margin-right: auto;width: 80%;">
</figure>

:::

:::

::: {.column #vcenter width=45%}

:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=55%}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1 (cont.):**

<figure>
  <img src="figs/ilustracao_variavel_aleatoria1.png" style="display: block;margin-left: auto;margin-right: auto;width: 80%;">
</figure>

:::

:::

::: {.column #vcenter width=45%}

:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=55%}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1 (cont.):**

<figure>
  <img src="figs/ilustracao_variavel_aleatoria2.png" style="display: block;margin-left: auto;margin-right: auto;width: 80%;">
</figure>

:::

:::

::: {.column #vcenter width=45%}

:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=55%}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1 (cont.):**

<figure>
  <img src="figs/ilustracao_variavel_aleatoria3.png" style="display: block;margin-left: auto;margin-right: auto;width: 80%;">
</figure>

:::

:::

::: {.column #vcenter width=45%}

:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=55%}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1 (cont.):**

<figure>
  <img src="figs/ilustracao_variavel_aleatoria4.png" style="display: block;margin-left: auto;margin-right: auto;width: 80%;">
</figure>

:::

:::

::: {.column #vcenter width=45%}

:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=55%}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 1 (cont.):**

<figure>
  <img src="figs/ilustracao_variavel_aleatoria5.png" style="display: block;margin-left: auto;margin-right: auto;width: 80%;">
</figure>

:::

:::

::: {.column #vcenter width=45%}
::: {.callout-caution}
## Observa√ß√£o

Os valores de $\text{Im}(X)$ induzem uma parti√ß√£o de $\Omega$. No exemplo, vimos:

-   $[X=0] = \{(FFF)\}$;
-   $[X=1] = \{(FFS), (FSF), (SFF)\}$;
-   $[X=2] = \{(FSS), (SFS), (SSF)\}$; e
-   $[X=3] = \{(SSS)\}$.

:::
:::

:::



## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

A qualquer va $X$, podemos associar um contradom√≠nio (normalmente o conjunto $\mathbb{R}$) e uma [**imagem**]{style="color:red;"}, que denotaremos por $\text{Im}(X)$.

:::

::: {.callout-note}
## Defini√ß√£o

O conjunto de todos poss√≠veis valores que uma va $X$ pode assumir √© denominado **imagem** de $X$ e √© denotado por $\text{Im}(X)$.

:::

::: {.callout-caution}
## Observa√ß√£o

No exemplo anterior, temos que $\text{Im}(X) = \{0,1,2,3\}$.
:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Similarmente a estat√≠stica descritiva, podemos classificar as va's de acordo com o seu conjunto imagem.

:::

::: {.callout-note}
## Defini√ß√£o

Dada uma va $X$, dizemos que:

-   $X$ √© va **discreta** (vad) se $\text{Im}(X)$ for conjunto finito ou infinito enumer√°vel;
-   $X$ √© va **cont√≠nua** (vac) se $\text{Im}(X)$ for conjunto n√£o enumer√°vel.

:::

::: {.callout-caution}
## Observa√ß√£o

Agora, fica claro que a va $X$ do exemplo anterior se trata de uma **vad**.

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 2:** Uma linha de produ√ß√£o √© observada at√© a produ√ß√£o da primeira pe√ßa defeituosa. Seja $S =$ "Pe√ßa defeituosa" e $F =$ "Pe√ßa normal". Ent√£o temos que
$$
\Omega = \{(S), (FS), (FFS), (FFFS), \ldots\}.
$$

::: columns

::: {.column #vcenter width=60%}

A este experimento, podemos associar a va $X =$ "N√∫mero de pe√ßas produzidas". Nesse caso, ter√≠amos
$$
\text{Im}(X) = \{1, 2, 3, \ldots\}.
$$

:::

::: {.column #vcenter width=40%}

<figure>
  <img src="figs/ilustracao_variavel_aleatoria_discreta.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;">
</figure>

:::

:::

:::

::: {.callout-caution}
## Observa√ß√£o

Embora $\text{Im}(X)$ seja infinito, ele √© um conjunto enumer√°vel, de modo que $X$ √© **vad**.

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

::: columns

::: {.column #vcenter width=60%}

**Exemplo 3:** Um ponto de uma regi√£o circular de raio unit√°rio √© sorteado. Nesse caso, podemos definir $\Omega = \{\omega = (z_1,z_2) : z_1^2 + z_2^2 \leq 1\}$.

[Nesse espa√ßo amostral, um evento $A$, √© uma [**regi√£o**]{style="color:red;"} de pontos, $A\subset\Omega$.]{style="visibility:hidden;"}

[A este experimento, poder√≠amos associar a vari√°vel aleat√≥ria $X =$ "Dist√¢ncia de $\omega$ √† origem". Isto √© $X(\omega) = (z_1^2 - z_2^2)^{1/2}$. Note que, nesse caso $\text{Im}(X) = [0,1]$.]{style="visibility:hidden;"}

:::

::: {.column #vcenter width=40%}

<figure>
  <img src="figs/ilustracao_variavel_aleatoria_continua0.svg" style="display: block;margin-left: auto;margin-right: auto;width: 95%;">
</figure>

:::

:::

:::

::: {style="visibility:hidden"}

::: {.callout-caution}
## Observa√ß√£o

Como $\text{Im}(X)$ √© conjunto n√£o enumer√°vel, classificamos $X$ como uma **vac**.

:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

::: columns

::: {.column #vcenter width=60%}

**Exemplo 3:** Um ponto de uma regi√£o circular de raio unit√°rio √© sorteado. Nesse caso, podemos definir $\Omega = \{\omega = (z_1,z_2) : z_1^2 + z_2^2 \leq 1\}$.

Nesse espa√ßo amostral, um evento $A$, √© uma [**regi√£o**]{style="color:red;"} de pontos, $A\subset\Omega$.

[A este experimento, poder√≠amos associar a vari√°vel aleat√≥ria $X =$ "Dist√¢ncia de $\omega$ √† origem". Isto √© $X(\omega) = (z_1^2 - z_2^2)^{1/2}$. Note que, nesse caso $\text{Im}(X) = [0,1]$.]{style="visibility:hidden;"}

:::

::: {.column #vcenter width=40%}

<figure>
  <img src="figs/ilustracao_variavel_aleatoria_continua1.svg" style="display: block;margin-left: auto;margin-right: auto;width: 95%;">
</figure>

:::

:::

:::

::: {style="visibility:hidden"}

::: {.callout-caution}
## Observa√ß√£o

Como $\text{Im}(X)$ √© conjunto n√£o enumer√°vel, classificamos $X$ como uma **vac**.

:::

:::

## 1 Defini√ß√£o {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

::: columns

::: {.column #vcenter width=60%}

**Exemplo 3:** Um ponto de uma regi√£o circular de raio unit√°rio √© sorteado. Nesse caso, podemos definir $\Omega = \{\omega = (z_1,z_2) : z_1^2 + z_2^2 \leq 1\}$.

Nesse espa√ßo amostral, um evento $A$, √© uma [**regi√£o**]{style="color:red;"} de pontos, $A\subset\Omega$.

A este experimento, poder√≠amos associar a vari√°vel aleat√≥ria $X =$ "Dist√¢ncia de $\omega$ √† origem". Isto √© $X(\omega) = (z_1^2 + z_2^2)^{1/2}$. Note que, nesse caso $\text{Im}(X) = [0,1]$.

:::

::: {.column #vcenter width=40%}

<figure>
  <img src="figs/ilustracao_variavel_aleatoria_continua2.svg" style="display: block;margin-left: auto;margin-right: auto;width: 95%;">
</figure>

:::

:::

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Como $\text{Im}(X)$ √© conjunto n√£o enumer√°vel, classificamos $X$ como uma **vac**.

:::

:::

## Fun√ß√£o de distribui√ß√£o acumulada

::: {.callout-caution}
## Observa√ß√£o

Um evento aleat√≥rio muito importante para modelagem de va's √© $[X \leq x]$. A probabilidade deste evento nos diz o quanto de probabilidade a va $X$ acumula at√© o valor $x$.

:::

::: {.callout-note}
## Defini√ß√£o

A **fun√ß√£o de distribui√ß√£o acumulada** (fda) √© definida por $F_X(x) = P(X \leq x)$
:::

::: {.callout-caution}
## Observa√ß√£o

Ao se partir de uma medida de probabilidade definida em $\Omega$, para o calcular $F_X(x)$, devemos encontrar a probabilidade (em $\Omega$) do evento $A_x = \{\omega \in \Omega: X(\omega) \leq x\}$. Isto √©, $F_X(x) = P(X \leq x) = P(A_x)$.

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 1 (cont.) {.unnumbered .unlisted}

Se supomos que $\Omega$ √© equiprov√°vel. Teremos que

$$
F_X(x) = \begin{cases}
0, & x < 0;\\
P(X=0) = \frac{1}{8}, & 0 \leq x < 1;\\
P(X=0) + P(X=1) = \frac{1}{8} + \frac{3}{8} = \frac{4}{8}, & 1 \leq x < 2;\\
P(X=0) + P(X=1) + P(X=2) = \frac{1}{8} + \frac{3}{8} + \frac{3}{8} = \frac{7}{8}, & 2 \leq x < 3;\\
P(X=0) + P(X=1) + P(X=2) + P(X=3) = \frac{1}{8} + \frac{3}{8} + \frac{3}{8} + \frac{1}{8} = 1, & x \geq 3;\\
\end{cases}
$$

## {.unnumbered .unlisted}

### Exemplo 1 (cont.) {.unnumbered .unlisted}

<figure>
  <img src="figs/ilustracao_fda0.png" style="display: block;margin-left: auto;margin-right: auto;width: 65%;">
</figure>

## {.unnumbered .unlisted}

### Exemplo 1 (cont.) {.unnumbered .unlisted}

<figure>
  <img src="figs/ilustracao_fda1.png" style="display: block;margin-left: auto;margin-right: auto;width: 65%;">
</figure>

## {.unnumbered .unlisted}

### Exemplo 1 (cont.) {.unnumbered .unlisted}

<figure>
  <img src="figs/ilustracao_fda2.png" style="display: block;margin-left: auto;margin-right: auto;width: 65%;">
</figure>

## {.unnumbered .unlisted}

### Exemplo 1 (cont.) {.unnumbered .unlisted}

<figure>
  <img src="figs/ilustracao_fda3.png" style="display: block;margin-left: auto;margin-right: auto;width: 65%;">
</figure>

## {.unnumbered .unlisted}

### Exemplo 1 (cont.) {.unnumbered .unlisted}

<figure>
  <img src="figs/ilustracao_fda4.png" style="display: block;margin-left: auto;margin-right: auto;width: 65%;">
</figure>


## {.unnumbered .unlisted}

### Exemplo 1 (cont.) {.unnumbered .unlisted}

<figure>
  <img src="figs/ilustracao_fda5.png" style="display: block;margin-left: auto;margin-right: auto;width: 65%;">
</figure>

::: {.callout-caution}
## Observa√ß√£o

No caso discreto, os tamanhos dos saltos de $F_X(x)$ nos d√° os valores de $P(X=x)$.
:::

## 1.1 Fun√ß√£o de distribui√ß√£o acumulada {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Se $X$ √© vad, a fun√ß√£o $p_X(x) = P(X=x)$, $x \in \text{Im}(X)$, √© chamada [**fun√ß√£o massa de probabilidade**]{style="color:red;"} (fmp).
:::

::: fragment

::: {.callout-warning}
## Propriedades

A fmp $p_X(x)$ de um uma vad $X$ satisfaz:

::: incremental

1.    $p_X(x) \geq 0$;
2.    $\textstyle \sum_{x} p_X(x) = 1$.

:::

:::

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Assim, vemos que, para vari√°veis aleat√≥rias discretas, a fda $F_X(x)$ nos fornece a fmp $p_X(x)$ e vice-versa.
:::

:::

## 1.1 Fun√ß√£o de distribui√ß√£o acumulada {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

A fmp √© um modelo te√≥rico para as **frequ√™ncias relativas** vistas em estat√≠stica descritiva.
:::

::: fragment


<figure>
  <img src="figs/ilustracao_frequencia_fmp.png" style="display: block;margin-left: auto;margin-right: auto;width: 75%;">
</figure>


:::

## {.unnumbered .unlisted .smaller}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

Supondo que nenhum ponto de $\Omega$ √© privilegiado, podemos definir a medida de probabilidade de $A$ como
$$\textstyle P(A) = \frac{\text{√Årea}(A)}{\text{√Årea}(\Omega)} = \frac{\text{√Årea}(A)}{\pi}.$$
Nesse caso, as probabilidades de dois eventos de mesma √°rea ser√£o as mesmas (equiprobabilidade).  

::: columns

::: {.column #vcenter width=65%}

[Usando essa medida de probabilidade, para calcular a fda de $X$, precisamos encontrar a √°rea da regi√£o $[X \leq x]$. Veja na ilustra√ß√£o ao lado.]{style="visibility:hidden;"}

[Logo, a fda de $X$ √© dada por
$$
\textstyle F_X(x) = P(X \leq x) = \begin{cases}
0, & x < 0;\\
\frac{\text{√Årea}(X \leq x)}{\pi} = \frac{\pi x^2}{\pi} = x^2, & 0\leq x < 1;\\
1, & x \geq 1.
\end{cases}
$$
]{style="visibility:hidden;"}

:::

::: {.column #vcenter width=35%}

<figure>
  <img src="figs/ilustracao_fda_vac0.png" style="display: block;margin-left: auto;margin-right: auto;width: 70%;">
</figure>

:::

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

Supondo que nenhum ponto de $\Omega$ √© privilegiado, podemos definir a medida de probabilidade de $A$ como
$$\textstyle P(A) = \frac{\text{√Årea}(A)}{\text{√Årea}(\Omega)} = \frac{\text{√Årea}(A)}{\pi}.$$
Nesse caso, as probabilidades de dois eventos de mesma √°rea ser√£o as mesmas (equiprobabilidade).  

::: columns

::: {.column #vcenter width=65%}

Usando essa medida de probabilidade, para calcular a fda de $X$, precisamos encontrar a √°rea da regi√£o $[X \leq x]$. Veja na ilustra√ß√£o ao lado.

[Logo, a fda de $X$ √© dada por
$$
\textstyle F_X(x) = P(X \leq x) = \begin{cases}
0, & x < 0;\\
\frac{\text{√Årea}(X \leq x)}{\pi} = \frac{\pi x^2}{\pi} = x^2, & 0\leq x < 1;\\
1, & x \geq 1.
\end{cases}
$$
]{style="visibility:hidden;"}

:::

::: {.column #vcenter width=35%}

<figure>
  <img src="figs/ilustracao_fda_vac0.png" style="display: block;margin-left: auto;margin-right: auto;width: 70%;">
</figure>


:::

:::



## {.unnumbered .unlisted .smaller}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

Supondo que nenhum ponto de $\Omega$ √© privilegiado, podemos definir a medida de probabilidade de $A$ como
$$\textstyle P(A) = \frac{\text{√Årea}(A)}{\text{√Årea}(\Omega)} = \frac{\text{√Årea}(A)}{\pi}.$$
Nesse caso, as probabilidades de dois eventos de mesma √°rea ser√£o as mesmas (equiprobabilidade).  

::: columns

::: {.column #vcenter width=65%}

Usando essa medida de probabilidade, para calcular a fda de $X$, precisamos encontrar a √°rea da regi√£o $[X \leq x]$. Veja na ilustra√ß√£o ao lado.

[Logo, a fda de $X$ √© dada por
$$
\textstyle F_X(x) = P(X \leq x) = \begin{cases}
0, & x < 0;\\
\frac{\text{√Årea}(X \leq x)}{\pi} = \frac{\pi x^2}{\pi} = x^2, & 0\leq x < 1;\\
1, & x \geq 1.
\end{cases}
$$
]{style="visibility:hidden;"}

:::

::: {.column #vcenter width=35%}

<figure>
  <img src="figs/ilustracao_fda_vac1.png" style="display: block;margin-left: auto;margin-right: auto;width: 70%;">
</figure>


:::

:::


## {.unnumbered .unlisted .smaller}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

Supondo que nenhum ponto de $\Omega$ √© privilegiado, podemos definir a medida de probabilidade de $A$ como
$$\textstyle P(A) = \frac{\text{√Årea}(A)}{\text{√Årea}(\Omega)} = \frac{\text{√Årea}(A)}{\pi}.$$
Nesse caso, as probabilidades de dois eventos de mesma √°rea ser√£o as mesmas (equiprobabilidade).  

::: columns

::: {.column #vcenter width=65%}

Usando essa medida de probabilidade, para calcular a fda de $X$, precisamos encontrar a √°rea da regi√£o $[X \leq x]$. Veja na ilustra√ß√£o ao lado.

[Logo, a fda de $X$ √© dada por
$$
\textstyle F_X(x) = P(X \leq x) = \begin{cases}
0, & x < 0;\\
\frac{\text{√Årea}(X \leq x)}{\pi} = \frac{\pi x^2}{\pi} = x^2, & 0\leq x < 1;\\
1, & x \geq 1.
\end{cases}
$$
]{style="visibility:hidden;"}

:::

::: {.column #vcenter width=35%}

<figure>
  <img src="figs/ilustracao_fda_vac2.png" style="display: block;margin-left: auto;margin-right: auto;width: 70%;">
</figure>


:::

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

Supondo que nenhum ponto de $\Omega$ √© privilegiado, podemos definir a medida de probabilidade de $A$ como
$$\textstyle P(A) = \frac{\text{√Årea}(A)}{\text{√Årea}(\Omega)} = \frac{\text{√Årea}(A)}{\pi}.$$
Nesse caso, as probabilidades de dois eventos de mesma √°rea ser√£o as mesmas (equiprobabilidade).  

::: columns

::: {.column #vcenter width=65%}

Usando essa medida de probabilidade, para calcular a fda de $X$, precisamos encontrar a √°rea da regi√£o $[X \leq x]$. Veja na ilustra√ß√£o ao lado.

[Logo, a fda de $X$ √© dada por
$$
\textstyle F_X(x) = P(X \leq x) = \begin{cases}
0, & x < 0;\\
\frac{\text{√Årea}(X \leq x)}{\pi} = \frac{\pi x^2}{\pi} = x^2, & 0\leq x < 1;\\
1, & x \geq 1.
\end{cases}
$$
]{style="visibility:hidden;"}

:::

::: {.column #vcenter width=35%}

<figure>
  <img src="figs/ilustracao_fda_vac3.png" style="display: block;margin-left: auto;margin-right: auto;width: 70%;">
</figure>


:::

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

Supondo que nenhum ponto de $\Omega$ √© privilegiado, podemos definir a medida de probabilidade de $A$ como
$$\textstyle P(A) = \frac{\text{√Årea}(A)}{\text{√Årea}(\Omega)} = \frac{\text{√Årea}(A)}{\pi}.$$
Nesse caso, as probabilidades de dois eventos de mesma √°rea ser√£o as mesmas (equiprobabilidade).  

::: columns

::: {.column #vcenter width=65%}

Usando essa medida de probabilidade, para calcular a fda de $X$, precisamos encontrar a √°rea da regi√£o $[X \leq x]$. Veja na ilustra√ß√£o ao lado.

Logo, a fda de $X$ √© dada por
$$
\textstyle F_X(x) = P(X \leq x) = \begin{cases}
0, & x < 0;\\
\frac{\text{√Årea}(X \leq x)}{\pi} = \frac{\pi x^2}{\pi} = x^2, & 0\leq x < 1;\\
1, & x \geq 1.
\end{cases}
$$

:::

::: {.column #vcenter width=35%}

<figure>
  <img src="figs/ilustracao_fda_vac3.png" style="display: block;margin-left: auto;margin-right: auto;width: 70%;">
</figure>


:::

:::

## {.unnumbered .unlisted}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

<figure>
  <img src="figs/ilustracao_fda_vac_grafico0.png" style="display: block;margin-left: auto;margin-right: auto;width: 50%;">
</figure>


## {.unnumbered .unlisted}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

<figure>
  <img src="figs/ilustracao_fda_vac_grafico1.png" style="display: block;margin-left: auto;margin-right: auto;width: 50%;">
</figure>


## {.unnumbered .unlisted}

### Exemplo 3 (cont.) {.unnumbered .unlisted}

<figure>
  <img src="figs/ilustracao_fda_vac_grafico2.png" style="display: block;margin-left: auto;margin-right: auto;width: 50%;">
</figure>



::: {.callout-caution}
## Observa√ß√£o

Observe que n√£o h√° pontos de descontinuidade para a fda de uma va cont√≠nua. Portanto, a fda de uma vac n√£o fornece probabilidades diretamente.
:::

## 1.1 Fun√ß√£o de distribui√ß√£o acumulada {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Tomando a derivada da fda de uma vac, obtemos a chamada [**fun√ß√£o densidade de probabilidade**]{style="color:red;"}.
:::

::: fragment

::: {.callout-note}
## Defini√ß√£o

Se $X$ √© vac com fda $F_X(x)$, a sua **fun√ß√£o densidade de probabilidade** (fdp) √© definida por $f_X(x) = \frac{dF_X(x)}{dx}$.
:::

:::

::: fragment

::: {.callout-warning}
## Propriedades

A fdp $f_X(x)$ de uma vac $X$ satisfaz:

::: incremental

1.    $f_X(x) \geq 0$, $x\in \mathbb{R}$;
2.    $\int_{-\infty}^\infty f_X(x)dx = 1$.

:::

:::

:::

## 1.1 Fun√ß√£o de distribui√ß√£o acumulada {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

A fdp √© um modelo te√≥rico para as **densidades** de faixas vistas em estat√≠stica descritiva.
:::

::: fragment

<figure>
  <img src="figs/ilustracao_densidade_fdp.png" style="display: block;margin-left: auto;margin-right: auto;width: 75%;">
</figure>

:::

## 1.1 Fun√ß√£o de distribui√ß√£o acumulada {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Note que o tratamento probabil√≠stico para obter a fda, bem como o seu comportamento, dependem do tipo de va em quest√£o.
:::

::: fragment

::: {.callout-warning}
## Propriedades

Seja $F_X(x)$ fda de uma va $X$, ent√£o

::: incremental

1.    $\lim_{x\to-\infty} F_X(x) = 0$ e $\lim_{x\to\infty} F_X(x) = 1$;
2.    $x < x' \Rightarrow F_X(x) \leq F_X(x')$, isto √©, $F_X(\cdot)$ √© n√£o decrescente; e
3.    se $X$ √© vad, $P(X=x) = F_X(x) - \lim_{x'\uparrow x} F_X(x')$, isto √©, a fmp $p_X(x)$ √© o tamanho do salto de $F_X(\cdot)$ em $x$.
4.    se $X$ √© vac, $f_X(x) = \frac{dF_X(x)}{dx}$, isto √©, a fdp $f_X(x)$ √© a derivada de $F_X(\cdot)$ em $x$.

:::

:::

:::

# Vari√°veis aleat√≥rias discretas

## 2 Vari√°veis aleat√≥rias discretas {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√µes

::: incremental

1. Vimos que, se o modelo probabil√≠stico √© concebido sobre um espa√ßo amostral $\Omega$ abstrato e $X : \Omega \to \mathbb{R}$, ent√£o a fmp pode ser obtida por
$$p_X(x) = P(X = x) = P(A_x),$$
em que $A_x = \{\omega \in \Omega : X(\omega) = x\}$. Isto √©, a fmp de $X$ √© **induzida** pela medida de probabilidade em $\Omega$;
2. Muito frequentemente, a constru√ß√£o de um modelo probabil√≠stico em $\Omega$ √© muito complicada, o que dificultaria a determina√ß√£o da fmp induzida.
3. Para contornar esse problema, levando em considera√ß√£o o comportamento da vad em estudo, podemos especificar diretamente uma fmp para a vad, desde que atenda as propriedades j√° vistas:
    + $p_X(x) \geq 0$;
    + $\sum_{x\in\text{Im}(X)} p_X(x) = 1$.

:::

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 4 {.unnumbered .unlisted}

Suponha que em um estoque existem seis lotes de um produto: tr√™s com $0$ itens defeituosos; dois com $1$ defeituoso; e um com $2$ defeituosos. Um lote ser√° sorteado entre os seis e ser√° enviado a um cliente. Seja $X=$ "n√∫mero de itens defeituosos no lote recebido pelo cliente". [Nesse caso, podemos especificar]{.fragment fragment-index=1}

::: {.fragment fragment-index=1}

::: columns

::: {.column #vcenter width=45%}

<div style="text-align: center;">
<table>
  <tr style="border-top:solid;">
    <td style="border-right:solid 1pt;">$x$</td>
    <td style="text-align: center;">$0$</td>
    <td style="text-align: center;">$1$</td>
    <td style="text-align: center;">$2$</td>
    <td style="text-align: center;border-left:solid 1pt;">Total</td>
  </tr>
  <tr style="border-top:solid 1pt;border-bottom:solid;">
    <td style="border-right:solid 1pt;">$p_X(x)$ </td>
    <td style="text-align: center;">$\frac{3}{6}$</td>
    <td style="text-align: center;">$\frac{2}{6}$</td>
    <td style="text-align: center;">$\frac{1}{6}$</td>
    <td style="text-align: center;border-left:solid 1pt;">$1$</td>
  </tr>
</table>
</div>

:::

::: {.column #vcenter width=10%}

<p style="text-align:center;">
ou ainda
</p>

:::

::: {.column #vcenter width=45%}

<div style="text-align: center;">
<table>
  <tr style="border-top:solid;">
    <td style="border-right:solid 1pt;">$x$</td>
    <td style="text-align: center;">$0$</td>
    <td style="text-align: center;">$1$</td>
    <td style="text-align: center;">$2$</td>
    <td style="text-align: center;border-left:solid 1pt;">Total</td>
  </tr>
  <tr style="border-top:solid 1pt;border-bottom:solid;">
    <td style="border-right:solid 1pt;">$p_X(x)$ </td>
    <td style="text-align: center;">$\frac{1}{2}$</td>
    <td style="text-align: center;">$\frac{1}{3}$</td>
    <td style="text-align: center;">$\frac{1}{6}$</td>
    <td style="text-align: center;border-left:solid 1pt;">$1$</td>
  </tr>
</table>
</div>

:::

:::

:::

::: {.fragment fragment-index=2}

Se n√£o sabemos a quantidade de lotes em estoque, a especifica√ß√£o acima n√£o √© pratic√°vel, pois n√£o sabemos o comportamento probabil√≠stico do experimento ($\Omega$ √© equiprov√°vel, mas desconhecido).

:::

::: {.fragment fragment-index=3}

Nesse caso, se ainda assumirmos que os lotes tem no m√°ximo 2 itens defeituosos, podemos especificar uma fmp arbitr√°ria para a vad $X$, como, por exemplo

<div style="text-align: center;">
<table>
  <tr style="border-top:solid;">
    <td style="border-right:solid 1pt;">$x$</td>
    <td style="text-align: center;">$0$</td>
    <td style="text-align: center;">$1$</td>
    <td style="text-align: center;">$2$</td>
    <td style="text-align: center;border-left:solid 1pt;">Total</td>
  </tr>
  <tr style="border-top:solid 1pt;border-bottom:solid;">
    <td style="border-right:solid 1pt;">$p_X(x)$ </td>
    <td style="text-align: center;">$0.7$</td>
    <td style="text-align: center;">$0.2$</td>
    <td style="text-align: center;">$0.1$</td>
    <td style="text-align: center;border-left:solid 1pt;">$1$</td>
  </tr>
</table>
</div>

:::

::: {.fragment fragment-index=4}

Note que $p_X(0), p_X(1), p_X(2) \geq 0$ e que $\sum_{x=0}^2 p_X(x) = 1$, de modo que $p_X(x)$ √© uma fmp v√°lida.

:::

## 2 Vari√°veis aleat√≥rias discretas {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

No exemplo anterior, especificamos de maneira arbitr√°ria uma fmp $p_X(x)$ para a vad $X$. No entanto, podemos ser mais flex√≠veis e propor uma [**fam√≠lia**]{style="color:red;"} de fmp's que dependa de [**par√¢metros**]{style="color:red;"}.

:::

::: {.fragment fragment-index=1 style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 4 (cont.):** 

Para flexibilizar o nosso modelo probabil√≠stico, podemos especificar a seguinte [**forma**]{style="color:red;"} para a fmp:

::: columns

::: {.column #vcenter width=30%}

<div style="text-align: center;">
<table>
  <tr style="border-top:solid;">
    <td style="border-right:solid 1pt;">$x$</td>
    <td style="text-align: center;">$0$</td>
    <td style="text-align: center;">$1$</td>
    <td style="text-align: center;">$2$</td>
    <td style="text-align: center;border-left:solid 1pt;">Total</td>
  </tr>
  <tr style="border-top:solid 1pt;border-bottom:solid;">
    <td style="border-right:solid 1pt;">$p_X(x)$ </td>
    <td style="text-align: center;">$\alpha$</td>
    <td style="text-align: center;">$\beta$</td>
    <td style="text-align: center;">$\gamma$</td>
    <td style="text-align: center;border-left:solid 1pt;">$1$</td>
  </tr>
</table>
</div>

:::

::: {.column #vcenter width=70%}

::: {.fragment fragment-index=2}

Para $p_X(x)$ ser uma fmp, precisamos impor as seguintes restri√ß√µes:

::: incremental
- $0 \leq \alpha \leq 1$;
- $0 \leq \beta \leq 1-\alpha$; e
- $\gamma = 1-\alpha-\beta$ (isto √©, $\gamma$ √© fixo).
:::

:::

:::

:::

::: fragment

Nesse caso, dizemos que $\alpha$ e $\beta$ s√£o **par√¢metros** (livres) da fam√≠lia de fmp's $p_X(x)$.

:::

::: 

## 2 Vari√°veis aleat√≥rias discretas {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Se a forma de $p_X(x)$ depende de um valor (ou vetor de valores) $\theta$, dizemos que $\theta$ √© um **par√¢metro** (ou vetor param√©trico) da fam√≠lia $p_X(x)$.
:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Nesse caso, podemos escrever $p_X(x; \theta)$ para enfatizar que se trata de uma fam√≠lia de fmp's e que sua forma s√≥ √© completamente conhecida se soubermos o valor do par√¢metro $\theta$ que indexa a fam√≠lia.

:::

:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 4 (cont.):** Nesse exemplo, podemos agrupar os par√¢metros no vetor $\theta = (\alpha, \beta)$. Note que, a fmp induzida pela medida equiprov√°vel em $\Omega$ e a fmp arbitrariamente especificada posteriormente s√£o membros particulares dessa fam√≠lia, em que $\theta = (\frac{1}{2}, \frac{1}{3})$ e $\theta = (0.7, 0.2)$, respectivamente.

:::

## 2 Vari√°veis aleat√≥rias discretas {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Como j√° visto anteriormente, a fda pode ser obtida acumulando as probabilidades da fmp.
:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

::: columns

::: {.column #vcenter width=50%}

**Exemplo 4 (cont.):** A fda para a fam√≠lia de fmp's neste caso √©
$$
F_X(x) = F_X(x; \theta) = \begin{cases}
0, & x < 0;\\
\alpha, & 0\leq x < 1;\\
\alpha + \beta, & 1\leq x < 2;\\
1, & x \geq 2;\\
\end{cases}
$$

:::

::: {.column #vcenter width=50%}

<figure>
  <img src="figs/ilustracao_fda_exemplo4.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;">
</figure>

:::

:::

:::

## 2 Vari√°veis aleat√≥rias discretas {.unnumbered .unlisted}

::: {.callout-tip}
## Exerc√≠cio

Considere a seguinte fun√ß√£o de $x$ que depende de um vetor de par√¢metros $\theta = (\theta_1, \theta_2, \theta_3, \theta_4)$:
$$
p_X(x;\theta) = \begin{cases}
\theta_1, & x=0;\\
\theta_2, & x=1;\\
\theta_3, & x=2;\\
\theta_4, & x=3.
\end{cases}
$$

Pede-se:

1. Quais restri√ß√µes necessitamos impor sobre $\theta = (\theta_1, \theta_2, \theta_3, \theta_4)$ para garantir que $p_X(x;\theta)$ seja de fato fam√≠lia de fmp's?
2. Qual a condi√ß√£o adicional sobre $\theta$ para que $p_X(x;\theta)$ seja sim√©trica? Qual √© o ponto de simetria?
3. Determine e esboce a fda associada a fam√≠lia $p_X(x;\theta)$.
:::


## Esperan√ßa e vari√¢ncia de vad's

::: {.callout-caution}
## Observa√ß√£o

Vimos que a fmp √© um modelo te√≥rico para as frequ√™ncias relativas vistas em estat√≠stica descritiva. Assim, fazendo uso da fmp, √© natural calcularmos valores te√≥ricos para a m√©dia e a vari√¢ncia de uma vad $X$.
:::

::: {.callout-note}
## Defini√ß√£o

Seja $X$ vad com imagem $\text{Im}(X)$ e fmp $p_X(x;\theta)$, sua **m√©dia**, tamb√©m chamada de **esperan√ßa** ou **valor esperado**, √© definida por 
$$\mu = \mu_X = E(X) = \sum_{x\in\text{Im}(X)} x\cdot p_X(x;\theta).$$
:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√µes

::: incremental

1. A f√≥rmula para o c√°lculo de $\mu$ √© muito similar √†quela vista em estat√≠stica descritiva, no entanto, agora a fmp $p_X(x;\theta)$ toma o lugar da frequ√™ncia relativa que teria sido efetivamente observada;
2. De maneira similar a estat√≠stica descritiva, $\mu$ √© calculada como uma m√©dia **ponderada** com pesos dados por $p_X(x;\theta)$;
3. Naturalmente, para fam√≠lias de fmp's, pelo fato de $p_X(x;\theta)$ ser indexada por $\theta$, a sua esperan√ßa tamb√©m ser√° fun√ß√£o de $\theta$.

:::

:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 4 (cont.):** Utilizando a f√≥rmula de esperan√ßa, obtemos
$$\mu_X = 0p_X(0;\theta) + 1p_X(1;\theta) + 2p_X(2;\theta) = \beta + 2(1-\alpha-\beta) = 2-2\alpha - \beta.$$

Se $\alpha = \frac{1-\beta}{2}$, vemos que a fmp √© sim√©trica em torno de $1$ e $\mu_X = 1$.

:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√µes

::: incremental

1. Quando est√° claro a que va $X$ a esperan√ßa se refere, usaremos $\mu$ em vez de $\mu_X$;
2. No Exemplo 4, se hipotetizarmos uma popula√ß√£o em que a vad $X$ com valores $0, 1$ e $2$ associados as frequ√™ncias relativas $\alpha$, $\beta$, $1-\alpha-\beta$, respectivamente, ent√£o $\mu = 2-2\alpha - \beta$ ser√° a m√©dia populacional. Por isso podemos nos referir a $\mu$ por m√©dia populacional ou te√≥rica;
3. No Exemplo 4, tomando $\theta = (\frac{1}{2}, \frac{1}{3})$, obtemos $\mu = 2-2\frac{1}{2} - \frac{1}{3} = \frac{2}{3} \approx 0.67$, que n√£o √© um valor poss√≠vel de $X$. A palavra esperado deve ser interpretada com cautela porque uma pessoa n√£o espera ver um valor de $X = 0.67$ quando um √∫nico estoque √© selecionado.

:::

:::


## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 5:** Seja $X$ o n√∫mero de entrevistas que um estudante faz para conseguir um emprego e suponha que a sua seja $p_X(x) = \frac{k}{x^2}$, $x = 1, 2, 3, \ldots$, e $p_X(x) = 0$ caso contr√°rio. A constante $k$ deve ser tal que $k^{-1} = \sum_{x=1}^\infty\frac{1}{x^2}$. √â poss√≠vel mostrar que $\sum_{x=1}^\infty\frac{1}{x^2} < +\infty$, portanto $p_X(x)$ √© de fato uma fmp.

::: {.fragment fragment-index=1}

Agora, o seu valor esperado √©
$$
\textstyle \mu = \sum_{x=1}^\infty x \cdot p_X(x) = \sum_{x=1}^\infty x\cdot\frac{k}{x^2} = k\sum_{x=1}^\infty \frac{1}{x}.
$$
O √∫ltimo termo √© a soma harm√¥nica, que diverge, isto √©, $\mu = +\infty$.

:::

:::

::: {.fragment fragment-index=2}

::: {.callout-caution}
## Observa√ß√£o

Dizemos que $p_X(x)$ tem **caudas longas** (as probabilidades da cauda decrescem muito lentamente). Ao selecionar uma amostra dessa vari√°vel, a m√©dia amostras tender√° a crescer indefinidamente com o tamanho da amostra.

:::

:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Frequentemente, temos interesse na esperan√ßa de $Y = h(X)$, em vez de $X$. Pela defini√ß√£o poder√≠amos obter $\mu_Y = \sum_y y \cdot p_Y(y)$, necessitando da fmp de $Y$. No entanto, existe uma maneira mais direta.
:::

::: {.fragment fragment-index=1 style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 6:** Seja $X$ vad e $Y = X^2$. [Por exemplo: ]{.fragment fragment-index=2}

::: columns

::: {.column #vcenter width=50%}

::: {.fragment fragment-index=2}
<div style="text-align: center;">
Se a fmp de $X$ for:
<table>
  <tr style="border-top:solid;">
    <td style="border-right:solid 1pt;">$x$</td>
    <td style="text-align: center;">$-2$</td>
    <td style="text-align: center;">$0$</td>
    <td style="text-align: center;">$2$</td>
    <td style="text-align: center;border-left:solid 1pt;">Total</td>
  </tr>
  <tr style="border-top:solid 1pt;border-bottom:solid;">
    <td style="border-right:solid 1pt;">$p_X(x)$ </td>
    <td style="text-align: center;">$p_{-2}$</td>
    <td style="text-align: center;">$p_{0}$</td>
    <td style="text-align: center;">$p_{2}$</td>
    <td style="text-align: center;border-left:solid 1pt;">$1$</td>
  </tr>
</table>
</div>

:::

:::

::: {.column #vcenter width=50%}

::: {.fragment fragment-index=3}

<div style="text-align: center;">
A fmp de $Y$ ser√°:
<table>
  <tr style="border-top:solid;">
    <td style="border-right:solid 1pt;">$x$</td>
    <td style="text-align: center;">$0$</td>
    <td style="text-align: center;">$4$</td>
    <td style="text-align: center;border-left:solid 1pt;">Total</td>
  </tr>
  <tr style="border-top:solid 1pt;border-bottom:solid;">
    <td style="border-right:solid 1pt;">$p_Y(y)$ </td>
    <td style="text-align: center;">$p_{0}$</td>
    <td style="text-align: center;">$p_{-2}+p_{2}$</td>
    <td style="text-align: center;border-left:solid 1pt;">$1$</td>
  </tr>
</table>
</div>

:::

:::

:::

[Logo,
$$\textstyle \mu_Y = \sum_y y\cdot p_Y(y) = 0p_0 + 4(p_{-2} + p_2) = (-2)^2p_{-2} + 0^2p_{0} + 2^2p_{2} = \sum_x h(x)\cdot p_X(x) = E[h(X)].$$
]{.fragment fragment-index=4}

:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Assim, se $X$ for vad com fmp $p_X(x)$ e $Y = h(X)$, ent√£o a esperan√ßa de $Y$ √©
$$\mu_Y = E[h(X)] = \sum_x h(x)\cdot p_X(x).$$
Isto √©, substitu√≠mos os $x$ pelos $h(x)$ no c√°lculo.

:::

::: fragment

::: {.callout-warning}
## Propriedade

Seja $X$ vad com esperan√ßa $\mu_X$ e $Y = aX+b$, com $a, b$ constantes, ent√£o
$$\mu_{Y} = \mu_{aX+b} = E(aX + b) = a E(X) + b = a\mu_X + b.$$
:::

:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

√â verdade que $E(aX + b) = a E(X) + b$. Mas, n√£o necessariamente vale que  $E[h(X)] = h[E(X)]$.

:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 6 (cont.):** Sejam $p_{-2} = p_2 = \frac{1}{4}$ e $p_0 = \frac{1}{2}$. [Ent√£o, temos
$$\textstyle E(X) = -2\frac{1}{4} + 0\frac{1}{2} + 2\frac{1}{4} = 0$$]{.fragment}
[e
$$\textstyle E(X^2) = (-2)^2\frac{1}{4} + 0^2\frac{1}{2} + 2^2\frac{1}{4} = 2.$$]{.fragment}

::: fragment

Assim, $E(X^2) = 2 \neq [E(X)]^2 = 0$.

:::

:::


## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Seja $X$ vad com fmp $p_X(x)$ e esperan√ßa $\mu$. A vari√¢ncia de $X$, denotada por $V(X)$, √© definida por
$$\textstyle V(X) = \sum_{x}(x - \mu)^2\cdot p_X(x) = E[(X - \mu)^2].$$
O desvio padr√£o (DP) de $X$ √© definido por $DP(X) = \sqrt{V(X)}.$ A vari√¢ncia pode ser denotada por $\sigma^2_X$, ou apenas $\sigma^2$, e o DP por $\sigma_X$, ou apenas $\sigma$.

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Note que a vari√¢ncia √© definida como a esperan√ßa de $h(X) = (X-\mu)^2$. Isto √©, quanto **esperamos** que a vari√°vel $X$ se desvie de sua esperan√ßa $\mu$.
:::

:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 6 (cont.):** Suponha agora que $p_2 = \frac{\alpha}{2}$, $p_{-2} = \frac{1-\alpha}{2}$ e $p_0 = \frac{1}{2}$, com $0 < \alpha < 1$. [Ent√£o,
$$\textstyle E(X) = \mu = -2\frac{1-\alpha}{2} + 2\frac{\alpha}{2} = 2\alpha - 1.$$]{.fragment}
[Ent√£o, a vari√¢ncia √© dada por
$$\textstyle V(X) = \sigma^2 = \sum_{x}(x - \mu)^2\cdot p_X(x) = \sum_{x}[x-(2\alpha - 1)]^2 p_X(x).$$]{.fragment}
[Depois de algumas √°lgebras obtemos $\sigma^2_X = 1+4\alpha(1-\alpha)$.]{.fragment}

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

O c√°lculo dos desvios quadr√°ticos $(x-\mu)^2$ para obter $\sigma^2$ pode ser tedioso. Felizmente, temos uma f√≥rmula que pode simplificar a sua determina√ß√£o.

:::

:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: fragment

::: {.callout-warning}
## Propriedades

::: incremental

1. Seja $X$ vad com fmp $p_X(x)$ e esperan√ßa $\mu$. Ent√£o
$$\begin{align*}
\sigma^2 &= \textstyle \sum_{x}(x - \mu)^2\cdot p_X(x) = \sum_{x}(x^2 - 2\mu x + \mu^2)\cdot p_X(x)\\
&= \textstyle \sum_{x}x^2p_X(x) - 2\mu \sum_{x}x p_X(x) + \mu^2 \sum_{x}p_X(x) = E(X^2) - 2\mu\mu + \mu^2 = E(X^2) - \mu^2.
\end{align*}$$
2. Seja $X$ vad com esperan√ßa $\mu_X$ e $Y = aX+b$, com $a, b$ constantes, ent√£o
$$\sigma_{Y}^2 = \sigma_{aX+b}^2 = a^2 \sigma_X^2.$$
:::

:::

:::

::: fragment

::: {.callout-caution}
## Observa√ß√µes

::: incremental
- A Propriedade 1 pode ser utilizada para facilmente se chegar a vari√¢ncia do exemplo anterior;
- A Propriedade 2 mostra que a vari√¢ncia s√≥ √© afetada por mudan√ßas em $a$ (escala), e n√£o em $b$ (loca√ß√£o).
:::

:::

:::

## 2.1 Esperan√ßa e vari√¢ncia de vad's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 7:** Seja $X$ o n√∫mero obtido no arremesso de um dado honesto. Um jogo consiste de voc√™ pagar $Y = \frac{1}{X}$ e receber um pr√™mio de $\frac{1}{\mu_X}$ independente do resultado do dado. [Ser√° que o jogo √© vantajoso para o jogador?]{.fragment fragment-index=1}

[Note que $\mu_X = (1+2+\cdots+6)\frac{1}{6} = 3.5$, de onde vem que o pr√™mio √© sempre $\frac{1}{3.5} \approx 0.2857$.]{.fragment fragment-index=2}

[Por outro lado, temos
$$\textstyle \mu_Y = E(Y) = E(\frac{1}{X}) = (1+\frac{1}{2}+\cdots+\frac{1}{6})\frac{1}{6} = \frac{1}{6}\frac{(60+30+20+15+12+10)}{60} = \frac{147}{360} = 0.4083.$$]{.fragment fragment-index=3}

[Assim, isso significa, em m√©dia, pagar $0.4083$ para jogar um jogo que oferece pr√™mio fixo de $0.2857$.]{.fragment fragment-index=4}

:::

::: fragment

::: {.callout-tip}
## Exerc√≠cios

Qual seria a vari√¢ncia do valor pago?
:::

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 8 {.unnumbered .unlisted}

Uma loja de computadores comprou 3 computadores de certo tipo a R\$ $1000$ cada. Eles ser√£o vendidos a R\$
$1500$ cada. Ap√≥s um per√≠odo, o fabricante aceita os n√£o vendidos por R\$ 400 cada. Seja $X$ o n√∫mero de computadores vendidos e suponha que $p_X(0) = 0.1$, $p_X(1) = 0.2$, $p_X(2)=0.3$ e $p_X(3) = 0.4$. [Note que
$$\mu_X = 0\cdot0.1 + 1\cdot0.2 + 2\cdot0.3 + 3\cdot0.4 = 2$$
e
$$\sigma^2_X = 0^2\cdot0.1 + 1^2\cdot0.2 + 2^2\cdot0.3 + 3^2\cdot0.4 - 2^2 = 0.2 + 4\cdot0.3 + 9\cdot0.4 - 4 = 5 - 4 = 1.$$]{.fragment}

[Por sua vez, o lucro no per√≠odo seria de
$$L = h(X) = 1500X - 3000 + 400(3-X) = 1100X - 1800.$$]{.fragment}

[Logo, o lucro esperado ser√° $\mu_L = 1100\mu_x-1800 = 1100\cdot 2 - 1800 = 400$ e a vari√¢ncia do lucro ser√° de $\sigma_L = 1100^2\sigma^2_X = 1100^2\cdot 1 = 1100^2$. O desvio-padr√£o do lucro √© de $\sigma_L = \sqrt{1100^2} = 1100$.]{.fragment}

## Modelos probabil√≠sticos discretos

::: {.callout-caution}
## Observa√ß√£o

Em muitas situa√ß√µes, lidamos com experimentos cujo resultado √© dicot√¥mico (possui apenas dois resultados) ou pode ser dicotomizado.
:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 9:** Um exerc√≠cio possui 5 alternativas de resposta. Um estudante decide responder o exerc√≠cio aleatoriamente. Duas poss√≠veis formas de escrever o espa√ßo amostral s√£o:

<table>
<tr class=fragment><td>$\Omega = \{a, b, c, d, e\}$</td> <td>(do ponto de vista de todas alternativas poss√≠veis)</td></tr>
<tr class=fragment style="border-bottom:none;"><td>$\Omega = \{s,f\}$</td> <td>(do ponto de vista de se a alternativa est√° correta ($s$) ou errada $f$)</td></tr>
</table>

[Note que o segundo espa√ßo amostral √© escrita de maneira dicotomizada.]{.fragment}
:::

## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Dizemos que um experimento aleat√≥rio √© um experimento de Bernoulli se seu espa√ßo amostral √© dicot√¥mico e pode ser escrito como $\Omega = \{s,f\}$, em que costumamos denominar $s =$ sucesso e $f =$ fracasso. Normalmente, denotamos a probabilidade de sucesso por $P(\{s\}) = p$, $0\leq p\leq 1$.
:::

::: fragment

::: {.callout-note}
## Defini√ß√£o

Num experimento de Bernoulli com $P(\{s\}) = p$, podemos definir a vad
$$X = \begin{cases}
1, & \text{ se } \ \ s;\\
0, & \text{ se } \ \ f.
\end{cases}$$
Nesse caso, dizemos que $X$ tem distribui√ß√£o **Bernoulli** com probabilidade de sucesso $p$ e usamos a nota√ß√£o $X \sim \text{Ber}(p)$.
:::

:::

## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedade

Se $X \sim \text{Ber}(p)$, ent√£o

<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$\mu = E(X) = p$</td> <td>e</td> <td>$\sigma^2 = V(X) = p(1-p).$</td>
  </tr>
</table>

:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 9 (cont.):** Defina a vad $X$ como $X = 1$, se a alternativa est√° correta, e $X = 0$, se a alternativa est√° errada. Ent√£o $X \sim \text{Ber}(p)$, com $p = \frac{1}{5}$.

:::

::: fragment

::: {.callout-caution}
## Observa√ß√µes

::: incremental

1. No Exemplo 9, definimos como sucesso o aluno acertar a quest√£o, mas esse n√£o precisa ser o caso. A classifica√ß√£o do que ser√° entendido como **sucesso** depender√° do problema em quest√£o.
2. O experimento de Bernoulli pode ser utilizado para constru√ß√£o de vad's mais complexas.

:::

:::

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 9 (cont.) {.unnumbered .unlisted}

Se o estudante responde aleatoriamente uma prova com 4 exerc√≠cios de 5 alternativas cada, tratam-se de 4 realiza√ß√µes **independentes** de um experimento de Bernoulli com $P(\{s\}) = p = \frac{1}{5}$. 

::: {.fragment fragment-index=1}

Defina $X =$ "n√∫mero de exerc√≠cios respondidos corretamente". Note que $\text{Im}(X) = \{0,1,2,3,4\}$. A fmp de $X$ √© dada por

<table>
  <tr>
    <td style="border-top:solid;border-bottom:solid;">$\omega$</td>
    <td style="text-align:center;border-top:solid;border-bottom:solid">$X(\omega)$</td>
    <td style="text-align:center;border-top:solid;border-bottom:solid">$P(\{\omega\})$</td>
    <td style="text-align:center;border-top:none;border-bottom:none;visibility:hidden;">$P(X = x)$</td>
  </tr>
  <tr>
    <td>[$(ffff)$]{.fragment fragment-index=2}</td>
    <td style="text-align:center;">[$0$]{.fragment fragment-index=2}</td>
    <td style="text-align:center;">[$p^0(1-p)^4$]{.fragment fragment-index=2}</td>
    <td style="text-align:center;visibility:hidden;">$p^0(1-p)^4$</td>
  </tr>
  <tr>
    <td>[$(sfff)$, $(fsff)$, $(ffsf)$, $(fffs)$]{.fragment fragment-index=3}</td>
    <td style="text-align:center;">[$1$]{.fragment fragment-index=3}</td>
    <td style="text-align:center;">[$p^1(1-p)^3$]{.fragment fragment-index=3}</td>
    <td style="text-align:center;visibility:hidden;">$4p^1(1-p)^3$</td>
  </tr>
  <tr>
    <td>[$(ssff)$, $(sfsf)$, $(sffs)$, $(fssf)$, $(fsfs)$, $(ffss)$]{.fragment fragment-index=4}</td>
    <td style="text-align:center;">[$2$]{.fragment fragment-index=4}</td>
    <td style="text-align:center;">[$p^2(1-p)^2$]{.fragment fragment-index=4}</td>
    <td style="text-align:center;visibility:hidden;">$6p^2(1-p)^2$</td>
  </tr>
  <tr>
    <td>[$(sssf)$, $(ssfs)$, $(sfss)$, $(fsss)$]{.fragment fragment-index=5}</td>
    <td style="text-align:center;">[$3$]{.fragment fragment-index=5}</td>
    <td style="text-align:center;">[$p^3(1-p)^1$]{.fragment fragment-index=5}</td>
    <td style="text-align:center;visibility:hidden;">$4p^3(1-p)^1$</td>
  </tr>
  <tr style="border-bottom:none">
    <td style="border-bottom:solid">[$(ssss)$]{.fragment fragment-index=6}</td>
    <td style="text-align:center;border-bottom:solid">[$4$]{.fragment fragment-index=6}</td>
    <td style="text-align:center;border-bottom:solid">[$p^4(1-p)^0$]{.fragment fragment-index=6}</td>
    <td style="text-align:center;border-bottom:none;visibility:hidden;">$p^4(1-p)^0$</td>
  </tr>
</table>

:::

[Nesse caso, dizemos que $X$ tem distribui√ß√£o **Binomial** com $4$ repeti√ß√µes e probabilidade de sucesso $\frac{1}{5}$.]{style="visibility:hidden"}

## {.unnumbered .unlisted .smaller}

### Exemplo 9 (cont.) {.unnumbered .unlisted}

Se o estudante responde aleatoriamente uma prova com 4 exerc√≠cios de 5 alternativas cada, tratam-se de 4 realiza√ß√µes **independentes** de um experimento de Bernoulli com $P(\{s\}) = p = \frac{1}{5}$. 

Defina $X =$ "n√∫mero de exerc√≠cios respondidos corretamente". Note que $\text{Im}(X) = \{0,1,2,3,4\}$. A fmp de $X$ √© dada por

<table>
  <tr>
    <td style="border-top:solid;border-bottom:solid;">$\omega$</td>
    <td style="text-align:center;border-top:solid;border-bottom:solid">$X(\omega)$</td>
    <td style="text-align:center;border-top:solid;border-bottom:solid">$P(\{\omega\})$</td>
    <td style="text-align:center;border-top:solid;border-bottom:solid;background-color:lightgray;">$P(X = x)$</td>
  </tr>
  <tr>
    <td>$(ffff)$</td>
    <td style="text-align:center;">$0$</td>
    <td style="text-align:center;">$p^0(1-p)^4$</td>
    <td style="text-align:center;background-color:lightgray;">$p^0(1-p)^4$</td>
  </tr>
  <tr>
    <td>$(sfff)$, $(fsff)$, $(ffsf)$, $(fffs)$</td>
    <td style="text-align:center;">$1$</td>
    <td style="text-align:center;">$p^1(1-p)^3$</td>
    <td style="text-align:center;background-color:lightgray;">$4p^1(1-p)^3$</td>
  </tr>
  <tr>
    <td>$(ssff)$, $(sfsf)$, $(sffs)$, $(fssf)$, $(fsfs)$, $(ffss)$</td>
    <td style="text-align:center;">$2$</td>
    <td style="text-align:center;">$p^2(1-p)^2$</td>
    <td style="text-align:center;background-color:lightgray;">$6p^2(1-p)^2$</td>
  </tr>
  <tr>
    <td>$(sssf)$, $(ssfs)$, $(sfss)$, $(fsss)$</td>
    <td style="text-align:center;">$3$</td>
    <td style="text-align:center;">$p^3(1-p)^1$</td>
    <td style="text-align:center;background-color:lightgray;">$4p^3(1-p)^1$</td>
  </tr>
  <tr style="border-bottom:none">
    <td style="border-bottom:solid">$(ssss)$</td>
    <td style="text-align:center;border-bottom:solid">$4$</td>
    <td style="text-align:center;border-bottom:solid">$p^4(1-p)^0$</td>
    <td style="text-align:center;border-bottom:solid;background-color:lightgray;">$p^4(1-p)^0$</td>
  </tr>
</table>

::: fragment

Nesse caso, dizemos que $X$ tem distribui√ß√£o **Binomial** com $4$ repeti√ß√µes e probabilidade de sucesso $\frac{1}{5}$.

:::

## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Considere $n$ repeti√ß√µes independentes de um experimento de Bernoulli com probabilidade de sucesso $p$ e seja $X =$ "n√∫mero de sucessos nas $n$ repeti√ß√µes". Dizemos que $X$ tem distribui√ß√£o **Binomial** com $n$ repeti√ß√µes e probabilidade de sucesso $p$, denotada por $X \sim \text{Bin}(n,p)$. A fmp de $X$ √©
$$p_X(x) = P(X = x) = {n \choose x} p^x (1-p)^{n-x}, \ \ x=0,1,2,\ldots,n.$$
:::

::: {.callout-caution}
## Observa√ß√£o

Note que, se $X_i \sim \text{Ber}(p)$ √© a va Bernoulli associada √† $i$-√©sima repeti√ß√£o, ent√£o podemos escrever $X = \sum_{i=1}^nX_i$. Isto √©, a va Binomial pode ser vista como soma de $n$ va's Bernoulli indendentes com a mesma probabilidade de sucesso.
:::

## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedade

Se $X \sim \text{Bin}(n,p)$, ent√£o

<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$\mu = E(X) = np$</td> <td>e</td> <td>$\sigma^2 = V(X) = np(1-p).$</td>
  </tr>
</table>

:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 9 (cont.):** Como a prova tem $n=4$ quest√µes, cada uma com $5$ alternativas ($p=\frac{1}{5}$), temos que $\mu = E(X) = np = 4 \cdot \frac{1}{5} = 0.8$ e $\sigma^2 = V(X) = np(1-p) = 4 \cdot \frac{1}{5} \cdot \frac{4}{5} = 0.64$. Logo, $\sigma = 0.8$. Portanto, em m√©dia, o estudante acerta menos do que 1 das 4 quest√µes.

::: fragment

A probabilidade de ele acertar mais da metade da prova √©
$$\textstyle P(X > 2) = P(X = 3) + P(X = 4) = {4 \choose 3} (\frac{1}{5})^3 (\frac{4}{5})^{1} + {4 \choose 4} (\frac{1}{5})^4 (\frac{4}{5})^{0} = 0.0256 + 0.0016 = 0.0272.$$

:::

:::

## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

```{r fig.width=10, fig.align='center'}
n <- 20; x <- 0:n; p <- 0.2
par(family = "serif")
plot(x, dbinom(x = x, size = n, prob = p), type='h', xlab='', ylab='', main='', lwd=3)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(p)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = bquote(paste("Bin(",italic(n)==.(n),', ',italic(p)==.(p),")")), side = 3, line = 1.3, cex = 2)
```


## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

```{r fig.width=10, fig.align='center'}
n <- 20; x <- 0:n; p <- 0.5
par(family = "serif")
plot(x, dbinom(x = x, size = n, prob = p), type='h', xlab='', ylab='', main='', lwd=3)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(p)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = bquote(paste("Bin(",italic(n)==.(n),', ',italic(p)==.(p),")")), side = 3, line = 1.3, cex = 2)
```

## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

```{r fig.width=10, fig.align='center'}
n <- 20; x <- 0:n; p <- 0.8
par(family = "serif")
plot(x, dbinom(x = x, size = n, prob = p), type='h', xlab='', ylab='', main='', lwd=3)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(p)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = bquote(paste("Bin(",italic(n)==.(n),', ',italic(p)==.(p),")")), side = 3, line = 1.3, cex = 2)
```


## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 10:** Um lote cont√©m 10 pe√ßas, sendo 3 defeituosas. Ser√£o sorteadas para inspe√ß√£o 4 pe√ßas do lote. Seja $X =$ "n√∫mero de pe√ßas defeituosas na amostra". Se a amostra resulta em no m√°ximo 1 pe√ßa defeituosa, o lote √© classificado como conforme.

Se a sele√ß√£o √© feita [**com reposi√ß√£o**]{style='color:red;'}, ent√£o estamos contando o n√∫mero de sucessos (pe√ßas defeituosas) em 4 repeti√ß√µes independentes de um experimento de Bernoulli. Assim, $X \sim \text{Bin}(n=4, p=\frac{3}{10})$. Logo, a probabilidade do lote ser conforme √©
$$\textstyle P(X \leq 1) = P(X = 0) + P(X = 1) = {4 \choose 0}(\frac{7}{10})^4 + {4 \choose 1}(\frac{3}{10})(\frac{7}{10})^3 = 0.2401 + 0.4116 = 0.6517.$$

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

No Exemplo 10, a distribui√ß√£o Binomial s√≥ foi apropriada para a vari√°vel $X$ pelo fato da sele√ß√£o ser **com reposi√ß√£o**. Como veremos a seguir, $X$ ter√° outra distribui√ß√£o quando a sele√ß√£o √© **sem reposi√ß√£o**.
:::

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 11 {.unnumbered .unlisted}

Uma urna cont√©m $M$ objetos do Tipo 1 e $N-M$ do Tipo 2. Desses, ser√£o selecionados $n$ [**sem reposi√ß√£o**]{style="color:red;"}. Seja $X =$ "objetos do Tipo 1 nos $n$ selecionados". [Vamos determinar $p_X(x) = P(X=x)$.]{.fragment fragment-index=1} [Abaixo s√£o apresentadas a quantidade de maneiras que observamos $x$ objetos do Tipo 1 e $n-x$ do Tipo 2:]{.fragment fragment-index=2}

::: {.fragment fragment-index=2}

<table>
  <tr style='border-top:solid;border-bottom:solid'>
    <td style='border-right:solid 1pt'>Objeto</td>
    <td style='border-right:solid 1pt;text-align:center' colspan=4>Tipo 1</td>
    <td style='text-align:center' colspan=4>Tipo 2</td>
  </tr>
  <tr>
    <td style='border-right:solid 1pt'>Retirada</td>
    <td style='border-right:dotted 1pt;text-align:center'>$1$</td>
    <td style='border-right:dotted 1pt;text-align:center'>$2$</td>
    <td style='border-right:dotted 1pt;text-align:center'>$\cdots$</td>
    <td style='border-right:solid 1pt;text-align:center'>$x$</td>
    <td style='border-right:dotted 1pt;text-align:center'>$x+1$</td>
    <td style='border-right:dotted 1pt;text-align:center'>$x+2$</td>
    <td style='border-right:dotted 1pt;text-align:center'>$\cdots$</td>
    <td style='text-align:center'>$n$</td>
  </tr>
  <tr style='border-top:solid 1pt;border-bottom:solid'>
    <td style='border-right:solid 1pt'>Maneiras</td>
    <td style='border-right:dotted 1pt;text-align:center'>$M$</td>
    <td style='border-right:dotted 1pt;text-align:center'>$M-1$</td>
    <td style='border-right:dotted 1pt;text-align:center'>$\cdots$</td>
    <td style='border-right:solid 1pt;text-align:center'>$M-x+1$</td>
    <td style='border-right:dotted 1pt;text-align:center'>$N-M$</td>
    <td style='border-right:dotted 1pt;text-align:center'>$N-M-1$</td>
    <td style='border-right:dotted 1pt;text-align:center'>$\cdots$</td>
    <td style='text-align:center'>$N-M-n+x+1$</td>
  </tr>
</table>

:::

[Da regra do produto, temos $\frac{M!}{(M-x)!}\frac{(N-M)!}{(N-M-(n-x))!}$.]{.fragment fragment-index=3} [Como a ordem em que os objetos s√£o selecionados n√£o importa, precisamos dividir esse valor pelas $x!$ permuta√ß√µes dos objetos do Tipo 1 e pelas $(n-x)!$ do Tipo 2, resultando em ${M \choose x} {N-M \choose n-x}$ maneiras favor√°veis a $\{X = x\}$.]{.fragment fragment-index=4} [Sem nenhuma restri√ß√£o, obtemos $N(N-1)\cdots(N-n+1) = \frac{N!}{(N-n)!}$.]{.fragment fragment-index=5} [Descontando as $n!$ permuta√ß√µes, h√° ${N \choose n}$ elementos em $\Omega$.]{.fragment fragment-index=6} [Assim,
$$p_X(x) = P(X = x) = \frac{ {M \choose x} {M-M \choose n-x} }{ {N \choose n} }, \ \ \max\{0, n-(N-M)\} \leq x \leq \min\{n,M\}.$$]{.fragment fragment-index=7}

## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Sejam $N$ itens, $M$ do Tipo 1 e $N-M$ do Tipo 2, dos quais $n$ s√£o selecionados **sem reposi√ß√£o**. Seja $X =$ "itens do Tipo 1 na amostra". Dizemos que $X$ tem distribui√ß√£o hipergeom√©trica com par√¢metros $N$ (total), $M$ (itens do Tipo 1) e $n$ (tamanho da amostra) e denotamos por $X \sim \text{Hip}(N,M,n)$. A fmp de $X$ √©
$$p_X(x) = \frac{ {M \choose x} {N-M \choose n-x} }{ {N \choose n} }, \ \ \max\{0, n-(N-M)\} \leq x \leq \min\{n,M\}.$$
:::

::: fragment

::: {.callout-warning}
## Propriedade

Se $X \sim \text{Hip}(N,M,n)$ e $p = \frac{M}{N}$ √© a propor√ß√£o de itens do Tipo 1, ent√£o

<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$\mu = E(X) = np$</td> <td>e</td> <td>$\sigma^2 = V(X) = np(1-p)(\frac{N-n}{N-1}).$</td>
  </tr>
</table>

:::

:::

## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 10 (cont.):** Se a sele√ß√£o fosse realizada [**sem reposi√ß√£o**]{style="color:red;"}, ent√£o $X \sim \text{Hip}(N=10, M=3, n=4)$, logo a probabilidade do lote ser conforme √©
$$P(X \leq 1) = P(X=0) + P(X=1) = \frac{ {3 \choose 0} {7 \choose 4} }{ {10 \choose 4} } + \frac{ {3 \choose 1} {7 \choose 3} }{ {10 \choose 4} } = 0.1667 + 0.5 = 0.6667.$$

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Note o efeito do tipo de sele√ß√£o em algumas caracter√≠sticas da vad $X$:

<table style="margin-bottom: 12pt !important;">
  <tr style='border-top:solid;border-bottom:solid'>
    <td style='border-right:solid 1pt;'>Sele√ß√£o</td>
    <td>$P(X \leq 1)$</td>
    <td>$E(X)$</td>
    <td>$V(X)$</td>
  </tr>
  <tr>
    <td style='border-right:solid 1pt;'>Com reposi√ß√£o</td>
    <td>$0.6517$</td>
    <td>$1.2\ \ [np]$</td>
    <td>$0.84\ \ [np(1-p)]$</td>
  </tr>
  <tr style='border-bottom:solid;'>
    <td style='border-right:solid 1pt;'>Sem reposi√ß√£o</td>
    <td>$0.6667$</td>
    <td>$1.2 \ \ [np]$</td>
    <td>$0.56 \ \ [np(1-p)(\frac{N-n}{N-1})]$</td>
  </tr>
</table>

:::

:::

## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}


```{r fig.width=6, fig.height=4.5, fig.align='center', fig.ncol=2}
M <- 3; N <- 10; n <- 4; x <- 0:n
y1 <- dbinom(x, n, M/N)
y2 <- dhyper(x, M, N-M, n)
MM <- max(y1,y2)
par(family = "serif")
plot(x, y1, type='h', xlab='', ylab='', main='', lwd=3, ylim=c(0,MM))
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(p)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = bquote(paste("Bin(",italic(n)==.(n),', ',italic(p)==.(M/N),")")), side = 3, line = 1.3, cex = 2)
plot(x, y2, type='h', xlab='', ylab='', main='', lwd=3, ylim=c(0,MM))
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(p)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = bquote(paste("Hip(",italic(N)==.(N),', ',italic(M)==.(M),', ',italic(n)==.(n),")")), side = 3, line = 1.3, cex = 2)
```

## {.unnumbered .unlisted .smaller}

### Exemplo 12 {.unnumbered .unlisted}

Um sistema de transa√ß√µes **independentes** possui 3 computadores que operam de modo redundante:

- se o 1¬∫ apresenta falha de transa√ß√£o (com probabilidade $p$), o 2¬∫ entra em opera√ß√£o;
- se o 2¬∫ apresenta falha de transa√ß√£o (com probabilidade $p$), o 3¬∫ entra em opera√ß√£o;
- se o 3¬∫ apresenta falha de transa√ß√£o (com probabilidade $p$), o sistema √© interrompido;

[Tratam-se de repeti√ß√µes independentes de um experimento de Bernoulli com $P(\{s\}) = p$ at√© obter o 3¬∫ sucesso.]{.fragment fragment-index=1} [Seja $X =$ "n√∫mero de transa√ß√µes realizadas". Note que $\text{Im}(X) = \{3,4,\ldots\}$.]{.fragment fragment-index=2} [Veja a seguinte tabela:]{.fragment fragment-index=3}

::: {.fragment fragment-index=3}

<table>
  <tr style="border-top:solid;border-bottom:solid">
    <td style="text-align:left;border-right:solid 1pt;">$\omega$</td>
    <td style="text-align:center;border-right:solid 1pt;">$x$</td>
    <td style="text-align:center;border-right:solid 1pt;">$P(\{\omega\})$</td>
    <td style="text-align:center;">$P(X=x)$</td>
  </tr>
  <tr>
    <td style="text-align:left;border-right:solid 1pt;">$(sss)$</td>
    <td style="text-align:center;border-right:solid 1pt;">$3$</td>
    <td style="text-align:center;border-right:solid 1pt;">$p^3$</td>
    <td style="text-align:center;">$p^3$</td>
  </tr>
  <tr>
    <td style="text-align:left;border-right:solid 1pt;">$(ssfs)$, $(sfss)$, $(fsss)$</td>
    <td style="text-align:center;border-right:solid 1pt;">$4$</td>
    <td style="text-align:center;border-right:solid 1pt;">$(1-p)p^3$</td>
    <td style="text-align:center;">$3(1-p)p^3$</td>
  </tr>
  <tr>
    <td style="text-align:left;border-right:solid 1pt;">$(ssffs)$, $(sfsfs)$, $(fssfs)$, $(sffss)$, $(fsfss)$, $(ffsss)$</td>
    <td style="text-align:center;border-right:solid 1pt;">$5$</td>
    <td style="text-align:center;border-right:solid 1pt;">$(1-p)^2p^3$</td>
    <td style="text-align:center;">$6(1-p)^2p^3$</td>
  </tr>
  <tr style="border-bottom:solid">
    <td style="text-align:left;border-right:solid 1pt;">$\vdots$</td>
    <td style="text-align:center;border-right:solid 1pt;">$\vdots$</td>
    <td style="text-align:center;border-right:solid 1pt;">$\vdots$</td>
    <td style="text-align:center;">$\vdots$</td>
  </tr>
</table>

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 12 (cont.) {.unnumbered .unlisted}

Assim, notando que a √∫ltima repeti√ß√£o tem que ser $s$, um exemplo de $\omega$ favor√°vel a $[X = x]$ √©
$$\omega = (\underbrace{ssff\ldots f}_{x-1}s),$$
cuja probabilidade √© $P(\{\omega\}) = (1-p)^{x-3}p^3$. [Os outros resultados favor√°veis a $[X=x]$ t√™m a mesma probabilidade e s√£o contados verificando de quantas formas podemos posicionar os dois sucessos dentre as primeiras $x-1$ repeti√ß√µes.]{.fragment fragment-index=1} [Para o 1¬∫ $s$, temos $x-1$ posi√ß√µes e, para o 2¬∫ $s$, temos $x-2$ posi√ß√µes.]{.fragment fragment-index=2}

[Pela regra da multiplica√ß√£o ter√≠amos $(x-1)(x-2) = \frac{(x-1)!}{(x-3)!}$ maneiras poss√≠veis.]{.fragment fragment-index=3} [Como a ordem que escolhemos a posi√ß√£o n√£o importa (escolher 1 e 2 √© o mesmo que 2 e 1, por exemplo), precisamos descontar as $2!$ permuta√ß√µes poss√≠veis entre as duas, o que resulta em $\frac{(x-1)!}{2!(x-3)!} = { x-1 \choose 2 }$ maneiras poss√≠veis.]{.fragment fragment-index=4} [Assim
$$P(X = x) = { x-1 \choose 2 } (1-p)^{x-3} p^x, \ \ \ x = 3, 4, 5, \ldots.$$]{.fragment fragment-index=5}

## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Um experimento de Bernoulli com $P(\{s\}) = p$ √© repetido **independentemente** at√© a ocorr√™ncia do $k$-√©simo sucesso. Seja $X =$ "n√∫mero de repeti√ß√µes realizadas". Dizemos que $X$ tem distribui√ß√£o Binomial Negativa com $k$ sucessos e probabilidade de sucesso $p$, denotada por $X \sim \text{BN}(k,p)$. A fmp de $X$ √©
$$p_X(x) = P(X = x) = { x-1 \choose k-1 } (1-p)^{x-k} p^k, \ \ \ x = k, k+1, k+2, \ldots.$$
:::

::: fragment

::: {.callout-warning}
## Propriedade

Se $X \sim \text{BN}(k,p)$, ent√£o

<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$\mu = E(X) = \frac{k}{p}$</td> <td>e</td> <td>$\sigma^2 = V(X) = k\frac{(1-p)}{p^2}.$</td>
  </tr>
</table>
:::

:::

## 2.2 Modelos probabil√≠sticos discretos {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√µes

::: incremental

1. No Exemplo 12, temos que $X \sim \text{BN}(k=3, p)$. Se $p = 0.01$, por exemplo, ter√≠amos $\mu = E(X) = \frac{3}{0.01} = 300$, $\sigma^2 = V(X) = 3\frac{0.99}{0.01^2} = 29700$ e $\sigma \approx 172.34$. Em m√©dia, s√£o realizadas $300$ transa√ß√µes at√© a terceira falha com DP de $172.34$. Al√©m disso, $P(X > \mu) = P(X > 300) \approx 0.4221$;
2. A distribui√ß√£o BN tamb√©m pode ser definida como a distribui√ß√£o do n√∫mero de fracassos (em vez de repeti√ß√µes) at√© o $k$-√©simo sucesso. Nesse caso, sua fmp √©
$$\textstyle p_X(x) = { x + k -1 \choose k-1 } (1-p)^{x} p^k, \ \ \ x = 0, 1, 2, \ldots,$$
e sua esperan√ßa e vari√¢ncia s√£o, respectivamente, $\mu = k\frac{(1-p)}{p}$ e $\sigma^2 = k\frac{(1-p)}{p^2}$;
3. Se $X \sim \text{BN}(k = 1, p)$, dizemos que $X$ tem distribui√ß√£o geom√©trica, cuja nota√ß√£o √© $X \sim \text{Geo}(p)$;
4. Se $X \sim \text{BN}(k, p)$, ent√£o $X = \sum_{j=1}^k X_j$, em que $X_1,\ldots,X_k \sim \text{Geo}(p)$ independentes.
5. Bin: repeti√ß√µes fixas e sucessos aleat√≥rios; BN: sucessos fixos e repeti√ß√µes aleat√≥rias.

:::

:::

# Vari√°veis aleat√≥rias cont√≠nuas

## 3 Vari√°veis aleat√≥rias cont√≠nuas {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Anteriormente, definimos uma vac $X$ como sendo aquelas cuja imagem $\text{Im}(X)$ √© n√£o enumer√°vel. De agora em diante, as vac's ser√£o restringidas √†quelas em que a fda √© [**absolutamente cont√≠nua**]{style="color:red"}.
:::

::: {.callout-note}
## Defini√ß√£o

Diremos que $X$ √© va **cont√≠nua** (vac) se sua imagem $\text{Im}(X)$ √© n√£o enumer√°vel e se sua fda $F_X(x) = P(X \leq x)$ √© **absolutamente cont√≠nua**. Neste caso, podemos escrever
$$F_X(x) = \int_{-\infty}^x f_X(t)dt,$$
em que $f_X(\cdot)$ √© denominada **fun√ß√£o densidade de probabilidade** (fdp).
:::

## 3 Vari√°veis aleat√≥rias cont√≠nuas {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedades
Seja $X$ vac com fda $F_X(\cdot)$ e fdp $f_X(\cdot)$, ent√£o:

::: incremental

1. sua fdp satisfaz:
    + $f_X(\cdot) \geq 0$;
    + $\int_{-\infty}^\infty f_X(x)dx = 1$.
2. a probabilidade do intervalo $(a,b]$, $a<b$, √© dada por
$$\textstyle P(a < X \leq b) = F_X(b) - F_X(a) = \int_a^b f_X(x) dx;$$
3. a probabilidade de um ponto $x$ √© $P(X=x) = 0$;
4. valem as igualdades $P(a < X \leq b) = P(a \leq X \leq b) = P(a \leq X < b) = P(a < X < b)$, sendo que o mesmo n√£o √© v√°lido no caso discreto.

:::

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 13 {.unnumbered .unlisted}

Tempo de avan√ßo √© a diferen√ßa entre o instante em que um carro termina de passar por um ponto e o instante em que o pr√≥ximo carro come√ßa a passar por esse ponto. Seja $X =$ "tempo de avan√ßo para dois carros escolhidos ao acaso". O artigo "*The Statistical Properties of Freeway Traffic*" sugeriu a fdp
$$f_X(x) = 0.15e^{-0.15(x-0.5)} \mathbb{I}(x \geq 0.5) = \begin{cases}
0.15e^{-0.15(x-0.5)}, & x \geq 0.5;\\
0, & x < 0.5,
\end{cases}$$
em que $\mathbb{I}(A) = 1$, se a condi√ß√£o $A$ √© v√°lida, e $\mathbb{I}(A) = 0$, caso contr√°rio.

::: fragment

Note que $f_X(x) \geq 0$ e que $\int_{-\infty}^\infty f_X(x)dx = 1$. Vamos encontrar $P(X > 5)$. Note que
$$P(X > 5) = \int_{5}^\infty f_X(x) dx = \int_{5}^\infty 0.15e^{-0.15(x-0.5)} dx = \left[\left.-e^{-0.15(x-0.5)}\right|_5^\infty\right] = e^{-0.675} \approx 0.5092.$$

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 13 (cont.) {.unnumbered .unlisted}

Veja abaixo a representa√ß√£o da fdp e a da probabilidade $P(X > 5)$:

```{r fig.width=8, fig.height=4.5, fig.align='center'}
MM <- 25
x <- seq(-1,MM,0.01)
y <- as.numeric(x >= 0.5)*0.15*exp(-0.15*(x-0.5))
par(family = "serif", mar=c(5,4,1,2))
plot(x[x<0.5], y[x<0.5], type='n', xlab='', ylab='', main='', lwd=3,
     ylim=range(y)+c(-.1*diff(range(y)),.13*diff(range(y))),
     xlim=range(x)+c(-.02*diff(range(x)),.08*diff(range(x))))
polygon(x=c(5, 5, x[x > 5], MM),
        y=c(0, 0.15*exp(-0.675), y[x > 5], 0), col='lightblue', border=NA)
arrows(y0 = min(y)-.1*diff(range(y)), y1 = max(y)+.13*diff(range(y)), x0=0, x1=0, length = .1)
arrows(x0 = min(x)-.02*diff(range(x)), x1 = max(x)+.08*diff(range(x)), y0=0, y1=0, length = .1)
arrows(x0 = 10, x1 = 15, y0=0.02, y1=0.075, length = .1)
text(x=15, y=.075, labels=expression(italic(P)(italic(X) > 5)%~~%0.5092), pos = 4, cex=1.5)
lines(x[x >= 0.5], y[x >= 0.5], lwd=3)
lines(x[x < 0.5], y[x < 0.5], lwd=3)
lines(c(5, 5), c(0, 0.15*exp(-0.675)), lty=3, lwd=1.5)
lines(c(.5, .5), c(0, 0.15), lty=3, lwd=1.5)
lines(c(.5, .5), c(0, -0.005), lwd=1.5)
text(x=0.5, y=-0.007, labels = '0.5', adj=c(0.3,1), cex=.8)
lines(c(5, 5), c(0, -0.005), lwd=1.5)
text(x=5, y=-0.007, labels = '5', adj=c(0.5,1), cex=.8)
points(x=c(0.5, 0.5), y=c(0, 0.15), pch=c(21,21), bg=c('white','black'))
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
```

## 3 Vari√°veis aleat√≥rias cont√≠nuas {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

√â importante refor√ßar que podemos obter a fdp $f_X(\cdot)$ da fda $F_X(\cdot)$ e vice-versa, por meio de
$$\textstyle f_X(x) = \frac{d}{dx}F_X(x)\ \ \ \ \text{e} \ \ \ \ F_X(x) = \int_{-\infty}^x f_X(t)dt.$$
:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):** No caso, dada a fdp, podemos obter a fda como a antiderivada de $f_X(x)$
[$$\textstyle F_X(x) = \int_{-\infty}^{0.5}0dt + \int_{0.5}^x 0.15e^{-0.15(t-0.5)}dt = 0 + \left[\left.-e^{-0.15(t-0.5)}\right|_{0.5}^x\right] = 1-e^{-0.15(x-0.5)}.$$]{.fragment}
[Agora, a fda pode ser utilizada para obter a probabilidade anterior:
$$\textstyle P(X > 5) = 1- P(X \leq 5) = 1- F_X(5) = 1-[1-e^{-0.15(5-0.5)}] = e^{-0.675} \approx 0.5092.$$]{.fragment}
:::

## 3 Vari√°veis aleat√≥rias cont√≠nuas {.unnumbered .unlisted}


::: {.callout-caution}
## Observa√ß√£o

A inversa de $F_X(x)$ pode ser utilizada para encontrar os quantis.
:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):** Vimos que $F_X(x) = 1-e^{-0.15(x-0.5)}$. Vamos determinar a mediana de $X$, denotada por $\tilde{\mu}_X$. Para $\tilde{\mu}_X$ ser a mediana, devemos ter $F_X(\tilde{\mu}_X) = 0.5$. [Logo
$$1-e^{-0.15(\tilde{\mu}_X-0.5)} = 0.5 \Rightarrow e^{-0.15(\tilde{\mu}_X-0.5)} = 0.5 \Rightarrow \tilde{\mu}_X = 0.5 -\frac{20}{3}\log(0.5) \approx 5.121.$$]{.fragment}
:::

::: fragment

::: {.callout-tip}
## Exerc√≠cio

Encontre o quantil de ordem $p$, denotado por $Q_p$, isto √©, o valor tal que $F_X(Q_p) = p$.
:::

:::

## Esperan√ßa e vari√¢ncia de vac's

::: {.callout-caution}
## Observa√ß√£o

Em Estat√≠stica Descritiva, ao tratar de distribui√ß√µes intervalares, uma aproxima√ß√£o para a m√©dia era
$$\textstyle \bar{x} \approx \sum_{i}x_i^{(m)} f_i = \sum_{i}x_i^{(m)} d_i h_i,$$
em que $x_i^{(m)}$, $f_i$, $d_i$ e $h_i$ s√£o, respectivamente, o ponto m√©dio, a frequ√™ncia relativa, a [**densidade**]{style="color:red"} e o [**comprimento**]{style="color:red"} do intervalo $i$. Como a fdp $f_X(x)$ √© um modelo te√≥rico para as densidades $d_i$ no intervalo de comprimento infinitesimal $dx$ em torno de $x$, isso motiva a seguinte defini√ß√£o de esperan√ßa.
:::

::: fragment

::: {.callout-note}
## Defini√ß√£o

Seja $X$ vac com fdp $f_X(x)$, ent√£o a sua esperan√ßa √© definida por
$$\textstyle \mu = \mu_X = E(X) = \int_{-\infty}^\infty xf_X(x)dx.$$
:::

:::

## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedade

Da mesma forma que no caso discreto, se $X$ √© vac e $Y = h(X)$, ent√£o
$$\textstyle \mu_Y = E(Y) = E[h(X)] = \int_{-\infty}^\infty h(x) f_X(x) dx.$$
:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

A propriedade acima contorna a necessidade de obter $f_Y(y)$ para calcular $\mu_Y$ via $\mu_Y = \int_{-\infty}^\infty y f_Y(y)dy$.
:::

:::

::: fragment

::: {.callout-note}
## Defini√ß√£o

Seja $X$ vac com fdp $f_X(x)$, ent√£o a sua vari√¢ncia √© definida por
$$\textstyle \sigma^2 = \sigma^2_X = V(X) = E[(X-\mu)^2] = \int_{-\infty}^\infty (x-\mu)^2f_X(x)dx.$$
:::

:::

## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedade

Da mesma forma que no caso discreto, se $X$ √© vac, temos a seguinte forma alternativa para a vari√¢ncia:
$$\textstyle \sigma^2 = E(X^2) - \mu^2, \ \ \ \ \  E(X^2) = \int_{-\infty}^\infty x^2 f_X(x) dx.$$
:::

:::fragment

::: {.callout-warning}
## Propriedades

Da mesma forma que no caso discreto, se $X$ √© vac e $a$ e $b$ s√£o constantes, ent√£o:

::: incremental

1. $\mu_{aX+b} = E(aX + b) = aE(X) + b = a\mu_X + b$;
2. $\sigma_{aX+b}^2 = V(aX + b) = a^2V(X) = a^2\sigma_X^2$;
3. $\sigma_{aX+b} = DP(aX + b) = aDP(X) = a\sigma_X$.

:::

:::

:::

## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):**

Vamos calcular $\mu$. [Tomando $s = 0.15(x - 0.5)$, ent√£o $0.15x = s+0.15\cdot0.5$ e $ds = 0.15dx$.]{style='color:white'} [Portanto,]{style='color:white'}
$$\begin{align*}
\color{white}{\mu} &\color{white}{=}{\textstyle \color{white}{\int_{-\infty}^{0.5} x\cdot 0 dx + \int_{0.5}^{\infty} x\cdot 0.15e^{-0.15(x-0.5)} dx}\color{white}{=\int_{0}^\infty (s+0.15\cdot0.5)e^{-s}\frac{ds}{0.15}}}\\
&\color{white}{=}{\textstyle \color{white}{\frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5\int_{0}^\infty e^{-s}ds}\color{white}{= \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5.}}\\
\end{align*}$$

[Na integral ap√≥s a √∫ltima igualdade, fazendo $u = s$ e $dv = e^{-s}ds$, vem que $du=ds$ e $v = -e^{-s}$.]{style='color:white;'} [Logo,]{style='color:white;'}
$${\textstyle\color{white}{\mu = 0.5 + \frac{1}{0.15}\{[-\frac{s}{e^s}|_0^\infty] + \int_0^{\infty}e^{-s}ds\}}\color{white}{= 0.5 + \frac{20}{3}[0 + 1]}\color{white}{= \frac{3 + 40}{6} = \frac{43}{6} \approx 7.1667.}}$$

[Note que obtivemos $\mu = 7.1667 > \tilde\mu = 5.121$, o que reflete a assimetria √† direita da fdp.]{style='color:white;'}

:::

::: {style='visibility:hidden;'}

::: {.callout-tip}
## Exerc√≠cios

Calcule $\sigma^2$ para a vac $X$ do Exemplo 13.
:::

:::


## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):**

Vamos calcular $\mu$. Tomando $s = 0.15(x - 0.5)$, ent√£o $0.15x = s+0.15\cdot0.5$ e $ds = 0.15dx$. [Portanto,]{style='color:white'}
$$\begin{align*}
\color{white}{\mu} &\color{white}{=}{\textstyle \color{white}{\int_{-\infty}^{0.5} x\cdot 0 dx + \int_{0.5}^{\infty} x\cdot 0.15e^{-0.15(x-0.5)} dx}\color{white}{=\int_{0}^\infty (s+0.15\cdot0.5)e^{-s}\frac{ds}{0.15}}}\\
&\color{white}{=}{\textstyle \color{white}{\frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5\int_{0}^\infty e^{-s}ds}\color{white}{= \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5.}}\\
\end{align*}$$

[Na integral ap√≥s a √∫ltima igualdade, fazendo $u = s$ e $dv = e^{-s}ds$, vem que $du=ds$ e $v = -e^{-s}$.]{style='color:white;'} [Logo,]{style='color:white;'}
$${\textstyle\color{white}{\mu = 0.5 + \frac{1}{0.15}\{[-\frac{s}{e^s}|_0^\infty] + \int_0^{\infty}e^{-s}ds\}}\color{white}{= 0.5 + \frac{20}{3}[0 + 1]}\color{white}{= \frac{3 + 40}{6} = \frac{43}{6} \approx 7.1667.}}$$

[Note que obtivemos $\mu = 7.1667 > \tilde\mu = 5.121$, o que reflete a assimetria √† direita da fdp.]{style='color:white;'}

:::

::: {style='visibility:hidden;'}

::: {.callout-tip}
## Exerc√≠cios

Calcule $\sigma^2$ para a vac $X$ do Exemplo 13.
:::

:::



## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):**

Vamos calcular $\mu$. Tomando $s = 0.15(x - 0.5)$, ent√£o $0.15x = s+0.15\cdot0.5$ e $ds = 0.15dx$. Portanto, 
$$\begin{align*}
\mu &={\textstyle \int_{-\infty}^{0.5} x\cdot 0 dx + \int_{0.5}^{\infty} x\cdot 0.15e^{-0.15(x-0.5)} dx\color{white}{=\int_{0}^\infty (s+0.15\cdot0.5)e^{-s}\frac{ds}{0.15}}}\\
&\color{white}{=}{\textstyle \color{white}{\frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5\int_{0}^\infty e^{-s}ds}\color{white}{= \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5.}}\\
\end{align*}$$

[Na integral ap√≥s a √∫ltima igualdade, fazendo $u = s$ e $dv = e^{-s}ds$, vem que $du=ds$ e $v = -e^{-s}$.]{style='color:white;'} [Logo,]{style='color:white;'}
$${\textstyle\color{white}{\mu = 0.5 + \frac{1}{0.15}\{[-\frac{s}{e^s}|_0^\infty] + \int_0^{\infty}e^{-s}ds\}}\color{white}{= 0.5 + \frac{20}{3}[0 + 1]}\color{white}{= \frac{3 + 40}{6} = \frac{43}{6} \approx 7.1667.}}$$

[Note que obtivemos $\mu = 7.1667 > \tilde\mu = 5.121$, o que reflete a assimetria √† direita da fdp.]{style='color:white;'}

:::

::: {style='visibility:hidden;'}

::: {.callout-tip}
## Exerc√≠cios

Calcule $\sigma^2$ para a vac $X$ do Exemplo 13.
:::

:::




## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):**

Vamos calcular $\mu$. Tomando $s = 0.15(x - 0.5)$, ent√£o $0.15x = s+0.15\cdot0.5$ e $ds = 0.15dx$. Portanto, 
$$\begin{align*}
\mu &={\textstyle \int_{-\infty}^{0.5} x\cdot 0 dx + \int_{0.5}^{\infty} x\cdot 0.15e^{-0.15(x-0.5)} dx = \int_{0}^\infty (s+0.15\cdot0.5)e^{-s}\frac{ds}{0.15}}\\
&\color{white}{=}{\textstyle \color{white}{\frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5\int_{0}^\infty e^{-s}ds}\color{white}{= \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5.}}\\
\end{align*}$$

[Na integral ap√≥s a √∫ltima igualdade, fazendo $u = s$ e $dv = e^{-s}ds$, vem que $du=ds$ e $v = -e^{-s}$.]{style='color:white;'} [Logo,]{style='color:white;'}
$${\textstyle\color{white}{\mu = 0.5 + \frac{1}{0.15}\{[-\frac{s}{e^s}|_0^\infty] + \int_0^{\infty}e^{-s}ds\}}\color{white}{= 0.5 + \frac{20}{3}[0 + 1]}\color{white}{= \frac{3 + 40}{6} = \frac{43}{6} \approx 7.1667.}}$$

[Note que obtivemos $\mu = 7.1667 > \tilde\mu = 5.121$, o que reflete a assimetria √† direita da fdp.]{style='color:white;'}

:::

::: {style='visibility:hidden;'}

::: {.callout-tip}
## Exerc√≠cios

Calcule $\sigma^2$ para a vac $X$ do Exemplo 13.
:::

:::



## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):**

Vamos calcular $\mu$. Tomando $s = 0.15(x - 0.5)$, ent√£o $0.15x = s+0.15\cdot0.5$ e $ds = 0.15dx$. Portanto, 
$$\begin{align*}
\mu &={\textstyle \int_{-\infty}^{0.5} x\cdot 0 dx + \int_{0.5}^{\infty} x\cdot 0.15e^{-0.15(x-0.5)} dx = \int_{0}^\infty (s+0.15\cdot0.5)e^{-s}\frac{ds}{0.15}}\\
&={\textstyle \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5\int_{0}^\infty e^{-s}ds\color{white}{= \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5.}}\\
\end{align*}$$

[Na integral ap√≥s a √∫ltima igualdade, fazendo $u = s$ e $dv = e^{-s}ds$, vem que $du=ds$ e $v = -e^{-s}$.]{style='color:white;'} [Logo,]{style='color:white;'}
$${\textstyle\color{white}{\mu = 0.5 + \frac{1}{0.15}\{[-\frac{s}{e^s}|_0^\infty] + \int_0^{\infty}e^{-s}ds\}}\color{white}{= 0.5 + \frac{20}{3}[0 + 1]}\color{white}{= \frac{3 + 40}{6} = \frac{43}{6} \approx 7.1667.}}$$

[Note que obtivemos $\mu = 7.1667 > \tilde\mu = 5.121$, o que reflete a assimetria √† direita da fdp.]{style='color:white;'}

:::

::: {style='visibility:hidden;'}

::: {.callout-tip}
## Exerc√≠cios

Calcule $\sigma^2$ para a vac $X$ do Exemplo 13.
:::

:::



## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):**

Vamos calcular $\mu$. Tomando $s = 0.15(x - 0.5)$, ent√£o $0.15x = s+0.15\cdot0.5$ e $ds = 0.15dx$. Portanto, 
$$\begin{align*}
\mu &={\textstyle \int_{-\infty}^{0.5} x\cdot 0 dx + \int_{0.5}^{\infty} x\cdot 0.15e^{-0.15(x-0.5)} dx = \int_{0}^\infty (s+0.15\cdot0.5)e^{-s}\frac{ds}{0.15}}\\
&={\textstyle \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5\int_{0}^\infty e^{-s}ds = \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5.}\\
\end{align*}$$

[Na integral ap√≥s a √∫ltima igualdade, fazendo $u = s$ e $dv = e^{-s}ds$, vem que $du=ds$ e $v = -e^{-s}$.]{style='color:white;'} [Logo,]{style='color:white;'}
$${\textstyle\color{white}{\mu = 0.5 + \frac{1}{0.15}\{[-\frac{s}{e^s}|_0^\infty] + \int_0^{\infty}e^{-s}ds\}}\color{white}{= 0.5 + \frac{20}{3}[0 + 1]}\color{white}{= \frac{3 + 40}{6} = \frac{43}{6} \approx 7.1667.}}$$

[Note que obtivemos $\mu = 7.1667 > \tilde\mu = 5.121$, o que reflete a assimetria √† direita da fdp.]{style='color:white;'}

:::

::: {style='visibility:hidden;'}

::: {.callout-tip}
## Exerc√≠cios

Calcule $\sigma^2$ para a vac $X$ do Exemplo 13.
:::

:::



## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):**

Vamos calcular $\mu$. Tomando $s = 0.15(x - 0.5)$, ent√£o $0.15x = s+0.15\cdot0.5$ e $ds = 0.15dx$. Portanto, 
$$\begin{align*}
\mu &={\textstyle \int_{-\infty}^{0.5} x\cdot 0 dx + \int_{0.5}^{\infty} x\cdot 0.15e^{-0.15(x-0.5)} dx = \int_{0}^\infty (s+0.15\cdot0.5)e^{-s}\frac{ds}{0.15}}\\
&={\textstyle \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5\int_{0}^\infty e^{-s}ds = \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5.}\\
\end{align*}$$

Na integral ap√≥s a √∫ltima igualdade, fazendo $u = s$ e $dv = e^{-s}ds$, vem que $du=ds$ e $v = -e^{-s}$. [Logo,]{style='color:white;'}
$${\textstyle\color{white}{\mu = 0.5 + \frac{1}{0.15}\{[-\frac{s}{e^s}|_0^\infty] + \int_0^{\infty}e^{-s}ds\}}\color{white}{= 0.5 + \frac{20}{3}[0 + 1]}\color{white}{= \frac{3 + 40}{6} = \frac{43}{6} \approx 7.1667.}}$$

[Note que obtivemos $\mu = 7.1667 > \tilde\mu = 5.121$, o que reflete a assimetria √† direita da fdp.]{style='color:white;'}

:::

::: {style='visibility:hidden;'}

::: {.callout-tip}
## Exerc√≠cios

Calcule $\sigma^2$ para a vac $X$ do Exemplo 13.
:::

:::


## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):**

Vamos calcular $\mu$. Tomando $s = 0.15(x - 0.5)$, ent√£o $0.15x = s+0.15\cdot0.5$ e $ds = 0.15dx$. Portanto, 
$$\begin{align*}
\mu &={\textstyle \int_{-\infty}^{0.5} x\cdot 0 dx + \int_{0.5}^{\infty} x\cdot 0.15e^{-0.15(x-0.5)} dx = \int_{0}^\infty (s+0.15\cdot0.5)e^{-s}\frac{ds}{0.15}}\\
&={\textstyle \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5\int_{0}^\infty e^{-s}ds = \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5.}\\
\end{align*}$$

Na integral ap√≥s a √∫ltima igualdade, fazendo $u = s$ e $dv = e^{-s}ds$, vem que $du=ds$ e $v = -e^{-s}$. Logo
$${\textstyle \mu = 0.5 + \frac{1}{0.15}\{[-\frac{s}{e^s}|_0^\infty] + \int_0^{\infty}e^{-s}ds\}\color{white}{= 0.5 + \frac{20}{3}[0 + 1]}\color{white}{=\frac{3 + 40}{6} = \frac{43}{6} \approx 7.1667.}}$$

[Note que obtivemos $\mu = 7.1667 > \tilde\mu = 5.121$, o que reflete a assimetria √† direita da fdp.]{style='color:white;'}

:::

::: {style='visibility:hidden;'}

::: {.callout-tip}
## Exerc√≠cios

Calcule $\sigma^2$ para a vac $X$ do Exemplo 13.
:::

:::



## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):**

Vamos calcular $\mu$. Tomando $s = 0.15(x - 0.5)$, ent√£o $0.15x = s+0.15\cdot0.5$ e $ds = 0.15dx$. Portanto, 
$$\begin{align*}
\mu &={\textstyle \int_{-\infty}^{0.5} x\cdot 0 dx + \int_{0.5}^{\infty} x\cdot 0.15e^{-0.15(x-0.5)} dx = \int_{0}^\infty (s+0.15\cdot0.5)e^{-s}\frac{ds}{0.15}}\\
&={\textstyle \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5\int_{0}^\infty e^{-s}ds = \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5.}\\
\end{align*}$$

Na integral ap√≥s a √∫ltima igualdade, fazendo $u = s$ e $dv = e^{-s}ds$, vem que $du=ds$ e $v = -e^{-s}$. Logo
$${\textstyle \mu = 0.5 + \frac{1}{0.15}\{[-\frac{s}{e^s}|_0^\infty] + \int_0^{\infty}e^{-s}ds\} = 0.5 + \frac{20}{3}[0 + 1]\color{white}{=\frac{3 + 40}{6} = \frac{43}{6} \approx 7.1667.}}$$

[Note que obtivemos $\mu = 7.1667 > \tilde\mu = 5.121$, o que reflete a assimetria √† direita da fdp.]{style='color:white;'}

:::

::: {style='visibility:hidden;'}

::: {.callout-tip}
## Exerc√≠cios

Calcule $\sigma^2$ para a vac $X$ do Exemplo 13.
:::

:::


## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):**

Vamos calcular $\mu$. Tomando $s = 0.15(x - 0.5)$, ent√£o $0.15x = s+0.15\cdot0.5$ e $ds = 0.15dx$. Portanto, 
$$\begin{align*}
\mu &={\textstyle \int_{-\infty}^{0.5} x\cdot 0 dx + \int_{0.5}^{\infty} x\cdot 0.15e^{-0.15(x-0.5)} dx = \int_{0}^\infty (s+0.15\cdot0.5)e^{-s}\frac{ds}{0.15}}\\
&={\textstyle \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5\int_{0}^\infty e^{-s}ds = \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5.}\\
\end{align*}$$

Na integral ap√≥s a √∫ltima igualdade, fazendo $u = s$ e $dv = e^{-s}ds$, vem que $du=ds$ e $v = -e^{-s}$. Logo
$${\textstyle \mu = 0.5 + \frac{1}{0.15}\{[-\frac{s}{e^s}|_0^\infty] + \int_0^{\infty}e^{-s}ds\} = 0.5 + \frac{20}{3}[0 + 1] = \frac{3 + 40}{6} = \frac{43}{6} \approx 7.1667.}$$

[Note que obtivemos $\mu = 7.1667 > \tilde\mu = 5.121$, o que reflete a assimetria √† direita da fdp.]{style='color:white;'}

:::

::: {style='visibility:hidden;'}

::: {.callout-tip}
## Exerc√≠cios

Calcule $\sigma^2$ para a vac $X$ do Exemplo 13.
:::

:::


## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):**

Vamos calcular $\mu$. Tomando $s = 0.15(x - 0.5)$, ent√£o $0.15x = s+0.15\cdot0.5$ e $ds = 0.15dx$. Portanto, 
$$\begin{align*}
\mu &={\textstyle \int_{-\infty}^{0.5} x\cdot 0 dx + \int_{0.5}^{\infty} x\cdot 0.15e^{-0.15(x-0.5)} dx = \int_{0}^\infty (s+0.15\cdot0.5)e^{-s}\frac{ds}{0.15}}\\
&={\textstyle \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5\int_{0}^\infty e^{-s}ds = \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5.}\\
\end{align*}$$

Na integral ap√≥s a √∫ltima igualdade, fazendo $u = s$ e $dv = e^{-s}ds$, vem que $du=ds$ e $v = -e^{-s}$. Logo
$${\textstyle \mu = 0.5 + \frac{1}{0.15}\{[-\frac{s}{e^s}|_0^\infty] + \int_0^{\infty}e^{-s}ds\} = 0.5 + \frac{20}{3}[0 + 1] = \frac{3 + 40}{6} = \frac{43}{6} \approx 7.1667.}$$

Note que obtivemos $\mu = 7.1667 > \tilde\mu = 5.121$, o que reflete a assimetria √† direita da fdp.

:::

::: {style='visibility:hidden;'}

::: {.callout-tip}
## Exerc√≠cios

Calcule $\sigma^2$ para a vac $X$ do Exemplo 13.
:::

:::


## 3.1 Esperan√ßa e vari√¢ncia de vac's {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 13 (cont.):**

Vamos calcular $\mu$. Tomando $s = 0.15(x - 0.5)$, ent√£o $0.15x = s+0.15\cdot0.5$ e $ds = 0.15dx$. Portanto, 
$$\begin{align*}
\mu &={\textstyle \int_{-\infty}^{0.5} x\cdot 0 dx + \int_{0.5}^{\infty} x\cdot 0.15e^{-0.15(x-0.5)} dx = \int_{0}^\infty (s+0.15\cdot0.5)e^{-s}\frac{ds}{0.15}}\\
&={\textstyle \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5\int_{0}^\infty e^{-s}ds = \frac{1}{0.15}\int_{0}^\infty se^{-s}ds + 0.5.}\\
\end{align*}$$

Na integral ap√≥s a √∫ltima igualdade, fazendo $u = s$ e $dv = e^{-s}ds$, vem que $du=ds$ e $v = -e^{-s}$. Logo
$${\textstyle \mu = 0.5 + \frac{1}{0.15}\{[-\frac{s}{e^s}|_0^\infty] + \int_0^{\infty}e^{-s}ds\} = 0.5 + \frac{20}{3}[0 + 1] = \frac{3 + 40}{6} = \frac{43}{6} \approx 7.1667.}$$

Note que obtivemos $\mu = 7.1667 > \tilde\mu = 5.121$, o que reflete a assimetria √† direita da fdp.

:::

::: {.callout-tip}
## Exerc√≠cios

Calcule $\sigma^2$ para a vac $X$ do Exemplo 13.
:::

## Modelos probabil√≠sticos cont√≠nuos

::: {.callout-caution}
## Observa√ß√£o

Sem d√∫vidas, em termos pr√°ticos, o modelo probabil√≠stico mais importante para vari√°veis aleat√≥rias √© o n normal. Algumas de suas caracter√≠sticas ser√£o discutidas mais adiante.
:::

::: {.callout-note}
## Defini√ß√£o

Seja $X$ vac. Dizemos que $X$ tem distribui√ß√£o normal com m√©dia $\mu$ e vari√¢ncia $\sigma^2$ e escrevemos $X \sim \text{N}(\mu,\sigma^2)$ se sua fdp for dada por
$$f_X(x) = f_X(x; \mu,\sigma) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}, \ \ \ \ \ \ -\infty <x < \infty, \ \ -\infty < \mu < \infty, \ \ \sigma^2 > 0.$$
:::


## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

```{r fig.width=8, fig.height=4.5, fig.align='center'}
MM <- 25
x <- seq(-5,5,0.01)
mu1 <- 0
mu2 <- 1
s2_1 <- 1
s2_2 <- 3
y1 <- dnorm(x = x, mean = mu1, sd = sqrt(s2_1))
y2 <- dnorm(x = x, mean = mu2, sd = sqrt(s2_1))
y3 <- dnorm(x = x, mean = mu1, sd = sqrt(s2_2))
M_y <- max(y1, y2, y3)

par(family = "serif", mar=c(5,4,1,2))
plot(x, y1, type='n', xlab='', ylab='', main='', lwd=3,
     ylim=c(0, M_y))
lines(x, y1, lwd=2)
lines(x, y2, lwd=2, col='blue')
lines(x, y3, lwd=2, col='red')
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
legend('topleft',
       legend = as.expression(list(
         bquote(paste("N(",italic(mu)==.(mu1),', ',italic(sigma)^2==.(s2_1),")")),
         bquote(paste("N(",italic(mu)==.(mu2),', ',italic(sigma)^2==.(s2_1),")")),
         bquote(paste("N(",italic(mu)==.(mu1),', ',italic(sigma)^2==.(s2_2),")")))),
       col = c('black','blue','red'), lty=1, lwd=2
       )
lines(x=c(mu1,mu1), y=c(.07*M_y, M_y), lty=3, lwd=1.5)
text(x = mu1, y=.06*M_y, labels=bquote(italic(mu)==.(mu1)), pos=1)
lines(x=c(mu2,mu2), y=c(.07*M_y, M_y), lty=3, lwd=1.5, col='blue')
text(x = mu2, y=.06*M_y, labels=bquote(italic(mu)==.(mu2)), pos=1, col='blue')
```

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedade

Se $X \sim \text{N}(\mu, \sigma^2)$, ent√£o
<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$E(X) = \mu$</td> <td>e</td> <td>$V(X) = \sigma^2.$</td>
  </tr>
</table>
:::

::: fragment

::: {.callout-caution}
## Observa√ß√µes
Se $X \sim \text{N}(\mu, \sigma^2)$, ent√£o:

::: incremental

1. a sua fdp √© completamente especificada por sua m√©dia $\mu$ e sua vari√¢ncia $\sigma$;
2. √© √≥bvio que, $f_X(x) \geq 0$, mas a demonstra√ß√£o que $\int_{-\infty}^\infty f_X(x)dx = 1$ requer t√©cnicas de integra√ß√£o via coordenadas polares;
3. a opera√ß√£o definida por $Z = \frac{X - \mu}{\sigma}$ √© denominada [**padroniza√ß√£o**]{style='color:red;'} de $X$ e podemos mostrar que $Z \sim \text{N}(0,1)$, caso em que dizemos que $Z$ tem distribui√ß√£o [**normal padr√£o**]{style='color:red;'}.

:::

:::

:::


## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√µes

Se $X \sim \text{N}(\mu, \sigma^2)$, ent√£o:

::: incremental

1. a probabilidade intervalar $P(a < X \leq b)$ deveria ser obtida por
$${\textstyle P(a < X \leq b) = \int_a^b \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}} dx},$$
que n√£o possui solu√ß√£o anal√≠tica, exceto se $a = -\infty$ e $b = \infty$;
2. poder√≠amos, a princ√≠pio, utilizar m√©todos num√©ricos para obt√™-la, mas para cada $\mu$ e $\sigma^2$ diferentes precisar√≠amos executar o c√≥digo novamente;
3. podemos utilizar a **padroniza√ß√£o** para constatar que
$${\textstyle P(a < X \leq b) = P(\frac{a-\mu}{\sigma} < \frac{X-\mu}{\sigma} \leq \frac{b-\mu}{\sigma}) = P(\frac{a-\mu}{\sigma} < Z \leq \frac{b-\mu}{\sigma})}.$$

:::

:::

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 14:** Seja $X =$ "tempo de rea√ß√£o de um motorista √†s luzes de freio do carro a frente". Um artigo na *Ergonomics* (1993, p. 391-395) sugere que $X \sim \text{N}(1.25, 0.46^2)$. [Determinemos $P(1 \leq X \leq 1.75)$:
$$
\begin{align*}
P(1 \leq X \leq 1.75) &= {\textstyle P(\frac{1-\mu}{\sigma} \leq \frac{X-\mu}{\sigma} \leq \frac{1.75-\mu}{\sigma}) = P(\frac{1-1.25}{0.46} \leq Z \leq \frac{1.75-1.25}{0.46})}\\
&= {\textstyle P(-0.54 \leq Z \leq 1.09) = P(Z \leq 1.09) - P(Z \leq -0.54)}\\
&= {\textstyle \Phi(1.09) - \Phi(-0.54),}
\end{align*}
$$
em que $\Phi(z) = P(Z \leq z)$ √© uma nota√ß√£o especial para representar a fda da normal padr√£o $Z$.]{.fragment}
::: 

::: fragment

::: {.callout-caution}
## Observa√ß√µes

::: incremental

1. Note que passamos de um problema de calcular as probabilidades com respeito a $X \sim \text{N}(\mu, \sigma^2)$, com $\mu$ e $\sigma^2$ quaisquer, para as probabilidades de uma **normal padr√£o** $Z \sim \text{N}(0,1)$;
2. As probabilidades para $Z \sim \text{N}(0,1)$ tamb√©m n√£o tem solu√ß√£o anal√≠tica, mas m√©todos num√©ricos foram utilizados para computar e tabelar $\Phi(z)$ para diversos valores de $z$.

:::

:::

:::

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

```{r fig.width=8, fig.height=4.5, fig.align='center'}
x <- seq(-5,5,0.01)
mu <- 0;s2 <- 1
z <- -1.5
y <- dnorm(x = x, mean = mu1, sd = sqrt(s2_1))
M_y <- max(y); M_x <- max(x)
par(family = "serif", mar=c(5,4,1,2))
plot(x, y, type='n', xlab='', ylab='', main='', ylim=c(-.09*M_y, 1.07*M_y),
     xlim=c(min(x)-.02*diff(range(x)), max(x)+.04*diff(range(x))))
polygon(x=c(x[1], x[x < z], z, z),
        y=c(0, y[x < z], dnorm(z, mu, sqrt(s2)), 0), col='lightblue', border=NA)
arrows(y0 = -.09*M_y, y1 = 1.07*M_y, x0=0, x1=0, length = .1, lwd=2, col='darkgray')
arrows(y0 = 0, y1 = 0, x0=min(x)-.02*diff(range(x)), x1=max(x)+.04*diff(range(x)), length = .1, lwd=2, col='darkgray')
lines(x, y, lwd=3)
lines(x=c(z, z), y=c(0, dnorm(z, mu, sqrt(s2))), lwd=2)
lines(x=c(z, z), y=c(0, -.025*M_y), lwd=2)
text(x = z, y=-.02*M_y, labels=bquote(italic(z)==.(z)), pos=1)
arrows(x0 = -2, x1 = -3, y0 = dnorm(-2)/2, y1=.2, length=.07)
text(x=-3, y=.2, labels=bquote(Phi*"("*italic(z)*")"%~~%.(round(pnorm(z), 4))), pos=3)
mtext(text = expression(italic(z)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(Z)]*"("*italic(z)*")"), side = 2, line = 2, cex=1.5)
```

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

<figure>
  <img src="figs/fig_normal_padrao1.png" style="display: block;margin-left: auto;margin-right: auto;width: 70%;">
</figure>

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

<figure>
  <img src="figs/fig_normal_padrao2.png" style="display: block;margin-left: auto;margin-right: auto;width: 70%;">
</figure>


## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

<figure>
  <img src="figs/fig_normal_padrao3.png" style="display: block;margin-left: auto;margin-right: auto;width: 70%;">
</figure>

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

```{r fig.width=8, fig.height=4.5, fig.align='center'}
x <- seq(-5,5,0.01)
mu <- 0;s2 <- 1
z <- 1.5
y <- dnorm(x = x, mean = mu1, sd = sqrt(s2_1))
M_y <- max(y); M_x <- max(x)
par(family = "serif", mar=c(5,4,1,2))
plot(x, y, type='n', xlab='', ylab='', main='', ylim=c(-.09*M_y, 1.07*M_y),
     xlim=c(min(x)-.02*diff(range(x)), max(x)+.04*diff(range(x))))
polygon(x=c(x[1], x[x < z], z, z),
        y=c(0, y[x < z], dnorm(z, mu, sqrt(s2)), 0), col='lightblue', border=NA)
arrows(y0 = -.09*M_y, y1 = 1.07*M_y, x0=0, x1=0, length = .1, lwd=2, col='darkgray')
arrows(y0 = 0, y1 = 0, x0=min(x)-.02*diff(range(x)), x1=max(x)+.04*diff(range(x)), length = .1, lwd=2, col='darkgray')
lines(x, y, lwd=3)
lines(x=c(z, z), y=c(0, dnorm(z, mu, sqrt(s2))), lwd=2)
lines(x=c(z, z), y=c(0, -.025*M_y), lwd=2)
text(x = z, y=-.02*M_y, labels=bquote(italic(z)==.(z)), pos=1)
arrows(x0 = -2, x1 = -3, y0 = dnorm(-2)/2, y1=.2, length=.07)
text(x=-3, y=.2, labels=bquote(Phi*"("*italic(z)*")"%~~%.(round(pnorm(z), 4))), pos=3)
mtext(text = expression(italic(z)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(Z)]*"("*italic(z)*")"), side = 2, line = 2, cex=1.5)
```

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

<figure>
  <img src="figs/fig_normal_padrao2_1.png" style="display: block;margin-left: auto;margin-right: auto;width: 70%;">
</figure>

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

<figure>
  <img src="figs/fig_normal_padrao2_2.png" style="display: block;margin-left: auto;margin-right: auto;width: 70%;">
</figure>


## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

<figure>
  <img src="figs/fig_normal_padrao2_3.png" style="display: block;margin-left: auto;margin-right: auto;width: 70%;">
</figure>

## {.unnumbered .unlisted .smaller}

### Exemplo 14 (cont.) {.unnumbered .unlisted}

Vimos que $P(1 \leq X \leq 1.75) = P(-0.54 \leq Z \leq 1.09) = \Phi(1.09) - \Phi(-0.54)$. [Consultando a tabela da normal padr√£o, temos]{.fragment fragment-intex=1}

::: columns

::: {.column #vcenter width=50%}

::: {.fragment fragment-intex=2}

<figure>
  <img src="figs/figura_normal_padrao_ex14_1.png" style="display: block;margin-left: auto;margin-right: auto;width: 95%;">
  <figcaption style='text-align:center'>$\Phi(-0.54) = 0.2946$</figcaption>
</figure>

:::

:::

::: {.column #vcenter width=50%}

::: {.fragment fragment-intex=3}

<figure>
  <img src="figs/figura_normal_padrao_ex14_2.png" style="display: block;margin-left: auto;margin-right: auto;width: 95%;">
  <figcaption style='text-align:center'>$\Phi(1.09) = 0.8621$</figcaption>
</figure>

:::

:::

:::

[Assim,
$$P(1 \leq X \leq 1.75) = P(-0.54 \leq Z \leq 1.09) = \Phi(1.09) - \Phi(-0.54) = 0.8621 - 0.2946 = 0.5675.$$]{.fragment fragment-intex=4}


## {.unnumbered .unlisted .smaller}

### Exemplo 14 (cont.) {.unnumbered .unlisted}

Suponha que desejamos $P(X > 1.75)$. [Utilizando a padroniza√ß√£o, temos
$${\textstyle P(X > 1.75) = P(\frac{X-\mu}{\sigma} > \frac{1.75-1.25}{0.46}) = P(Z > 1.09) = 1 - P(Z \leq 1.09) = 1 - \Phi(1.09).}$$]{.fragment fragment-intex=1}

::: columns

::: {.column #vcenter width=60%}

::: {.fragment fragment-intex=2}

Consultando a tabela da normal padr√£o, temos

<figure>
  <img src="figs/figura_normal_padrao_ex14_2.png" style="display: block;margin-left: auto;margin-right: auto;width: 99%;">
  <figcaption style='text-align:center'>$\Phi(1.09) = 0.8621$</figcaption>
</figure>

:::

:::

::: {.column #vcenter width=40%}

::: {.fragment fragment-intex=3}

Logo,
$$\begin{align*}
P(X > 1.75) &= 1 - \Phi(1.09)\\
&= 1 - 0.8621\\
&= 0.1379.
\end{align*}$$

:::

:::

:::

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Muitas vezes, √© necess√°rio determinar o quantil de ordem $p$ da va $X$, denotado por $Q_{X,p}$, cuja defini√ß√£o √© $P(X \leq Q_{X,p}) = p$. Vejas as Figuras abaixo.
:::

::: {style='visibility:hidden'}

```{r fig.width=8, fig.height=4.5, fig.align='center'}
x <- seq(-.5,3,0.01)
a <- 2;b <- 3
p <- 0.5
q_p <- qgamma(p=p, shape = a,rate = b)
y <- dgamma(x = x, shape = a,rate = b)
M_y <- max(y); M_x <- max(x)
par(family = "serif", mar=c(5,4,1,2))
plot(x, y, type='n', xlab='', ylab='', main='', ylim=c(-.09*M_y, 1.07*M_y),
     xlim=c(min(x)-.02*diff(range(x)), max(x)+.04*diff(range(x))))
polygon(x=c(x[1], x[x < q_p], q_p, q_p),
        y=c(0, y[x < q_p], dgamma(x = q_p, shape = a,rate = b), 0), col='lightblue', border=NA)
arrows(y0 = -.09*M_y, y1 = 1.07*M_y, x0=0, x1=0, length = .1, lwd=2, col='darkgray')
arrows(y0 = 0, y1 = 0, x0=min(x)-.02*diff(range(x)), x1=max(x)+.04*diff(range(x)), length = .1, lwd=2, col='darkgray')
lines(x, y, lwd=3)
lines(x=c(q_p, q_p), y=c(0, dgamma(x = q_p, shape = a,rate = b)), lwd=2)
lines(x=c(q_p, q_p), y=c(0, -.025*M_y), lwd=2)
text(x = q_p, y=-.02*M_y, labels=bquote(italic(Q[X*","*p])==.(round(q_p, 4))), pos=1)
arrows(x0 = q_p/2, x1 = 1.5, y0 = dgamma(x = q_p, shape = a,rate = b)/2, y1=.6, length=.07)
text(x=1.5, y=.6, labels=bquote(italic(P)*"("*italic(X)<=italic(Q[X*","*p])*") = "*italic(F[X])*"("*italic(Q[X*","*p])*") = "*.(round(p, 4))), pos=4)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
legend('topright', legend=bquote(italic(p) == .(p)), fill = 'lightblue')
```

:::

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Muitas vezes, √© necess√°rio determinar o quantil de ordem $p$ da va $X$, denotado por $Q_{X,p}$, cuja defini√ß√£o √© $P(X \leq Q_{X,p}) = p$. Vejas as Figuras abaixo.
:::


```{r fig.width=8, fig.height=4.5, fig.align='center'}
x <- seq(-.5,3,0.01)
a <- 2;b <- 3
p <- 0.5
q_p <- qgamma(p=p, shape = a,rate = b)
y <- dgamma(x = x, shape = a,rate = b)
M_y <- max(y); M_x <- max(x)
par(family = "serif", mar=c(5,4,1,2))
plot(x, y, type='n', xlab='', ylab='', main='', ylim=c(-.09*M_y, 1.07*M_y),
     xlim=c(min(x)-.02*diff(range(x)), max(x)+.04*diff(range(x))))
polygon(x=c(x[1], x[x < q_p], q_p, q_p),
        y=c(0, y[x < q_p], dgamma(x = q_p, shape = a,rate = b), 0), col='lightblue', border=NA)
arrows(y0 = -.09*M_y, y1 = 1.07*M_y, x0=0, x1=0, length = .1, lwd=2, col='darkgray')
arrows(y0 = 0, y1 = 0, x0=min(x)-.02*diff(range(x)), x1=max(x)+.04*diff(range(x)), length = .1, lwd=2, col='darkgray')
lines(x, y, lwd=3)
lines(x=c(q_p, q_p), y=c(0, dgamma(x = q_p, shape = a,rate = b)), lwd=2)
lines(x=c(q_p, q_p), y=c(0, -.025*M_y), lwd=2)
text(x = q_p, y=-.02*M_y, labels=bquote(italic(Q[X*","*p])==.(round(q_p, 4))), pos=1)
arrows(x0 = q_p/2, x1 = 1.5, y0 = dgamma(x = q_p, shape = a,rate = b)/2, y1=.6, length=.07)
text(x=1.5, y=.6, labels=bquote(italic(P)*"("*italic(X)<=italic(Q[X*","*p])*") = "*italic(F[X])*"("*italic(Q[X*","*p])*") = "*.(round(p, 4))), pos=4)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
legend('topright', legend=bquote(italic(p) == .(p)), fill = 'lightblue')
```

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Muitas vezes, √© necess√°rio determinar o quantil de ordem $p$ da va $X$, denotado por $Q_{X,p}$, cuja defini√ß√£o √© $P(X \leq Q_{X,p}) = p$. Vejas as Figuras abaixo.
:::


```{r fig.width=8, fig.height=4.5, fig.align='center'}
x <- seq(-.5,3,0.01)
a <- 2;b <- 3
p <- 0.7
q_p <- qgamma(p=p, shape = a,rate = b)
y <- dgamma(x = x, shape = a,rate = b)
M_y <- max(y); M_x <- max(x)
par(family = "serif", mar=c(5,4,1,2))
plot(x, y, type='n', xlab='', ylab='', main='', ylim=c(-.09*M_y, 1.07*M_y),
     xlim=c(min(x)-.02*diff(range(x)), max(x)+.04*diff(range(x))))
polygon(x=c(x[1], x[x < q_p], q_p, q_p),
        y=c(0, y[x < q_p], dgamma(x = q_p, shape = a,rate = b), 0), col='lightblue', border=NA)
arrows(y0 = -.09*M_y, y1 = 1.07*M_y, x0=0, x1=0, length = .1, lwd=2, col='darkgray')
arrows(y0 = 0, y1 = 0, x0=min(x)-.02*diff(range(x)), x1=max(x)+.04*diff(range(x)), length = .1, lwd=2, col='darkgray')
lines(x, y, lwd=3)
lines(x=c(q_p, q_p), y=c(0, dgamma(x = q_p, shape = a,rate = b)), lwd=2)
lines(x=c(q_p, q_p), y=c(0, -.025*M_y), lwd=2)
text(x = q_p, y=-.02*M_y, labels=bquote(italic(Q[X*","*p])==.(round(q_p, 4))), pos=1)
arrows(x0 = q_p/2, x1 = 1.5, y0 = dgamma(x = q_p, shape = a,rate = b)/2, y1=.6, length=.07)
text(x=1.5, y=.6, labels=bquote(italic(P)*"("*italic(X)<=italic(Q[X*","*p])*") = "*italic(F[X])*"("*italic(Q[X*","*p])*") = "*.(round(p, 4))), pos=4)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
legend('topright', legend=bquote(italic(p) == .(p)), fill = 'lightblue')
```


## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Muitas vezes, √© necess√°rio determinar o quantil de ordem $p$ da va $X$, denotado por $Q_{X,p}$, cuja defini√ß√£o √© $P(X \leq Q_{X,p}) = p$. Vejas as Figuras abaixo.
:::


```{r fig.width=8, fig.height=4.5, fig.align='center'}
x <- seq(-.5,3,0.01)
a <- 2;b <- 3
p <- 0.9
q_p <- qgamma(p=p, shape = a,rate = b)
y <- dgamma(x = x, shape = a,rate = b)
M_y <- max(y); M_x <- max(x)
par(family = "serif", mar=c(5,4,1,2))
plot(x, y, type='n', xlab='', ylab='', main='', ylim=c(-.09*M_y, 1.07*M_y),
     xlim=c(min(x)-.02*diff(range(x)), max(x)+.04*diff(range(x))))
polygon(x=c(x[1], x[x < q_p], q_p, q_p),
        y=c(0, y[x < q_p], dgamma(x = q_p, shape = a,rate = b), 0), col='lightblue', border=NA)
arrows(y0 = -.09*M_y, y1 = 1.07*M_y, x0=0, x1=0, length = .1, lwd=2, col='darkgray')
arrows(y0 = 0, y1 = 0, x0=min(x)-.02*diff(range(x)), x1=max(x)+.04*diff(range(x)), length = .1, lwd=2, col='darkgray')
lines(x, y, lwd=3)
lines(x=c(q_p, q_p), y=c(0, dgamma(x = q_p, shape = a,rate = b)), lwd=2)
lines(x=c(q_p, q_p), y=c(0, -.025*M_y), lwd=2)
text(x = q_p, y=-.02*M_y, labels=bquote(italic(Q[X*","*p])==.(round(q_p, 4))), pos=1)
arrows(x0 = q_p/2, x1 = 1.5, y0 = dgamma(x = q_p, shape = a,rate = b)/2, y1=.6, length=.07)
text(x=1.5, y=.6, labels=bquote(italic(P)*"("*italic(X)<=italic(Q[X*","*p])*") = "*italic(F[X])*"("*italic(Q[X*","*p])*") = "*.(round(p, 4))), pos=4)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
legend('topright', legend=bquote(italic(p) == .(p)), fill = 'lightblue')
```

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 14 (cont.):** Suponha que desejamos encontrar o valor que corresponde ao tempo de rea√ß√£o dos $70\%$ motoristas que reagem mais rapidamente. Na verdade, estamos interessados no quantil de ordem $p=0.7$, isto √©, $Q_{X,0.7}$. Para encontrarmos, note que
$${\textstyle 0.7 = P(X \leq Q_{X,0.7}) = P(\frac{X - \mu}{\sigma} \leq \frac{Q_{X,0.7} - \mu}{\sigma})} = P(Z \leq Q_{Z,0.7}),$$
em que $Q_{Z,0.7} = \frac{Q_{X,0.7} - \mu}{\sigma} = \frac{Q_{X,0.7} - 1.25}{0.46}$, ou ainda, $Q_{X,0.7} = 1.25 + 0.46 Q_{Z,0.7}$.

:::

::: {.callout-caution}
## Observa√ß√£o

Note que, novamente, o problema passa do quantil de uma normal qualquer para o quantil de uma normal padr√£o. Para encontrar $Q_{Z,0.7}$, necessitamos consultar a tabela normal padr√£o de maneira inversa.

:::

## {.unnumbered .unlisted .smaller}

### Exemplo 14 (cont.) {.unnumbered .unlisted}

<figure>
  <img src="figs/figura_normal_padrao_ex14_2_1.png" style="display: block;margin-left: auto;margin-right: auto;width: 80%;">
</figure>

## {.unnumbered .unlisted .smaller}

### Exemplo 14 (cont.) {.unnumbered .unlisted}

<figure>
  <img src="figs/figura_normal_padrao_ex14_2_2.png" style="display: block;margin-left: auto;margin-right: auto;width: 80%;">
</figure>

## {.unnumbered .unlisted .smaller}

### Exemplo 14 (cont.) {.unnumbered .unlisted}

<figure>
  <img src="figs/figura_normal_padrao_ex14_2_3.png" style="display: block;margin-left: auto;margin-right: auto;width: 80%;">
</figure>

[Assim, conclu√≠mos que $0.52 < Q_{Z,0.7} < 0.53$. Podemos usar interpola√ß√£o para aproximar $Q_{Z, 0.7}$.]{.fragment fragment-index=1} [Note que $Q_{Z,0.6985} = 0.52$ e $Q_{Z,0.7019} = 0.53$.]{.fragment fragment-index=2} [Agora, admitindo que $Q_{Z,p}$ tem uma rela√ß√£o aproximadamente linear para $0.6985 \leq p \leq 0.7019$, temos que $Q_{Z,p} = a+bp$, com as restri√ß√µes]{.fragment fragment-index=3}

:::{.fragment fragment-index=3}

<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$0.52 = a+0.6985b$</td> <td>([**Eq. 1**]{style='color:red;'})</td> <td></td> <td></td> <td>e</td> <td></td> <td></td> <td>$0.53 = a+0.7019b$.</td> <td>([**Eq. 2**]{style='color:red;'})</td>
  </tr>
</table>

:::

[Pela 1¬™ equa√ß√£o, $a = 0.52 - 0.6985b$.]{.fragment fragment-index=4} [Substituindo na 2¬™ equa√ß√£o, vem $b = \frac{0.53 - 0.52}{0.7019 - 0.6985} \approx 2.9412$.]{.fragment fragment-index=5} [Retornando na 1¬™ equa√ß√£o, temos $a = 0.52 - 0.6985\cdot 2.9412 \approx -1.5344$.]{.fragment fragment-index=6} [Finalmente, temos
$$Q_{Z,0.7} = a+0.7b = -1.5344 + 0.7 \cdot 2.9412 \approx 0.5244 \color{white}{\Rightarrow Q_{X,0.7} = 1.25 + 0.46 Q_{Z,0.7} = 1.4912.}$$]{.fragment fragment-index=7}


## {.unnumbered .unlisted .smaller}

### Exemplo 14 (cont.) {.unnumbered .unlisted}

<figure>
  <img src="figs/figura_normal_padrao_ex14_2_3.png" style="display: block;margin-left: auto;margin-right: auto;width: 80%;">
</figure>

Assim, conclu√≠mos que $0.52 < Q_{Z,0.7} < 0.53$. Podemos usar interpola√ß√£o para aproximar $Q_{Z, 0.7}$. Note que $Q_{Z,0.6985} = 0.52$ e $Q_{Z,0.7019} = 0.53$. Agora, admitindo que $Q_{Z,p}$ tem uma rela√ß√£o aproximadamente linear para $0.6985 \leq p \leq 0.7019$, temos que $Q_{Z,p} = a+bp$, com as restri√ß√µes

<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$0.52 = a+0.6985b$</td> <td>([**Eq. 1**]{style='color:red;'})</td> <td></td> <td></td> <td>e</td> <td></td> <td></td> <td>$0.53 = a+0.7019b$.</td> <td>([**Eq. 2**]{style='color:red;'})</td>
  </tr>
</table>

Pela 1¬™ equa√ß√£o, $a = 0.52 - 0.6985b$. Substituindo na 2¬™ equa√ß√£o, vem $b = \frac{0.53 - 0.52}{0.7019 - 0.6985} \approx 2.9412$. Retornando na 1¬™ equa√ß√£o, temos $a = 0.52 - 0.6985\cdot 2.9412 \approx -1.5344$. Finalmente, temos
$$Q_{Z,0.7} = a+0.7b = -1.5344 + 0.7 \cdot 2.9412 \approx 0.5244 \color{red}{\Rightarrow Q_{X,0.7} = 1.25 + 0.46 Q_{Z,0.7} = 1.4912.}$$ 
**Conclus√£o:** 70% dos motoristas apresentam tempo de rea√ß√£o inferior a 1,4912 seg.


## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedade

De modo geral, podemos encontrar o quantil $Q_{Z,p}$ de uma normal padr√£o por interpola√ß√£o da seguinte forma. Sejam $p_L$ e $p_U$, respectivamente, a maior e a menor probabilidades tabeladas tais que $p_L < p < p_U$ e $Q_{Z,p_L}$ e $Q_{Z,p_U}$ os respectivos quantis, ent√£o
$$Q_{Z,p} \approx a + bp,$$
em que
<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$b = \frac{p_U - p_L}{Q_{Z,p_U} - Q_{Z,p_L}}$</td> <td>e</td> <td>$a = p_L - bQ_{Z,p_L}$.</td>
  </tr>
</table>

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

No Exemplo 14, obtivemos $p_L = 0.6985$, $p_U = 0.7019$, $Q_{Z,p_L} = 0.52$ e $Q_{Z,p_U} = 0.53$.
:::

:::

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√µes

::: incremental

1. Em infer√™ncia, veremos um dos teoremas mais importantes para utiliza√ß√£o em aplica√ß√µes, o **Teorema Central do Limite** (TCL). Basicamente, o TCL afirma que, em grandes amostras, a m√©dia amostral tem distribui√ß√£o aproximadamente normal.
2. Como a m√©dia amostral √© soma de va's dividida pelo tamanho da amostra, √© natural, imaginar que, se uma va $X$ pode ser enxergada como soma de v√°rias va's, ent√£o a sua distribui√ß√£o tamb√©m ser√° bem aproximada por uma normal. Esse √© o caso da distribui√ß√£o Binomial (soma de Bernoulli's), por exemplo.

:::

:::

::: fragment

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 15:** Dos motoristas de um estado, 25% n√£o t√™m seguro. Seja $X =$ "quantidade sem seguro numa amostra de tamanho 50". [Se $s =$ "motorista n√£o ter seguro", ent√£o $X \sim \text{Bin}(n = 50, p = 0.25)$.]{.fragment} [Vamos determinar a probabilidade de 20% ou menos da amostra n√£o ter seguro:]{.fragment} [
$$\textstyle P(\frac{X}{n} \leq 0.2) = P(X \leq 10) = \sum_{x=0}^{10} p_X(x) = \sum_{x=0}^{10} {50 \choose x} 0.25^x0.75^{50-x} \approx 0.2622.$$]{.fragment}

:::

:::

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√µes

::: incremental

1. Note que, no Exemplo 15, o c√°lculo do valor exato de $P(X \leq 10)$ envolveu o c√°lculo de 11 probabilidades da distribui√ß√£o binomial, o que pode ser exaustivo se realizado sem aux√≠lio computacional;
2. A alternativa que surge √© utilizar $Y \sim \text{N}(\mu, \sigma^2)$ como aproxima√ß√£o para $X \sim \text{Bin}(n,p)$;
3. Os par√¢metros $\mu$ e $\sigma^2$ da distribui√ß√£o de $Y$ utilizada para a aproxima√ß√£o s√£o $\mu = \mu_X = np$ e $\sigma^2 = np(1-p)$, que s√£o a m√©dia e a vari√¢ncia da $X \sim \text{Bin}(n,p)$;
4. Tendo em vista que $X$ pode ser representada como soma de $n$ va's $\text{Ber}(p)$, o TCL garante que a aproxima√ß√£o do Item 2 fica melhor a medida que $n$ aumenta;
5. Para ilustra√ß√£o, os gr√°ficos a seguir mostram a fmp de $X \sim \text{Bin}(n,p)$ com a fdp de $Y \sim \text{N}(\mu = np, \sigma^2 = np(1-p))$, para $p=0.05$ e $0.25$, e $n = 5, 10, 50$ e $100$.

:::

:::

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}


```{r out.width="100%", fig.height=5}
#| layout-ncol: 2

n <- 5
p1 <- 0.05; p2 <- 0.25
mu1 <- n*p1;mu2 <- n*p2
s1 <- sqrt(n*p1*(1-p1)); s2 <- sqrt(n*p2*(1-p2))
qq <- 0:n; qq1 <- seq(-.5, n+.5, by = 0.01)
x1 <- dbinom(qq, n, p1); x2 <- dbinom(qq, n, p2)
y1 <- dnorm(qq1, mu1, s1); y2 <- dnorm(qq1, mu2, s2)
M1 <- max(y1, x1); M2 <- max(y2, x2)

par(family = "serif", mar=c(5,4,2.5,2))
plot(qq, x1, type='h', xlab='', ylab='', main='', lwd=3, xlim=c(-.5, n+.5), ylim=c(0, M1))
lines(qq1, y1, col='red', lwd=3)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(p)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 4, line = 1, cex=1.5, col='red')
mtext(text = bquote(italic(n)==.(n)*","~italic(p)==.(p1)), side = 3, line = .5, cex=2)
legend('topright', legend=c(expression(Bin*"("*italic(n)*","*italic(p)*")"), expression(N*"("*italic(np)*","~italic(np)*"("*italic(1-p)*")"*")")), col=c('black', 'red'), lwd=3)

plot(qq, x2, type='h', xlab='', ylab='', main='', lwd=3, xlim=c(-.5, n+.5), ylim=c(0, M2))
lines(qq1, y2, col='red', lwd=3)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(p)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 4, line = 1, cex=1.5, col='red')
mtext(text = bquote(italic(n)==.(n)*","~italic(p)==.(p2)), side = 3, line = .5, cex=2)
legend('topright', legend=c(expression(Bin*"("*italic(n)*","*italic(p)*")"), expression(N*"("*italic(np)*","~italic(np)*"("*italic(1-p)*")"*")")), col=c('black', 'red'), lwd=3)
```

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

```{r out.width="100%", fig.height=5}
#| layout-ncol: 2

n <- 10
p1 <- 0.05; p2 <- 0.25
mu1 <- n*p1;mu2 <- n*p2
s1 <- sqrt(n*p1*(1-p1)); s2 <- sqrt(n*p2*(1-p2))
qq <- 0:n; qq1 <- seq(-.5, n+.5, by = 0.01)
x1 <- dbinom(qq, n, p1); x2 <- dbinom(qq, n, p2)
y1 <- dnorm(qq1, mu1, s1); y2 <- dnorm(qq1, mu2, s2)
M1 <- max(y1, x1); M2 <- max(y2, x2)

par(family = "serif", mar=c(5,4,2.5,2))
plot(qq, x1, type='h', xlab='', ylab='', main='', lwd=3, xlim=c(-.5, n+.5), ylim=c(0, M1))
lines(qq1, y1, col='red', lwd=3)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(p)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 4, line = 1, cex=1.5, col='red')
mtext(text = bquote(italic(n)==.(n)*","~italic(p)==.(p1)), side = 3, line = .5, cex=2)
legend('topright', legend=c(expression(Bin*"("*italic(n)*","*italic(p)*")"), expression(N*"("*italic(np)*","~italic(np)*"("*italic(1-p)*")"*")")), col=c('black', 'red'), lwd=3)

plot(qq, x2, type='h', xlab='', ylab='', main='', lwd=3, xlim=c(-.5, n+.5), ylim=c(0, M2))
lines(qq1, y2, col='red', lwd=3)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(p)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 4, line = 1, cex=1.5, col='red')
mtext(text = bquote(italic(n)==.(n)*","~italic(p)==.(p2)), side = 3, line = .5, cex=2)
legend('topright', legend=c(expression(Bin*"("*italic(n)*","*italic(p)*")"), expression(N*"("*italic(np)*","~italic(np)*"("*italic(1-p)*")"*")")), col=c('black', 'red'), lwd=3)
```


## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

```{r out.width="100%", fig.height=5}
#| layout-ncol: 2

n <- 50
p1 <- 0.05; p2 <- 0.25
mu1 <- n*p1;mu2 <- n*p2
s1 <- sqrt(n*p1*(1-p1)); s2 <- sqrt(n*p2*(1-p2))
qq <- 0:n; qq1 <- seq(-.5, n+.5, by = 0.01)
x1 <- dbinom(qq, n, p1); x2 <- dbinom(qq, n, p2)
y1 <- dnorm(qq1, mu1, s1); y2 <- dnorm(qq1, mu2, s2)
M1 <- max(y1, x1); M2 <- max(y2, x2)

par(family = "serif", mar=c(5,4,2.5,2))
plot(qq, x1, type='h', xlab='', ylab='', main='', lwd=3, xlim=c(-.5, n+.5), ylim=c(0, M1))
lines(qq1, y1, col='red', lwd=3)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(p)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 4, line = 1, cex=1.5, col='red')
mtext(text = bquote(italic(n)==.(n)*","~italic(p)==.(p1)), side = 3, line = .5, cex=2)
legend('topright', legend=c(expression(Bin*"("*italic(n)*","*italic(p)*")"), expression(N*"("*italic(np)*","~italic(np)*"("*italic(1-p)*")"*")")), col=c('black', 'red'), lwd=3)

plot(qq, x2, type='h', xlab='', ylab='', main='', lwd=3, xlim=c(-.5, n+.5), ylim=c(0, M2))
lines(qq1, y2, col='red', lwd=3)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(p)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 4, line = 1, cex=1.5, col='red')
mtext(text = bquote(italic(n)==.(n)*","~italic(p)==.(p2)), side = 3, line = .5, cex=2)
legend('topright', legend=c(expression(Bin*"("*italic(n)*","*italic(p)*")"), expression(N*"("*italic(np)*","~italic(np)*"("*italic(1-p)*")"*")")), col=c('black', 'red'), lwd=3)
```

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

```{r out.width="100%", fig.height=5}
#| layout-ncol: 2

n <- 100
p1 <- 0.05; p2 <- 0.25
mu1 <- n*p1;mu2 <- n*p2
s1 <- sqrt(n*p1*(1-p1)); s2 <- sqrt(n*p2*(1-p2))
qq <- 0:n; qq1 <- seq(-.5, n+.5, by = 0.01)
x1 <- dbinom(qq, n, p1); x2 <- dbinom(qq, n, p2)
y1 <- dnorm(qq1, mu1, s1); y2 <- dnorm(qq1, mu2, s2)
M1 <- max(y1, x1); M2 <- max(y2, x2)

par(family = "serif", mar=c(5,4,2.5,2))
plot(qq, x1, type='h', xlab='', ylab='', main='', lwd=3, xlim=c(-.5, n+.5), ylim=c(0, M1))
lines(qq1, y1, col='red', lwd=3)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(p)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 4, line = 1, cex=1.5, col='red')
mtext(text = bquote(italic(n)==.(n)*","~italic(p)==.(p1)), side = 3, line = .5, cex=2)
legend('topright', legend=c(expression(Bin*"("*italic(n)*","*italic(p)*")"), expression(N*"("*italic(np)*","~italic(np)*"("*italic(1-p)*")"*")")), col=c('black', 'red'), lwd=3)

plot(qq, x2, type='h', xlab='', ylab='', main='', lwd=3, xlim=c(-.5, n+.5), ylim=c(0, M2))
lines(qq1, y2, col='red', lwd=3)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(p)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 4, line = 1, cex=1.5, col='red')
mtext(text = bquote(italic(n)==.(n)*","~italic(p)==.(p2)), side = 3, line = .5, cex=2)
legend('topright', legend=c(expression(Bin*"("*italic(n)*","*italic(p)*")"), expression(N*"("*italic(np)*","~italic(np)*"("*italic(1-p)*")"*")")), col=c('black', 'red'), lwd=3)
```



## {.unnumbered .unlisted .smaller}

### Exemplo 15 (cont.) {.unnumbered .unlisted}

Nesse caso, temos $\mu_X = np = 50 \cdot 0.25 = 12.5$ e $\sigma_X^2 = np(1-p) = 50 \cdot 0.25 \cdot 0.75 = 9.375$. Vamos ilustrar a aproxima√ß√£o de $P(X \leq 10)$ por meio de $Y \sim \text{N}(12.5, 9.375)$. Veja a figura abaixo.


## {.unnumbered .unlisted .smaller}

### Exemplo 15 (cont.) {.unnumbered .unlisted}

Nesse caso, temos $\mu_X = np = 50 \cdot 0.25 = 12.5$ e $\sigma_X^2 = np(1-p) = 50 \cdot 0.25 \cdot 0.75 = 9.375$. Vamos ilustrar a aproxima√ß√£o de $P(X \leq 10)$ por meio de $Y \sim \text{N}(12.5, 9.375)$. Veja a figura abaixo.

```{r fig.width=11, fig.height=5, fig.align='center'}

n <- 50; p <- 0.25; x <- floor(0.2*n); mu <- n*p; s <- sqrt(n*p*(1-p))
qq_bin <- 0:n; qq_nor <- seq(-.5, n+.5, by = 0.01)
dbin <- dbinom(qq_bin, n, p); dnor <- dnorm(qq_nor, mu, s)
My <- max(dbin, dnor)

par(family = "serif", mar=c(5,4,1,2))
plot(qq, x1, type='n', xlab='', ylab='', main='', xlim=range(qq_nor), ylim=c(0, My))
# rect(xleft=(0:x-.5), ybottom=rep(0, x+1), xright=(0:x+.5), ytop=dbin[qq_bin <= x],
# col=rgb(0, 0, 0, .3, maxColorValue = 1), lty=3, lwd=1.2)
# polygon(x=c(qq_nor[1],qq_nor[qq_nor < x+.5], x+.5, x+.5),
#         y=c(0, dnor[qq_nor < x+.5], dnorm(x+.5, mu, s), 0),
# col=rgb(1, 0, 0, .3, maxColorValue = 1), border='red')
for(i in 1:length(qq_bin)) lines(x=c(qq[i],qq[i]), y=c(0, dbin[i]), lwd=1.1)
lines(qq_nor, dnor, col='red', lwd=1.1)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(p)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 4, line = 1, cex=1.5, col='red')
# legend('topright',
#        legend=as.expression(list(
#               bquote(italic(P)*"("*italic(X)<=10*")"~"="~.(round(pbinom(x, n, p),4))),
#               bquote(italic(P)*"("*italic(Y)<=10.5*")"~"="~.(round(pnorm(x+.5, mu, s) - pnorm(-.5, mu, s),4)))
#               )),
#        fill=c(col=rgb(0, 0, 0, .3, maxColorValue = 1),
#               col=rgb(1, 0, 0, .3, maxColorValue = 1))
# )


```


## {.unnumbered .unlisted .smaller}

### Exemplo 15 (cont.) {.unnumbered .unlisted}

Nesse caso, temos $\mu_X = np = 50 \cdot 0.25 = 12.5$ e $\sigma_X^2 = np(1-p) = 50 \cdot 0.25 \cdot 0.75 = 9.375$. Vamos ilustrar a aproxima√ß√£o de $P(X \leq 10)$ por meio de $Y \sim \text{N}(12.5, 9.375)$. Veja a figura abaixo.

```{r fig.width=11, fig.height=5, fig.align='center'}

n <- 50; p <- 0.25; x <- floor(0.2*n); mu <- n*p; s <- sqrt(n*p*(1-p))
qq_bin <- 0:n; qq_nor <- seq(-.5, n+.5, by = 0.01)
dbin <- dbinom(qq_bin, n, p); dnor <- dnorm(qq_nor, mu, s)
My <- max(dbin, dnor)

par(family = "serif", mar=c(5,4,1,2))
plot(qq, x1, type='n', xlab='', ylab='', main='', xlim=range(qq_nor), ylim=c(0, My))
rect(xleft=(0:x-.5), ybottom=rep(0, x+1), xright=(0:x+.5), ytop=dbin[qq_bin <= x],
col=rgb(0, 0, 0, .3, maxColorValue = 1), lty=3, lwd=1.2)
# polygon(x=c(qq_nor[1],qq_nor[qq_nor < x+.5], x+.5, x+.5),
#         y=c(0, dnor[qq_nor < x+.5], dnorm(x+.5, mu, s), 0),
# col=rgb(1, 0, 0, .3, maxColorValue = 1), border='red')
for(i in 1:length(qq_bin)) lines(x=c(qq[i],qq[i]), y=c(0, dbin[i]), lwd=1.1)
lines(qq_nor, dnor, col='red', lwd=1.1)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(p)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 4, line = 1, cex=1.5, col='red')
legend('topright',
       legend=as.expression(list(
              bquote(italic(P)*"("*italic(X)<=10*")"~"="~.(round(pbinom(x, n, p),4)))#,
              # bquote(italic(P)*"("*italic(Y)<=10.5*")"~"="~.(round(pnorm(x+.5, mu, s) - pnorm(-.5, mu, s),4)))
              )),
       fill=c(col=rgb(0, 0, 0, .3, maxColorValue = 1)#,
              # col=rgb(1, 0, 0, .3, maxColorValue = 1)
)
)


```

## {.unnumbered .unlisted .smaller}

### Exemplo 15 (cont.) {.unnumbered .unlisted}

Nesse caso, temos $\mu_X = np = 50 \cdot 0.25 = 12.5$ e $\sigma_X^2 = np(1-p) = 50 \cdot 0.25 \cdot 0.75 = 9.375$. Vamos ilustrar a aproxima√ß√£o de $P(X \leq 10)$ por meio de $Y \sim \text{N}(12.5, 9.375)$. Veja a figura abaixo.

```{r fig.width=11, fig.height=5, fig.align='center'}

n <- 50; p <- 0.25; x <- floor(0.2*n); mu <- n*p; s <- sqrt(n*p*(1-p))
qq_bin <- 0:n; qq_nor <- seq(-.5, n+.5, by = 0.01)
dbin <- dbinom(qq_bin, n, p); dnor <- dnorm(qq_nor, mu, s)
My <- max(dbin, dnor)

par(family = "serif", mar=c(5,4,1,2))
plot(qq, x1, type='n', xlab='', ylab='', main='', xlim=range(qq_nor), ylim=c(0, My))
rect(xleft=(0:x-.5), ybottom=rep(0, x+1), xright=(0:x+.5), ytop=dbin[qq_bin <= x],
col=rgb(0, 0, 0, .3, maxColorValue = 1), lty=3, lwd=1.2)
polygon(x=c(qq_nor[1],qq_nor[qq_nor < x+.5], x+.5, x+.5),
        y=c(0, dnor[qq_nor < x+.5], dnorm(x+.5, mu, s), 0),
col=rgb(1, 0, 0, .3, maxColorValue = 1), border='red')
for(i in 1:length(qq_bin)) lines(x=c(qq[i],qq[i]), y=c(0, dbin[i]), lwd=1.1)
lines(qq_nor, dnor, col='red', lwd=1.1)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(p)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 4, line = 1, cex=1.5, col='red')
legend('topright',
       legend=as.expression(list(
              bquote(italic(P)*"("*italic(X)<=10*")"~"="~.(round(pbinom(x, n, p),4))),
              bquote(italic(P)*"("*italic(Y)<=10.5*")"~"="~"?")
              )),
       fill=c(col=rgb(0, 0, 0, .3, maxColorValue = 1),
              col=rgb(1, 0, 0, .3, maxColorValue = 1))
)


```

## {.unnumbered .unlisted .smaller}

### Exemplo 15 (cont.) {.unnumbered .unlisted}

Assim, a ideia √© realizar a aproxima√ß√£o
$$\textstyle P(X \leq 10) \approx P(Y \leq 10.5) = P(Z \leq \frac{10.5 - 12.5}{\sqrt{9.375}}) = P(Z \leq -0.65) = 0.2578.$$

<figure>
  <img src="figs/figura_normal_padrao_ex15_3.png" style="display: block;margin-left: auto;margin-right: auto;width: 80%;">
</figure>

## {.unnumbered .unlisted .smaller}

### Exemplo 15 (cont.) {.unnumbered .unlisted}

Nesse caso, temos $\mu_X = np = 50 \cdot 0.25 = 12.5$ e $\sigma_X^2 = np(1-p) = 50 \cdot 0.25 \cdot 0.75 = 9.375$. Vamos ilustrar a aproxima√ß√£o de $P(X \leq 10)$ por meio de $Y \sim \text{N}(12.5, 9.375)$. Veja a figura abaixo.

```{r fig.width=11, fig.height=5, fig.align='center'}

n <- 50; p <- 0.25; x <- floor(0.2*n); mu <- n*p; s <- sqrt(n*p*(1-p))
qq_bin <- 0:n; qq_nor <- seq(-.5, n+.5, by = 0.01)
dbin <- dbinom(qq_bin, n, p); dnor <- dnorm(qq_nor, mu, s)
My <- max(dbin, dnor)

par(family = "serif", mar=c(5,4,1,2))
plot(qq, x1, type='n', xlab='', ylab='', main='', xlim=range(qq_nor), ylim=c(0, My))
rect(xleft=(0:x-.5), ybottom=rep(0, x+1), xright=(0:x+.5), ytop=dbin[qq_bin <= x],
col=rgb(0, 0, 0, .3, maxColorValue = 1), lty=3, lwd=1.2)
polygon(x=c(qq_nor[1],qq_nor[qq_nor < x+.5], x+.5, x+.5),
        y=c(0, dnor[qq_nor < x+.5], dnorm(x+.5, mu, s), 0),
col=rgb(1, 0, 0, .3, maxColorValue = 1), border='red')
for(i in 1:length(qq_bin)) lines(x=c(qq[i],qq[i]), y=c(0, dbin[i]), lwd=1.1)
lines(qq_nor, dnor, col='red', lwd=1.1)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(p)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 4, line = 1, cex=1.5, col='red')
legend('topright',
       legend=as.expression(list(
              bquote(italic(P)*"("*italic(X)<=10*")"~"="~.(round(pbinom(x, n, p),4))),
              bquote(italic(P)*"("*italic(Y)<=10.5*")"~"="~.(round(pnorm(x+.5, mu, s) - pnorm(-.5, mu, s),4)))
       )),
       fill=c(col=rgb(0, 0, 0, .3, maxColorValue = 1),
              col=rgb(1, 0, 0, .3, maxColorValue = 1))
)


```

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-tip}
## Exerc√≠cios

Considerando as condi√ß√µes do Exemplo 15 e utilizando $Y \sim \text{N}(12.5, 9.375)$, aproxime as seguintes probabilidades:

1. $P(X < 10)$;
2. $P(X = 10)$;
3. $P(X > 10)$;
4. $P(X \geq 10)$.
:::

::: {.callout-caution}
## Observa√ß√µes

1. √â poss√≠vel notar que a va normal tem fdp sim√©trica em torno de $\mu$ com formato de sino (a fdp $f_X(x)$ decresce conforme $x$ se afasta de $\mu$).
2. Em muitas situa√ß√µes pr√°ticas, a vac √© positiva e possui assimetria. Uma fam√≠lia de fdp com essas caracter√≠sticas √© a fam√≠lia **gama**.
:::

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Dizemos que $X$ tem distribui√ß√£o Gama com par√¢metros $\alpha$ e $\beta$, se sua fdp √© dada por
$$\textstyle f_X(x) = \frac{1}{\beta^\alpha\Gamma(\alpha)}x^{\alpha - 1}e^{-x/\beta}, \ \ \ \ x > 0, \ \ \ \ \alpha,\beta > 0,$$
em que $\Gamma(\alpha) = \int_0^\infty z^{\alpha-1}e^{-z}dz$ √© a fun√ß√£o gama. Nesse caso, utilizamos a nota√ß√£o $X \sim \text{Gama}(\alpha, \beta)$.
:::

::: fragment

::: {.callout-warning}
## Propriedades

A fun√ß√£o gama possui as seguintes propriedades:

::: incremental

1. Para qualquer $\alpha > 1$, $\Gamma(\alpha) = (\alpha - 1)\Gamma(\alpha - 1)$;
2. Se $n \in \mathbb{N}$, ent√£o $\Gamma(n) = (n-1)!$;
3. $\Gamma(\frac{1}{2}) = \pi$.

:::

:::

:::

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Se $X \sim \text{Gama}(\alpha, 1)$, isto √©, com par√¢metro $\beta=1$, dizemos que $X$ tem distribui√ß√£o [**gama padr√£o**]{style="color:red;"} de par√¢metro de forma $\alpha$.

:::

::: fragment

::: {.callout-warning}
## Propriedades

::: incremental

1. Se $X \sim \text{Gama}(\alpha, \beta)$, ent√£o
<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$E(X) = \alpha\beta$</td> <td>e</td> <td>$V(X) = \alpha\beta^2.$</td>
  </tr>
</table>
2. Se $X \sim \text{Gama}(\alpha, \beta)$, ent√£o $\frac{X}{\beta} \sim \text{Gama}(\alpha, 1)$, isto √©, $\frac{X}{\beta}$ tem distribui√ß√£o gama padr√£o com par√¢metro de forma $\alpha$.
3. Assim, os problemas de c√°lculos de probabilidades de uma $\text{Gama}(\alpha, \beta)$ podem ser transformados nos de uma $\text{Gama}(\alpha, 1)$ por meio da opera√ß√£o $\frac{X}{\beta}$. A probabilidades de uma gama padr√£o para diferentes valores de $\alpha$ podem ser obtidas por m√©todos num√©ricos e seus valores tabelados.

:::

:::

:::


## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

```{r fig.width=8, fig.height=4.5, fig.align='center'}
x <- seq(0.00001,4,length.out=1000)
a1 <- 0.7; b1 <- 1
a2 <- 1; b2 <- 1
a3 <- 1.5; b3 <- 1

y1 <- dgamma(x = x, shape = a1,scale = b1)
y2 <- dgamma(x = x, shape = a2,scale = b2)
y3 <- dgamma(x = x, shape = a3,scale = b3)

M_y <- max(2, y2, y3)
par(family = "serif", mar=c(5,4,1,2))
plot(x, y1, type='n', xlab='', ylab='', main='', ylim=c(-.09*M_y, 1.07*M_y),
     xlim=c(min(x)-.02*diff(range(x)), max(x)+.04*diff(range(x))))

arrows(y0 = -.09*M_y, y1 = 1.07*M_y, x0=0, x1=0, length = .1, lwd=2, col='darkgray')
arrows(y0 = 0, y1 = 0, x0=min(x)-.02*diff(range(x)), x1=max(x)+.04*diff(range(x)), length = .1, lwd=2, col='darkgray')
lines(x[y1 <= M_y], y1[y1 <= M_y], lwd=2)
lines(x, y2, lwd=2, col='blue')
lines(x, y3, lwd=2, col='red')

mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
legend('topright',
       legend=as.expression(list(bquote(alpha == .(a1)*','~beta == .(b1)),
                                 bquote(alpha == .(a2)*','~beta == .(b2)),
                                 bquote(alpha == .(a3)*','~beta == .(b3)))),
       col=c('black', 'blue', 'red'), lty=1, lwd=2)
```

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

```{r fig.width=8, fig.height=4.5, fig.align='center'}
x <- seq(0.001,4,length.out=1000)
a1 <- 2; b1 <- 0.5
a2 <- 2; b2 <- 1
a3 <- 2; b3 <- 1.5

y1 <- dgamma(x = x, shape = a1,scale = b1)
y2 <- dgamma(x = x, shape = a2,scale = b2)
y3 <- dgamma(x = x, shape = a3,scale = b3)

M_y <- max(y1, y2, y3)
par(family = "serif", mar=c(5,4,1,2))
plot(x, y1, type='n', xlab='', ylab='', main='', ylim=c(-.09*M_y, 1.07*M_y),
     xlim=c(min(x)-.02*diff(range(x)), max(x)+.04*diff(range(x))))

arrows(y0 = -.09*M_y, y1 = 1.07*M_y, x0=0, x1=0, length = .1, lwd=2, col='darkgray')
arrows(y0 = 0, y1 = 0, x0=min(x)-.02*diff(range(x)), x1=max(x)+.04*diff(range(x)), length = .1, lwd=2, col='darkgray')
lines(x, y1, lwd=2)
lines(x, y2, lwd=2, col='blue')
lines(x, y3, lwd=2, col='red')

mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
legend('topright',
       legend=as.expression(list(bquote(alpha == .(a1)*','~beta == .(b1)),
                                 bquote(alpha == .(a2)*','~beta == .(b2)),
                                 bquote(alpha == .(a3)*','~beta == .(b3)))),
       col=c('black', 'blue', 'red'), lty=1, lwd=2)
```


## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

<figure>
  <img src="figs/fig_gama_padrao1.png" style="display: block;margin-left: auto;margin-right: auto;width: 80%;">
</figure>

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

<figure>
  <img src="figs/fig_gama_padrao2.png" style="display: block;margin-left: auto;margin-right: auto;width: 80%;">
</figure>

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

<figure>
  <img src="figs/fig_gama_padrao3.png" style="display: block;margin-left: auto;margin-right: auto;width: 80%;">
</figure>

## {.unnumbered .unlisted .smaller}

### Exemplo 16 {.unnumbered .unlisted}

O tempo de vida $X$ (semanas) de um camundongo exposto a radia√ß√£o satisfaz $X \sim \text{Gama}(8, 13)$. Valores originais em *Survival Distributions: Reliability Applications in the Biomedical Services* s√£o $\alpha = 8.5$ e $\beta = 13.3$.

[Temos $E(X) = \alpha\beta = 8\cdot 13 = 104$, $V(X) = 8\cdot 13^2 = 1352$ e $DP(X) = \sqrt{1352} \approx 36.77$. Se $Y = \frac{X}{13}$, ent√£o $Y \sim \text{Gama}(8, 1)$.]{.fragment fragment-index=1} [Da√≠, por exemplo, a probabilidade de um camundongo sobreviver de 60 a 120 semanas √©
$$\textstyle P(60 < X < 120) = P(\frac{60}{13} < \frac{X}{13} < \frac{120}{13}) \approx P(4.62 < Y < 9.23) = F_Y(9.23) - F_Y(4.62).$$]{.fragment fragment-index=2}

::: columns

::: {.column #vcenter width=50%}

::: {.fragment fragment-intex=3}

<figure>
  <img src="figs/fig_gama_padrao_Ex16_1.png" style="display: block;margin-left: auto;margin-right: auto;width: 95%;">
  <figcaption style='text-align:center'>$0.051 = F_Y(4) < F_Y(4.62) < F_Y(5) = 0.133$</figcaption>
</figure>

:::

:::

::: {.column #vcenter width=50%}

::: {.fragment fragment-intex=4}

<figure>
  <img src="figs/fig_gama_padrao_Ex16_2.png" style="display: block;margin-left: auto;margin-right: auto;width: 95%;">
  <figcaption style='text-align:center'>$0.676 = F_Y(9) < F_Y(9.23) < F_Y(10) = 0.780$</figcaption>
</figure>

:::

:::

:::

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 16 (cont.):** Podemos aproximar o valor de $F_Y(4.62)$ utilizando interpola√ß√£o linear. [Assumindo que $F_Y(y) \approx a+by$, $y \in [4,5]$, e notando que $F_Y(4) = 0.051 = a+4b$ e que $F_Y(5) = 0.133 = a + 5b$, obtemos]{.fragment fragment-intex=1}

::: {.fragment fragment-intex=1}

<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$5b-4b = b = 0.133 - 0.051 = 0.082$</td> <td>e</td> <td>$a = 0.051 - 4b = 0.051 - 4 \cdot 0.082 = -0.277.$</td>
  </tr>
</table>

:::

[Logo, $F_Y(4.62) \approx -0.277 + 0.082 \cdot 4.62 = 0.1018$ (valor verdadeiro [`r round(pgamma(q = 4.62, shape = 8, rate = 1), 4)`]{style='color:blue;'}).]{.fragment fragment-intex=3} [Analogamente, obtemos $F_Y(9.23) \approx -0.26 + 0.104 \cdot 9.23 = 0.6999$ (valor verdadeiro [`r round(pgamma(q = 9.23, shape = 8, rate = 1), 4)`]{style='color:blue;'}).]{.fragment fragment-intex=4} [Assim,]{.fragment fragment-intex=5}

::: {.fragment fragment-intex=5}

<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$P(60 < X < 120) \approx 0.6999 - 0.1018 = 0.5981$</td> <td>(Valor verdadeiro [`r round(diff(pgamma(q = c(4.62, 9.23), shape = 8, rate = 1)), 4)`]{style='color:blue;'}).</td>
  </tr>
</table>

:::

:::

::: {.fragment fragment-intex=6}

::: {.callout-caution}
## Observa√ß√£o

Existe um caso especial da distribui√ß√£o Gama que √© muito √∫til em infer√™ncia, que √© a distribui√ß√£o [**qui-quadrado**]{style='color:red;'}.

:::

:::


## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Dizemos que $X$ tem distribui√ß√£o qui-quadrado com $\nu$ graus de liberdade (gl), denotada por $X \sim \chi^2_\nu$, se
<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$f_X(x) = \frac{(1/2)^{\nu/2}}{\Gamma(\frac{\nu}{2})}x^{\frac{\nu}{2}-1}e^{-\frac{x}{2}}, \ \ \ \ x > 0, \ \ \ \ \nu = 1, 2, \ldots.$</td>
  </tr>
</table>
:::

::: {.fragment fragment-intex=2}

::: {.callout-warning}
## Propriedade

A distribui√ß√£o $\chi^2_\nu$ √© um caso especial da $\text{Gama}(\alpha, \beta)$, com $\alpha = \frac{\nu}{2}$ e $\beta = 2$. Assim, pela esperan√ßa e variancia da distribui√ß√£o gama, se $X \sim \chi^2_\nu$, temos que
<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$E(X) = \alpha\beta = \nu$</td> <td>e</td> <td>$V(X) = \alpha\beta^2 = 2\nu.$</td>
  </tr>
</table>

:::

:::

::: {.fragment fragment-intex=3}

::: {.callout-caution}
## Observa√ß√£o

Embora, em geral, as probabilidades da distribui√ß√£o Gama n√£o possam ser obtidas analiticamente, quando $\alpha = 1$ isso √© poss√≠vel. Esse caso particular da distribui√ß√£o Gama, √© chamada de distribui√ß√£o [**exponencial**]{style='color:red;'}.
:::

:::



## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Dizemos que $X$ tem distribui√ß√£o exponencial com taxa $\lambda$, denotada por $X \sim \text{Exp}(\lambda)$, se sua fdp √©
<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$f_X(x) = \lambda e^{-\lambda x}, \ \ \ \ x > 0, \ \ \ \ \lambda > 0.$</td>
  </tr>
</table>
:::

::: fragment

::: {.callout-warning}
## Propriedades

::: incremental

1. A distribui√ß√£o $\text{Exp}(\lambda)$ √© um caso especial da $\text{Gama}(\alpha, \beta)$, com $\alpha = 1$ e $\beta = \frac{1}{\lambda}$;
2. Assim, pela esperan√ßa e variancia da distribui√ß√£o gama, se $X \sim \text{Exp}(\lambda)$, temos que
<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$\mu = E(X) = \alpha\beta = \frac{1}{\lambda}$</td> <td>e</td> <td>$\sigma^2 = V(X) = \alpha\beta^2 = \frac{1}{\lambda^2}.$</td>
  </tr>
</table>

:::

:::

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Note que, se $X \sim \text{Exp}(\lambda)$, ent√£o $\mu = \sigma$.
:::

:::

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

```{r fig.width=8, fig.height=4.5, fig.align='center'}
x <- seq(0.001,4,length.out=1000)
a1 <- 1; b1 <- 0.5
a2 <- 1; b2 <- 1
a3 <- 1; b3 <- 2

y1 <- dgamma(x = x, shape = a1,scale = b1)
y2 <- dgamma(x = x, shape = a2,scale = b2)
y3 <- dgamma(x = x, shape = a3,scale = b3)

M_y <- max(y1, y2, y3)
par(family = "serif", mar=c(5,4,1,2))
plot(x, y1, type='n', xlab='', ylab='', main='', ylim=c(-.09*M_y, 1.07*M_y),
     xlim=c(min(x)-.02*diff(range(x)), max(x)+.04*diff(range(x))))

arrows(y0 = -.09*M_y, y1 = 1.07*M_y, x0=0, x1=0, length = .1, lwd=2, col='darkgray')
arrows(y0 = 0, y1 = 0, x0=min(x)-.02*diff(range(x)), x1=max(x)+.04*diff(range(x)), length = .1, lwd=2, col='darkgray')
lines(x, y1, lwd=2)
lines(x, y2, lwd=2, col='blue')
lines(x, y3, lwd=2, col='red')

mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
legend('topright',
       legend=as.expression(list(bquote(lambda == .(1/b1)),
                                 bquote(lambda == .(1/b2)),
                                 bquote(lambda == .(1/b3)))),
       col=c('black', 'blue', 'red'), lty=1, lwd=2)
```


## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedade

Se $X \sim \text{Exp}(\lambda)$, ent√£o sua fda √© dada por
<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$F_X(x) = 1 - e^{-\lambda x}.$</td>
  </tr>
</table>
:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 17:** O tempo de resposta $X$ em um terminal de computador on-line satisfaz $X \sim \text{Exp}(\lambda)$. Suponha que o tempo de resposta esperado √© de 5 segundos. [Ent√£o $E(X) = 5 = 1/\lambda$, com $\lambda = 0.2$.]{.fragment}

[A probabilidade de o tempo de resposta ser maior que 10 segundos √©
$$P(X > 10) = 1- P(X \leq 10) = 1 - F_X(10) = 1 - (1-e^{-0.2\cdot 10}) = e^{-2} \approx 0.1353.$$]{.fragment}

[Seja $\tilde{\mu}$ o tempo de resposta mediano. Como $F_X(\tilde{\mu}) = 1-e^{-0.2\cdot \tilde{\mu}} = 0.5$,]{.fragment} [temos que a mediana √© $\tilde{\mu} = -5\log(0.5) \approx 3.4657$.]{.fragment} [Note que $\tilde{\mu} \approx 3.4657 > 5 = \mu$, o que reflete a assimetria √† direita da distribui√ß√£o exponencial.]{.fragment}

::: 


## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√µes

1. A distribui√ß√£o exponencial √© muito utilizada para modelar o tempo de vida de componentes em geral;
2. Uma propriedade importante da distribui√ß√£o exponencial nessas aplica√ß√µes √© a **falta de mem√≥ria**.
:::

::: fragment

::: {.callout-warning}
## Propriedade - Fala de mem√≥ria da distribui√ß√£o exponencial

Se $X \sim \text{Exp}(\lambda)$, ent√£o $P(X > t + s‚èê X > s) = P(X > t) = e^{-\lambda t}$, ou seja, se sabemos que $X$ j√° ultrapassou $s$, a probabilidade de $X$ ultrapassar $t+s$ √© a mesma de $X$ ultrapassar $t$. Em outras palavras, ap√≥s $s$ instantes, o componente n√£o apresenta sinais de desgaste/melhora.
:::

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Embora a falta de mem√≥ria possa ser admitida em algumas aplica√ß√µes, em outras os componentes se deterioram ou ocasionalmente melhoram com o passar do tempo (ao menos at√© certo ponto). Modelos mais gerais de tempo de vida s√£o fornecidos pelas distribui√ß√µes Gama, Weibull e Lognormal.
:::

:::


## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Al√©m das diversas aplica√ß√µes pr√°ticas, a distribui√ß√£o exponencial √© utilizada na constru√ß√£o de uma nova distribui√ß√£o **discreta**, a distribui√ß√£o [**Poisson**]{style="color:red;"}.
:::


::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 18:** Um processo √© monitorado continuamente em busca de falhas. Para qualquer instante $t \geq 0$, seja $X_t =$ "quantidade de falhas at√© o instante $t$". Suponha que $X_t$ satisfaz os seguintes requisitos:

::: incremental

- o tempo entre falhas tem distribui√ß√£o exponencial com taxa $\lambda$;
- as falhas acontecem independentemente;
- no instante inicial, temos $X_0 = 0$.

:::

[Dizemos $\{X_t, t \geq 0\}$ √© um processo de **Poisson** com taxa $\lambda$.]{.fragment} [Para cada $t$, $X_t$ √© uma vad.]{.fragment} [A fmp $X$ √©]{.fragment}
<table class=fragment>
  <tr style="border-bottom:none;text-align:center;">
    <td>$p_{X_t}(x) = P(X_t = x) = \frac{e^{-\lambda t}(\lambda t)^x}{x!}, \ \ \ x=0,1,2,\ldots.$</td>
  </tr>
</table>


[O n√∫mero de falhas at√© $t=1$ define a distribui√ß√£o **Poisson**.]{.fragment}

::: 

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Dizemos que $X$ tem distribui√ß√£o Poisson com taxa $\lambda$, denotada por $X \sim \text{Pois}(\lambda)$ se sua fmp √©
<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$p_X(x) = P(X = x) = \frac{e^{-\lambda}\lambda^x}{x!}, \ \ \ x=0,1,2,\ldots.$</td>
  </tr>
</table>
:::

::: fragment

::: {.callout-warning}
## Propriedade

Se $X \sim \text{Pois}(\lambda)$, temos que
<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$\mu = E(X) = \lambda$</td> <td>e</td> <td>$\sigma^2 = V(X) = \lambda.$</td>
  </tr>
</table>
:::

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

A distribui√ß√£o Poisson √© muito utilizada para modelar o n√∫mero de ocorr√™ncias de eventos, n√£o somente no tempo, mas tamb√©m por unidades de medida, como √°reas, por exemplo.

:::

:::

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 19:** Em determinada cidade, o n√∫mero de casos de dengue tem distribui√ß√£o de Poisson com $100$ ocorr√™ncias por $\text{km}^2$ **em m√©dia**, ou seja, $\mu = \lambda = 100$. Qual a probabilidade de se observar menos que 3 ocorr√™ncias em uma regi√£o de $10000\text{m}^2$?

[Primeiramente, temos que $10000\text{m}^2 = 100\text{m} \cdot 100\text{m} = 0.1\text{km} \cdot 0.1\text{km} = 0.01\text{km}^2$.]{.fragment} [Logo, o n√∫mero de ocorr√™ncias $X$ na regi√£o especificada deve satisfazer $X \sim \text{Pois}(\lambda t)$, com $\lambda = 100$
e $t = 0.01$, ou seja $\lambda t = 1$.]{.fragment} [Assim,
$$\textstyle P(X < 3) = p_X(0) + p_X(1) + p_X(2) = \frac{e^{-1}1^0}{0!} + \frac{e^{-1}1^1}{1!} + \frac{e^{-1}1^2}{2!} = e^{-1}[1+1+\frac{1}{2}] \approx 0.9197.$$]{.fragment}

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Vimos que $X \sim \text{Exp}(\lambda)$ possui a caracter√≠stica de perda de mem√≥ria. [Em algumas aplica√ß√µes, essa propriedade n√£o √© razo√°vel.]{.fragment} [A distribui√ß√£o gama em geral n√£o possui essa propriedade.]{.fragment} [Outros exemplos que tamb√©m n√£o t√™m essa restri√ß√£o s√£o as distribui√ß√µes Weibull e Lognormal.]{.fragment}
:::

:::

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

A vac $X$ tem distribui√ß√£o Weibull com par√¢metros $\alpha$ e $\beta$, denotada por $X \sim \text{Weibull}(\alpha, \beta)$ se sua fdp √©
<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$f_X(x) = \frac{\alpha}{\beta^\alpha} x^{\alpha-1}e^{-(\frac{x}{\beta})^\alpha}, \ \ \ x > 0, \ \ \ \alpha,\beta > 0.$</td>
  </tr>
</table>
:::

::: fragment

::: {.callout-warning}
## Propriedade

Se $X \sim \text{Weibull}(\alpha, \beta)$, temos que
<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$\mu = E(X) = \beta\Gamma(1+\frac{1}{\alpha})$</td> <td>e</td> <td>$\sigma^2 = V(X) = \beta^2\{\Gamma(1+\frac{2}{\alpha})-[\Gamma(1+\frac{1}{\alpha})]^2\}.$</td>
  </tr>
</table>
:::

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Note que $E(X)$ e $V(X)$ dependem da fun√ß√£o gama, $\Gamma(\cdot)$, e frequentemente s√£o obtidas por m√©todos num√©ricos.
:::

:::

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

```{r out.width="100%", fig.height=5}
#| layout-ncol: 2

x <- seq(0.00001, 5, length.out=1000)

a1 <- 1; b1 <- 1
a2 <- 2; b2 <- 1
a3 <- 0.5; b3 <- 1
y1 <- dweibull(x, a1, b1)
y2 <- dweibull(x, a2, b2)
y3 <- dweibull(x, a3, b3)
Max <- max(y1, y2, min(max(y3), 1.5))

par(family = "serif", mar=c(5,4,2.5,2))
plot(x, y1, type='n', xlab='', ylab='', main='', lwd=3, ylim=c(-.03*Max, 1.07*Max),
     xlim=c(min(x)-.03*diff(range(x)), max(x)+.07*diff(range(x))))

arrows(y0 = -.03*Max, y1 = 1.07*Max, x0=0, x1=0, length = .1, lwd=2, col='darkgray')
arrows(y0 = 0, y1 = 0, x0=min(x)-.03*diff(range(x)), x1=max(x)+.07*diff(range(x)), length = .1, lwd=2, col='darkgray')

lines(x, y1, col='blue', lwd=3)
lines(x, y2, col='red', lwd=3)
lines(x[y3<1.5], y3[y3<1.5], col='black', lwd=3)
mtext(text = expression(italic(t)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = expression(Weibull(alpha, beta)), side = 3, line = .5, cex=2)
legend('topright',
       legend=as.expression(list(bquote(alpha*" = "*.(a3)*"; "*beta*" = "*.(b3)),
                                 bquote(alpha*" = "*.(a1)*"; "*beta*" = "*.(b1)),
                                 bquote(alpha*" = "*.(a2)*"; "*beta*" = "*.(b2)))),
       col=c('black', 'blue', 'red'), lwd=3)


x <- seq(0, 2.5, length.out=1000)
a1 <- 10; b1 <- 0.5
a2 <- 10; b2 <- 1
a3 <- 10; b3 <- 2
y1 <- dweibull(x, a1, b1)
y2 <- dweibull(x, a2, b2)
y3 <- dweibull(x, a3, b3)
Max <- max(y1, y2, y3)

par(family = "serif", mar=c(5,4,2.5,2))
plot(x, y1, type='n', xlab='', ylab='', main='', lwd=3, ylim=c(-.03*Max, 1.07*Max),
     xlim=c(min(x)-.03*diff(range(x)), max(x)+.07*diff(range(x))))

arrows(y0 = -.03*Max, y1 = 1.07*Max, x0=0, x1=0, length = .1, lwd=2, col='darkgray')
arrows(y0 = 0, y1 = 0, x0=min(x)-.03*diff(range(x)), x1=max(x)+.07*diff(range(x)), length = .1, lwd=2, col='darkgray')

lines(x, y1, col='black', lwd=3)
lines(x, y2, col='blue', lwd=3)
lines(x, y3, col='red', lwd=3)
mtext(text = expression(italic(t)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
mtext(text = expression(Weibull(alpha, beta)), side = 3, line = .5, cex=2)
legend('topright',
       legend=as.expression(list(bquote(alpha*" = "*.(a1)*"; "*beta*" = "*.(b1)),
                                 bquote(alpha*" = "*.(a2)*"; "*beta*" = "*.(b2)),
                                 bquote(alpha*" = "*.(a3)*"; "*beta*" = "*.(b3)))),
       col=c('black', 'blue', 'red'), lwd=3)
```

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedades

::: incremental

1. Se $X \sim \text{Weibull}(\alpha, \beta)$ √© poss√≠vel mostrar que $Y = (\frac{X}{\beta})^\alpha$ satisfaz $Y \sim \text{Exp}(1)$. De modo an√°logo, se $Y \sim \text{Exp}(1)$, ent√£o $X = \beta Y^{1/\alpha}$ satisfaz $X \sim \text{Weibull}(\alpha, \beta)$;
2. Se $X \sim \text{Weibull}(\alpha, \beta)$, a fda de $X$ √©
<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$F_X(x) = 1- e^{-(\frac{x}{\beta})^{\alpha}}$;</td>
  </tr>
</table>
3. Se $X \sim \text{Weibull}(1, \frac{1}{\lambda})$, isto √©, $\alpha = 1$ e $\beta = \frac{1}{\lambda}$, ent√£o $X \sim \text{Exp}(\lambda)$.

:::

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

A fun√ß√£o $S(t) = P(X > t) = 1-F_X(t)$ √© denominada de fun√ß√£o **sobreviv√™ncia**. As fun√ß√µes sobreviv√™ncia de uma $\text{Exp}(\lambda)$ e de uma $\text{Weibull}(\alpha, \beta)$ s√£o, respectivamente:
<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$S_E(t) = e^{-\lambda t}$</td> <td>e</td> <td>$S_W(t) = e^{-(\frac{t}{\beta})^{\alpha}}.$</td>
  </tr>
</table>
:::

:::

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

```{r out.width="100%", fig.height=5}
#| layout-ncol: 2

x <- seq(0.0001, 3, length.out=1000)
lam1 <- 1
lam2 <- 3
ye1 <- 1-pexp(x, lam1)
ye2 <- 1-pexp(x, lam2)
a1 <- .5; b1 <- 1
a2 <- 3; b2 <- 1.5
yw1 <- 1-pweibull(x, a1, b1)
yw2 <- 1-pweibull(x, a2, b2)
Max <- max(ye1, ye2, yw1, yw2)

par(family = "serif", mar=c(5,4,2.5,2))
plot(x, ye1, type='n', xlab='', ylab='', main='', lwd=3, xlim=c(0, 3), ylim=c(0, Max))
lines(x, ye1, col='black', lwd=3)
lines(x, ye2, col='blue', lwd=3)
mtext(text = expression(italic(t)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(S)[italic(E)]*"("*italic(t)*")"), side = 2, line = 2, cex=1.5)
mtext(text = expression(Exp(lambda)), side = 3, line = .5, cex=2)
legend('topright',
       legend=as.expression(list(bquote(lambda == .(lam1)),
                                 bquote(lambda == .(lam2)))),
       col=c('black', 'blue'), lwd=3)

par(family = "serif", mar=c(5,4,2.5,2))
plot(x, ye1, type='n', xlab='', ylab='', main='', lwd=3, xlim=c(0, 3), ylim=c(0, Max))
lines(x, yw1, col='black', lwd=3)
lines(x, yw2, col='blue', lwd=3)
mtext(text = expression(italic(t)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(S)[italic(W)]*"("*italic(t)*")"), side = 2, line = 2, cex=1.5)
mtext(text = expression(Weibull(alpha, beta)), side = 3, line = .5, cex=2)
legend('topright',
       legend=as.expression(list(bquote(alpha*" = "*.(a1)*"; "*beta*" = "*.(b1)),
                                 bquote(alpha*" = "*.(a2)*"; "*beta*" = "*.(b2)))),
       col=c('black', 'blue'), lwd=3)

```

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Note que, para $X \sim \text{Weibull}(\alpha, \beta)$, a fun√ß√£o sobreviv√™ncia $S(t)$ possui uma forma mais flex√≠vel, o que permite modelar fen√¥menos mais complexos.
:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 20:** Um mesmo produto √© montado por tr√™s f√°bricas diferentes. Sejam $T_1, T_2$ e $T_3$ os tempos de vida (em anos) do referido produto quando montado nas F√°bricas 1, 2 e 3, respectivamente, e suponha que $T_i \sim \text{Weibull}(\alpha_i, 1)$, com $\alpha_1 = 0.5$, $\alpha_2 = 1$ e $\alpha_3 = 2$.

[Determinemos $S_i(0.5) = P(T_i > 0.5)$ e $S_i(2) = P(T_i > 2)$, para $i=1, 2, 3$.]{.fragment} [Temos que
$$S_i(0.5) = e^{-0.5^{\alpha_i}} = \begin{cases}
e^{-0.5^{0.5}} = 0.4931, & i=1;\\
e^{-0.5^{1}} = 0.6065, & i=2;\\
e^{-0.5^{2}} = 0.7788, & i=3.\\
\end{cases}\ \ \ \ \text{e}\ \ \ \ S_i(2) = e^{-2^{\alpha_i}} = \begin{cases}
e^{-2^{0.5}} = 0.2431, & i=1;\\
e^{-2^{1}} = 0.1353, & i=2;\\
e^{-2^{2}} = 0.0183, & i=3.\\
\end{cases}$$]{.fragment}

:::

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

A vac $X$ tem distribui√ß√£o lognormal com par√¢metros $\mu$ e $\sigma^2$, denotada por $X \sim \text{LogN}(\mu, \sigma^2)$ se sua fdp √©
<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$f_X(x) = \frac{1}{x\sqrt{2\pi\sigma^2}}e^{-\frac{[\ln(x) - \mu]^2}{2\sigma^2}}, \ \ \ x \geq 0.$</td>
  </tr>
</table>
:::

::: fragment

::: {.callout-warning}
## Propriedades

::: incremental

1. √â poss√≠vel mostrar que, se $X \sim \text{LogN}(\mu, \sigma^2)$, ent√£o $Y = \ln(X)$ satisfaz $Y \sim \text{N}(\mu, \sigma^2)$;
2. Se $X \sim \text{LogN}(\mu, \sigma^2)$, ent√£o
<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$E(X) = e^{\mu + \frac{\sigma^2}{2}}$</td> <td>e</td> <td>$V(X) = e^{2\mu + \sigma^2}(e^{\sigma^2} - 1).$</td>
  </tr>
</table>

:::

:::

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Note que, se $X \sim \text{LogN}(\mu, \sigma^2)$, ent√£o $\mu$ e $\sigma^2$ n√£o s√£o a esperan√ßa e vari√¢ncia de $X$, mas sim de $\ln(X)$.
:::

:::

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

```{r fig.width=8, fig.height=4.5, fig.align='center'}
x <- seq(0, 10,length.out=1000)
mu1 <- -0.5; s1 <- 1
mu2 <- 1; s2 <- 1
mu3 <- 1; s3 <- 2
mu4 <- 1; s4 <- 0.3

y1 <- dlnorm(x = x, meanlog = mu1, sdlog = s1)
y2 <- dlnorm(x = x, meanlog = mu2, sdlog = s2)
y3 <- dlnorm(x = x, meanlog = mu3, sdlog = s3)
y4 <- dlnorm(x = x, meanlog = mu4, sdlog = s4)

M_y <- max(y1, y2, y3, y4)
par(family = "serif", mar=c(5,4,1,2))
plot(x, y1, type='n', xlab='', ylab='', main='', ylim=c(-.09*M_y, 1.07*M_y),
     xlim=c(min(x)-.02*diff(range(x)), max(x)+.04*diff(range(x))))

arrows(y0 = -.09*M_y, y1 = 1.07*M_y, x0=0, x1=0, length = .1, lwd=2, col='darkgray')
arrows(y0 = 0, y1 = 0, x0=min(x)-.02*diff(range(x)), x1=max(x)+.04*diff(range(x)), length = .1, lwd=2, col='darkgray')
lines(x, y1, lwd=2)
lines(x, y2, lwd=2, col='blue')
lines(x, y3, lwd=2, col='red')
lines(x, y4, lwd=2, col='purple')

mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
legend('topright',
       legend=as.expression(list(bquote(mu*" = "*.(mu1)*";"~sigma^2*" = "*.(s1^2)),
                                 bquote(mu*" = "*.(mu2)*";"~sigma^2*" = "*.(s2^2)),
                                 bquote(mu*" = "*.(mu3)*";"~sigma^2*" = "*.(s3^2)),
                                 bquote(mu*" = "*.(mu4)*";"~sigma^2*" = "*.(s4^2)))),
       col=c('black', 'blue', 'red', 'purple'), lty=1, lwd=2)
```

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-top: 12px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 21:** O artigo *Reliability of Wood Joist Floor Systems with Creep* sugere que a vac $X =$ "m√≥dulo da elasticidade de sistemas de vigas de madeira" satisfaz $X \sim \text{LogN}(0.375, 0.25^2)$. [Assim,]{.fragment fragment-index=1}
<table class="fragment" data-fragment-index="1">
  <tr style="border-bottom:none;text-align:center;">
    <td>$E(X) = e^{0.375 + \frac{0.25^2}{2}} \approx 1.5012$</td> <td>e</td>  <td>$V(X) = e^{2\cdot0.375 + 0.25^2}(e^{0.25^2} - 1) \approx 0.1453.$</td>
  </tr>
</table>
[Para obter a probabilidade do m√≥dulo da elasticidade estar entre 1 e 2, por exemplo, podemos recorrer √† transforma√ß√£o logar√≠tmica ($\ln(X) \sim \text{N}(\mu, \sigma^2)$) e transformar o problema no c√°lculo de probabilidades de uma normal padr√£o:]{.fragment fragment-index=2}
[$$\begin{align*}
P(1 \leq X \leq 2) &= \textstyle P(\ln(1) \leq \ln(X) \leq \ln(2)) = P(\frac{0-0.375}{0.25} \leq \frac{\ln(X)-0.375}{0.25} \leq \frac{0.6932-0.375}{0.25})\\
&= \textstyle P(-1.5 \leq Z \leq 1.27) = \Phi(1.27) - \Phi(-1.5) = 0.8980 - 0.0668 = 0.8312.
\end{align*}$$]{.fragment fragment-index=3}

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Todos modelos cont√≠nuos que vimos atribuem densidade em intervalos ilimitados (nos reais ou nos reais n√£o negativos). A distribui√ß√£o [**Beta**]{style="color:red;"} permite modelar vac's com suporte limitado a um intervalo $(A,B)$.
:::

:::

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

A vac $X$ possui distribui√ß√£o Beta com par√¢metros $\alpha, \beta > 0$ no intervalo $(A,B)$, denotada por $X \sim \text{Beta}(\alpha, \beta)$, se sua fdp √©
<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$f_X(x) = \frac{1}{B-A}\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}(\frac{x-A}{B-A})^{\alpha-1}(\frac{B-x}{B-A})^{\beta-1},\ \ \ \ A < X < B$.</td>
  </tr>
</table>
:::

::: fragment

::: {.callout-warning}
## Propriedade

Se $X \sim \text{Beta}(\alpha, \beta)$ em $(A,B)$, ent√£o
<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$E(X) = \mu = A + (B-A)\frac{\alpha}{\alpha+\beta}$</td> <td>e</td> <td>$V(X) = \sigma^2 = \frac{(B-A)^2\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}.$</td>
  </tr>
</table>
:::

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

O caso $A = 0$ e $B=1$ fornece a **Beta padr√£o**, isto √©, o suporte √© o intervalo $(0,1)$. Veja a figura a seguir.
:::

:::

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

```{r out.width="100%", fig.height=5}
#| layout-ncol: 2

x <- seq(0.0001, 0.9999, length.out=1000)
a1 <- 0.5; b1 <- 0.5
a2 <- 0.5; b2 <- 3
a3 <- 1; b3 <- 1
a4 <- 2; b4 <- 2
a5 <- 2; b5 <- 3

y1 <- dbeta(x, a1, b1)
y2 <- dbeta(x, a2, b2)
y3 <- dbeta(x, a3, b3)
y4 <- dbeta(x, a4, b4)
y5 <- dbeta(x, a5, b5)

Max <- min(max(y1, y2, y3, y4, y5), 4)

par(family = "serif", mar=c(5,4,2.5,2))
plot(x[y1 < 4], y1[y1 < 4], type='n', xlab='', ylab='', main='', lwd=3, ylim=c(-.07*Max, 1.07*Max), xlim=c(min(x)-.04*diff(range(x)), max(x)+.07*diff(range(x))))
arrows(y0 = -.07*Max, y1 = 1.07*Max, x0=0, x1=0, length = .1, lwd=2, col='darkgray')
arrows(y0 = 0, y1 = 0, x0=min(x)-.04*diff(range(x)), x1=max(x)+.07*diff(range(x)), length = .1, lwd=2, col='darkgray')
lines(c(1, 1), c(0, 1.05*Max), lty=3, lwd=1.5)
lines(x[y1 < 4], y1[y1 < 4], col='black', lwd=3)
lines(x[y2 < 4], y2[y2 < 4], col='blue', lwd=3)
lines(x[y3 < 4], y3[y3 < 4], col='red', lwd=3)
lines(x[y4 < 4], y4[y4 < 4], col='purple', lwd=3)
lines(x[y5 < 4], y5[y5 < 4], col='darkgreen', lwd=3)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
# mtext(text = expression(Exp(lambda)), side = 3, line = .5, cex=2)
legend('top',
       legend=as.expression(list(bquote(alpha*" = "*.(a1)*"; "*beta*" = "*.(b1)),
                                 bquote(alpha*" = "*.(a2)*"; "*beta*" = "*.(b2)),
                                 bquote(alpha*" = "*.(a3)*"; "*beta*" = "*.(b3)),
                                 bquote(alpha*" = "*.(a4)*"; "*beta*" = "*.(b4)),
                                 bquote(alpha*" = "*.(a5)*"; "*beta*" = "*.(b5)))),
       col=c('black', 'blue', 'red', 'purple', 'darkgreen'), lwd=3)

a1 <- 0.5; b1 <- 0.5
a2 <- 3; b2 <- 0.5
a3 <- 1; b3 <- 1
a4 <- 2; b4 <- 2
a5 <- 3; b5 <- 2

y1 <- dbeta(x, a1, b1)
y2 <- dbeta(x, a2, b2)
y3 <- dbeta(x, a3, b3)
y4 <- dbeta(x, a4, b4)
y5 <- dbeta(x, a5, b5)

Max <- min(max(y1, y2, y3, y4, y5), 4)

par(family = "serif", mar=c(5,4,2.5,2))
plot(x[y1 < 4], y1[y1 < 4], type='n', xlab='', ylab='', main='', lwd=3, ylim=c(-.07*Max, 1.07*Max), xlim=c(min(x)-.04*diff(range(x)), max(x)+.07*diff(range(x))))
arrows(y0 = -.07*Max, y1 = 1.07*Max, x0=0, x1=0, length = .1, lwd=2, col='darkgray')
arrows(y0 = 0, y1 = 0, x0=min(x)-.04*diff(range(x)), x1=max(x)+.07*diff(range(x)), length = .1, lwd=2, col='darkgray')
lines(c(1, 1), c(0, 1.05*Max), lty=3, lwd=1.5)
lines(x[y1 < 4], y1[y1 < 4], col='black', lwd=3)
lines(x[y2 < 4], y2[y2 < 4], col='blue', lwd=3)
lines(x[y3 < 4], y3[y3 < 4], col='red', lwd=3)
lines(x[y4 < 4], y4[y4 < 4], col='purple', lwd=3)
lines(x[y5 < 4], y5[y5 < 4], col='darkgreen', lwd=3)
mtext(text = expression(italic(x)), side = 1, line = 2, cex=1.5)
mtext(text = expression(italic(f)[italic(X)]*"("*italic(x)*")"), side = 2, line = 2, cex=1.5)
# mtext(text = expression(Exp(lambda)), side = 3, line = .5, cex=2)
legend('top',
       legend=as.expression(list(bquote(alpha*" = "*.(a1)*"; "*beta*" = "*.(b1)),
                                 bquote(alpha*" = "*.(a2)*"; "*beta*" = "*.(b2)),
                                 bquote(alpha*" = "*.(a3)*"; "*beta*" = "*.(b3)),
                                 bquote(alpha*" = "*.(a4)*"; "*beta*" = "*.(b4)),
                                 bquote(alpha*" = "*.(a5)*"; "*beta*" = "*.(b5)))),
       col=c('black', 'blue', 'red', 'purple', 'darkgreen'), lwd=3)

```

## 3.2 Modelos probabil√≠sticos cont√≠nuos {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√µes

::: incremental 

1. Note que $\alpha=\beta$ fornece fdp's sim√©tricas;
2. Se $\alpha=\beta=1$, dizemos que $X$ tem distribui√ß√£o uniforme em $(A,B)$, denotada por $X \sim \text{U}(A,B)$;
3. Ao trocar o valor de $\alpha$ pelo de $\beta$ e o de $\beta$ pelo de $\alpha$, a fdp √© refletida em torno de $\frac{A+B}{2}$;
4. O c√°lculo de probabilidades da distribui√ß√£o Beta, em geral, requer o uso de m√©todos num√©ricos. Mas, para uma Beta padr√£o com $\alpha, \beta \in \mathbb{N}$, √© poss√≠vel a sua obten√ß√£o anal√≠tica ($\Gamma(n) = (n-1)!$, $n \in \mathbb{N}$).

:::

:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-top: 12px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 22:** Suponha que o tempo $X \in (2,5)$ (em dias) para a constru√ß√£o da funda√ß√£o de uma casa satisfaz $X \sim \text{Beta}(2, 3)$. [Nesse caso, temos $A=2$ (tempo m√≠nimo) e $B=5$ (tempo m√°ximo).]{.fragment} [Assim,]{.fragment}
<table class="fragment">
  <tr style="border-bottom:none;text-align:center;">
    <td>$P(X < 3) = \int_2^3\frac{1}{5-2}\frac{\Gamma(2 + 3)}{\Gamma(2)\Gamma(3)}(\frac{x-2}{5-2})^{2-1}(\frac{5-x}{5-2})^{3-1}dx = 12\int_{0}^{\frac{1}{3}}u(1-u)^2du = \frac{4}{3}(\frac{1}{2} - \frac{2}{9} + \frac{1}{36}) \approx 0.407,$</td>
  </tr>
</table>
[em que fizemos a transforma√ß√£o $u = \frac{x-2}{3}$ na igualdade entre o 2¬∫ e o 3¬∫ termos.]{.fragment}
:::

# Vetores Aleat√≥rios Bidimensionais

## 4 Vetores Aleat√≥rios Bidimensionais {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

At√© agora, tratamos uma va isoladamente, por meio de sua fmp (se discreta), de sua fdp (se cont√≠nua), ou ainda de sua fda. Em v√°rios casos, √© de interesse estudar o comportamento conjunto de duas va's.
:::

::: fragment

::: {.callout-note}
## Defini√ß√£o

Em um experimento aleat√≥rio com espa√ßo amostral $\Omega$, considere duas va's $X = X(\omega)$ e $Y = Y(\omega)$, $\omega \in \Omega$. Dizemos que $(X,Y)$ √© um **vetor aleat√≥rio (bidimensional)**. Sejam $A_x = \{\omega \in \Omega : X(\omega) \leq x\}$ e $B_y = \{\omega \in \Omega : Y(\omega) \leq y\}$, ent√£o a fda conjunta (fdac) de $(X,Y)$ √© definida por
<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$F_{X,Y}(x,y) = P(A_x \cap B_y) = P(X \leq x, Y \leq y), \ \ \ \ x,y \in \mathbb{R}.$</td>
  </tr>
</table>
:::

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Se estiver claro a qual vetor aleat√≥rio nos referimos, podemos escrever $F(x,y)$ em vez de $F_{X,Y}(x,y)$.
:::

:::

## 4 Vetores Aleat√≥rios Bidimensionais {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Um vetor aleat√≥rio pode ser:

::: incremental

- discreto, quando ambas coordenadas s√£o discretas;
- cont√≠nuo, quando ambas coordenadas s√£o cont√≠nuas;
- misto, quando uma coordenada √© discreta e a outra cont√≠nua.

:::

:::

::: fragment

::: {.callout-note}
## Defini√ß√£o

Para um vetor aleat√≥rio $(X, Y)$ discreto, a fmp conjunta (fmpc) √© definida por
<table>
  <tr style="border-bottom:none;text-align:center;">
    <td>$p_{X,Y}(x,y) = p(x,y) = P(X = x, Y = y), \ \ \ \ x \in \text{Im}(X), \ \ \ \ y \in \text{Im}(Y).$</td>
  </tr>
</table>

:::

:::





## {.unnumbered .unlisted .smaller}

### Exemplo 23 {.unnumbered .unlisted}

Dois dados honestos de 4 faces s√£o arremessados. [Note que $\Omega = \{\omega = (z_1,z_2) : z_1, z_2 = 1,2,3,4\}$.]{.fragment fragment-index="1"} [Seja $X(\omega) = z_1 + z_2$ e $Y(\omega) = |z_1 - z_2|$. Identifiquemos $\text{Im}(X)$ e $\text{Im}(Y)$.]{style="visibility:hidden"}

::: columns

::: {.column #vcenter width=33.4%}

::: {.fragment fragment-index="1"}

<figure>
  <img src="figs/exemplo23_omega.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;">
</figure>

:::

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaX0.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:hidden;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaY0.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:hidden;">
</figure>

:::

:::

[Assim, notamos que $\text{Im}(X) = \{2, 3, \ldots, 8\}$ e $\text{Im}(Y) = \{0,1, 2, 3\}$.]{style="visibility:hidden"}






## {.unnumbered .unlisted .smaller}

### Exemplo 23 {.unnumbered .unlisted}

Dois dados honestos de 4 faces s√£o arremessados. Note que $\Omega = \{\omega = (z_1,z_2) : z_1, z_2 = 1,2,3,4\}$. Seja $X(\omega) = z_1 + z_2$ e $Y(\omega) = |z_1 - z_2|$. [Identifiquemos $\text{Im}(X)$ e $\text{Im}(Y)$.]{.fragment}

::: columns

::: {.column #vcenter width=33.4%}

<figure>
  <img src="figs/exemplo23_omega.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaX0.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:hidden;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaY0.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:hidden;">
</figure>

:::

:::

[Assim, notamos que $\text{Im}(X) = \{2, 3, \ldots, 8\}$ e $\text{Im}(Y) = \{0,1, 2, 3\}$.]{style="visibility:hidden"}







## {.unnumbered .unlisted .smaller}

### Exemplo 23 {.unnumbered .unlisted}

Dois dados honestos de 4 faces s√£o arremessados. Note que $\Omega = \{\omega = (z_1,z_2) : z_1, z_2 = 1,2,3,4\}$. Seja $X(\omega) = z_1 + z_2$ e $Y(\omega) = |z_1 - z_2|$. Identifiquemos $\text{Im}(X)$ e $\text{Im}(Y)$.

::: columns

::: {.column #vcenter width=33.4%}

<figure>
  <img src="figs/exemplo23_omega.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaX0.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:show;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaY0.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:hidden;">
</figure>

:::

:::

[Assim, notamos que $\text{Im}(X) = \{2, 3, \ldots, 8\}$ e $\text{Im}(Y) = \{0,1, 2, 3\}$.]{style="visibility:hidden"}








## {.unnumbered .unlisted .smaller}

### Exemplo 23 {.unnumbered .unlisted}

Dois dados honestos de 4 faces s√£o arremessados. Note que $\Omega = \{\omega = (z_1,z_2) : z_1, z_2 = 1,2,3,4\}$. Seja $X(\omega) = z_1 + z_2$ e $Y(\omega) = |z_1 - z_2|$. Identifiquemos $\text{Im}(X)$ e $\text{Im}(Y)$.

::: columns

::: {.column #vcenter width=33.4%}

<figure>
  <img src="figs/exemplo23_omega.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaX1.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:show;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaY0.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:hidden;">
</figure>

:::

:::

[Assim, notamos que $\text{Im}(X) = \{2, 3, \ldots, 8\}$ e $\text{Im}(Y) = \{0,1, 2, 3\}$.]{style="visibility:hidden"}








## {.unnumbered .unlisted .smaller}

### Exemplo 23 {.unnumbered .unlisted}

Dois dados honestos de 4 faces s√£o arremessados. Note que $\Omega = \{\omega = (z_1,z_2) : z_1, z_2 = 1,2,3,4\}$. Seja $X(\omega) = z_1 + z_2$ e $Y(\omega) = |z_1 - z_2|$. Identifiquemos $\text{Im}(X)$ e $\text{Im}(Y)$.

::: columns

::: {.column #vcenter width=33.4%}

<figure>
  <img src="figs/exemplo23_omega.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaX2.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:show;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaY0.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:hidden;">
</figure>

:::

:::

[Assim, notamos que $\text{Im}(X) = \{2, 3, \ldots, 8\}$ e $\text{Im}(Y) = \{0,1, 2, 3\}$.]{style="visibility:hidden"}









## {.unnumbered .unlisted .smaller}

### Exemplo 23 {.unnumbered .unlisted}

Dois dados honestos de 4 faces s√£o arremessados. Note que $\Omega = \{\omega = (z_1,z_2) : z_1, z_2 = 1,2,3,4\}$. Seja $X(\omega) = z_1 + z_2$ e $Y(\omega) = |z_1 - z_2|$. Identifiquemos $\text{Im}(X)$ e $\text{Im}(Y)$.

::: columns

::: {.column #vcenter width=33.4%}

<figure>
  <img src="figs/exemplo23_omega.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaX3.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:show;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaY0.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:hidden;">
</figure>

:::

:::

[Assim, notamos que $\text{Im}(X) = \{2, 3, \ldots, 8\}$ e $\text{Im}(Y) = \{0,1, 2, 3\}$.]{style="visibility:hidden"}







## {.unnumbered .unlisted .smaller}

### Exemplo 23 {.unnumbered .unlisted}

Dois dados honestos de 4 faces s√£o arremessados. Note que $\Omega = \{\omega = (z_1,z_2) : z_1, z_2 = 1,2,3,4\}$. Seja $X(\omega) = z_1 + z_2$ e $Y(\omega) = |z_1 - z_2|$. Identifiquemos $\text{Im}(X)$ e $\text{Im}(Y)$.

::: columns

::: {.column #vcenter width=33.4%}

<figure>
  <img src="figs/exemplo23_omega.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaX4.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:show;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaY0.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:hidden;">
</figure>

:::

:::

[Assim, notamos que $\text{Im}(X) = \{2, 3, \ldots, 8\}$ e $\text{Im}(Y) = \{0,1, 2, 3\}$.]{style="visibility:hidden"}







## {.unnumbered .unlisted .smaller}

### Exemplo 23 {.unnumbered .unlisted}

Dois dados honestos de 4 faces s√£o arremessados. Note que $\Omega = \{\omega = (z_1,z_2) : z_1, z_2 = 1,2,3,4\}$. Seja $X(\omega) = z_1 + z_2$ e $Y(\omega) = |z_1 - z_2|$. Identifiquemos $\text{Im}(X)$ e $\text{Im}(Y)$.

::: columns

::: {.column #vcenter width=33.4%}

<figure>
  <img src="figs/exemplo23_omega.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaX5.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:show;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaY0.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:hidden;">
</figure>

:::

:::

[Assim, notamos que $\text{Im}(X) = \{2, 3, \ldots, 8\}$ e $\text{Im}(Y) = \{0,1, 2, 3\}$.]{style="visibility:hidden"}







## {.unnumbered .unlisted .smaller}

### Exemplo 23 {.unnumbered .unlisted}

Dois dados honestos de 4 faces s√£o arremessados. Note que $\Omega = \{\omega = (z_1,z_2) : z_1, z_2 = 1,2,3,4\}$. Seja $X(\omega) = z_1 + z_2$ e $Y(\omega) = |z_1 - z_2|$. Identifiquemos $\text{Im}(X)$ e $\text{Im}(Y)$.

::: columns

::: {.column #vcenter width=33.4%}

<figure>
  <img src="figs/exemplo23_omega.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaX6.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:show;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaY0.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:hidden;">
</figure>

:::

:::

[Assim, notamos que $\text{Im}(X) = \{2, 3, \ldots, 8\}$ e $\text{Im}(Y) = \{0,1, 2, 3\}$.]{style="visibility:hidden"}







## {.unnumbered .unlisted .smaller}

### Exemplo 23 {.unnumbered .unlisted}

Dois dados honestos de 4 faces s√£o arremessados. Note que $\Omega = \{\omega = (z_1,z_2) : z_1, z_2 = 1,2,3,4\}$. Seja $X(\omega) = z_1 + z_2$ e $Y(\omega) = |z_1 - z_2|$. Identifiquemos $\text{Im}(X)$ e $\text{Im}(Y)$.

::: columns

::: {.column #vcenter width=33.4%}

<figure>
  <img src="figs/exemplo23_omega.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaX7.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:show;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaY0.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:hidden;">
</figure>

:::

:::

[Assim, notamos que $\text{Im}(X) = \{2, 3, \ldots, 8\}$ e $\text{Im}(Y) = \{0,1, 2, 3\}$.]{style="visibility:hidden"}







## {.unnumbered .unlisted .smaller}

### Exemplo 23 {.unnumbered .unlisted}

Dois dados honestos de 4 faces s√£o arremessados. Note que $\Omega = \{\omega = (z_1,z_2) : z_1, z_2 = 1,2,3,4\}$. Seja $X(\omega) = z_1 + z_2$ e $Y(\omega) = |z_1 - z_2|$. Identifiquemos $\text{Im}(X)$ e $\text{Im}(Y)$.

::: columns

::: {.column #vcenter width=33.4%}

<figure>
  <img src="figs/exemplo23_omega.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaX7.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:show;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaY0.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:show;">
</figure>

:::

:::

[Assim, notamos que $\text{Im}(X) = \{2, 3, \ldots, 8\}$ e $\text{Im}(Y) = \{0,1, 2, 3\}$.]{style="visibility:hidden"}







## {.unnumbered .unlisted .smaller}

### Exemplo 23 {.unnumbered .unlisted}

Dois dados honestos de 4 faces s√£o arremessados. Note que $\Omega = \{\omega = (z_1,z_2) : z_1, z_2 = 1,2,3,4\}$. Seja $X(\omega) = z_1 + z_2$ e $Y(\omega) = |z_1 - z_2|$. Identifiquemos $\text{Im}(X)$ e $\text{Im}(Y)$.

::: columns

::: {.column #vcenter width=33.4%}

<figure>
  <img src="figs/exemplo23_omega.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaX7.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:show;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaY1.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:show;">
</figure>

:::

:::

[Assim, notamos que $\text{Im}(X) = \{2, 3, \ldots, 8\}$ e $\text{Im}(Y) = \{0,1, 2, 3\}$.]{style="visibility:hidden"}








## {.unnumbered .unlisted .smaller}

### Exemplo 23 {.unnumbered .unlisted}

Dois dados honestos de 4 faces s√£o arremessados. Note que $\Omega = \{\omega = (z_1,z_2) : z_1, z_2 = 1,2,3,4\}$. Seja $X(\omega) = z_1 + z_2$ e $Y(\omega) = |z_1 - z_2|$. Identifiquemos $\text{Im}(X)$ e $\text{Im}(Y)$.

::: columns

::: {.column #vcenter width=33.4%}

<figure>
  <img src="figs/exemplo23_omega.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaX7.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:show;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaY2.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:show;">
</figure>

:::

:::

[Assim, notamos que $\text{Im}(X) = \{2, 3, \ldots, 8\}$ e $\text{Im}(Y) = \{0,1, 2, 3\}$.]{style="visibility:hidden"}







## {.unnumbered .unlisted .smaller}

### Exemplo 23 {.unnumbered .unlisted}

Dois dados honestos de 4 faces s√£o arremessados. Note que $\Omega = \{\omega = (z_1,z_2) : z_1, z_2 = 1,2,3,4\}$. Seja $X(\omega) = z_1 + z_2$ e $Y(\omega) = |z_1 - z_2|$. Identifiquemos $\text{Im}(X)$ e $\text{Im}(Y)$.

::: columns

::: {.column #vcenter width=33.4%}

<figure>
  <img src="figs/exemplo23_omega.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaX7.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:show;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaY3.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:show;">
</figure>

:::

:::

[Assim, notamos que $\text{Im}(X) = \{2, 3, \ldots, 8\}$ e $\text{Im}(Y) = \{0,1, 2, 3\}$.]{style="visibility:hidden"}






## {.unnumbered .unlisted .smaller}

### Exemplo 23 {.unnumbered .unlisted}

Dois dados honestos de 4 faces s√£o arremessados. Note que $\Omega = \{\omega = (z_1,z_2) : z_1, z_2 = 1,2,3,4\}$. Seja $X(\omega) = z_1 + z_2$ e $Y(\omega) = |z_1 - z_2|$. Identifiquemos $\text{Im}(X)$ e $\text{Im}(Y)$.

::: columns

::: {.column #vcenter width=33.4%}

<figure>
  <img src="figs/exemplo23_omega.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaX7.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:show;">
</figure>

:::

::: {.column #vcenter width=33.3%}

<figure>
  <img src="figs/exemplo23_omega_vaY4.png" style="display: block;margin-left: auto;margin-right: auto;width: 90%;visibility:show;">
</figure>

:::

:::

[Assim, notamos que $\text{Im}(X) = \{2, 3, \ldots, 8\}$ e $\text{Im}(Y) = \{0,1, 2, 3\}$.]{.fragment}



## 4. Vetores Aleat√≥rios Bidimensionais {.unnumbered .unlisted}


::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

::: columns

::: {.column #vcenter width=30%}

<figure>
  <img src="figs/exemplo23_omega_vasXY.png" style="display: block;margin-left: auto;margin-right: auto;width: 95%;visibility:show;">
</figure>

:::

::: {.column #vcenter width=70%}

::: fragment

**Exemplo: 23 (cont.)** A fmpc $p(x,y)$ pode ser representada pela tabela:

<table class="tblcenter" style="margin-left: auto; margin-right: auto;">
  <tr style="border-top:solid 3pt; border-bottom:solid 1pt; text-align:center;">
    <td style="border-right:solid 1pt">$y\backslash x$</td> <td> $2$ </td> <td> $3$ </td> <td> $4$ </td> <td> $5$ </td> <td> $6$ </td> <td> $7$ </td> <td> $8$ </td>
  </tr>
  <tr class='fragment' style="text-align:center;">
    <td style="border-right:solid 1pt">$0$</td> <td> $\frac{1}{16}$ </td> <td> $0$ </td> <td> $\frac{1}{16}$ </td> <td> $0$ </td> <td> $\frac{1}{16}$ </td> <td> $0$ </td> <td> $\frac{1}{16}$ </td>
  </tr>
  <tr class='fragment' style="text-align:center;">
    <td style="border-right:solid 1pt">$1$</td> <td> $0$ </td> <td> $\frac{2}{16}$ </td> <td> $0$ </td> <td> $\frac{2}{16}$ </td> <td> $0$ </td> <td> $\frac{2}{16}$ </td> <td> $0$ </td>
  </tr>
  <tr class='fragment' style="text-align:center;">
    <td style="border-right:solid 1pt">$2$</td> <td> $0$ </td> <td> $0$ </td> <td> $\frac{2}{16}$ </td> <td> $0$ </td> <td> $\frac{2}{16}$ </td> <td> $0$ </td> <td> $0$ </td>
  </tr>
  <tr class='fragment' style="border-bottom:solid 3pt; text-align:center;">
    <td style="border-right:solid 1pt">$3$</td> <td> $0$ </td> <td> $0$ </td> <td> $0$ </td> <td> $\frac{2}{16}$ </td> <td> $0$ </td> <td> $0$ </td> <td> $0$ </td>
  </tr>
</table>

:::

:::

:::

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Pela fmpc, fica evidente que os valores de $X$ alteram o comportamento probabil√≠stico de $Y$ e vice-versa. Isto √©, que essas vari√°veis s√£o **dependentes**!
:::

:::

## 4. Vetores Aleat√≥rios Bidimensionais {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√µes

1. Pela fmpc, podemos obter probabilidades conjuntas para eventos de interesse;
2. A fmp de apenas uma va √© obtida da fmpc somando $p(x,y)$ em todos os valores da outra vari√°vel;
3. Nesse contexto, essa fmp univariada √© chamada de fmp **marginal**.

:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-top: 12px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo 23 (cont.):** A probabilidade $P(X \geq 7, Y \leq 1)$ pode ser obtida como
<table style="margin-left: auto; margin-right: auto;">
  <tr style="border-bottom:none">
    <td>$P(X \geq 7, Y \leq 1) = \sum_{x\geq 7}\sum_{y\leq 1} p(x,y) = p(7, 0) + p(7, 1) + p(8, 0) + p(8, 1) = 0 + \frac{1}{16} + \frac{2}{16} + 0 = \frac{3}{16}.$</td>
  </tr>
</table>
As fmp's marginais de $X$ e $Y$ s√£o

::: columns

::: {.column #vcenter width=57%}

<table class="tblcenter" style="margin-left: auto; margin-right: auto;">
  <tr style="border-bottom:solid 1pt; border-top:solid 3pt">
    <td style="border-right:solid 1pt">$x$</td> <td>$2$</td> <td>$3$</td> <td>$4$</td> <td>$5$</td> <td>$6$</td> <td>$7$</td> <td>$8$</td>
  </tr>
  <tr style="border-bottom:solid 3pt">
    <td style="border-right:solid 1pt">$p_X(x)$</td> <td>$\frac{1}{16}$</td> <td>$\frac{2}{16}$</td> <td>$\frac{3}{16}$</td> <td>$\frac{4}{16}$</td> <td>$\frac{3}{16}$</td> <td>$\frac{2}{16}$</td> <td>$\frac{1}{16}$</td>
  </tr>
</table>

:::

::: {.column #vcenter width=5%}

e

:::

::: {.column #vcenter width=38%}

<table class="tblcenter" style="margin-left: auto; margin-right: auto;">
  <tr style="border-bottom:solid 1pt; border-top:solid 3pt">
    <td style="border-right:solid 1pt">$y$</td> <td>$0$</td> <td>$1$</td> <td>$2$</td> <td>$3$</td>
  </tr>
  <tr style="border-bottom:solid 3pt">
    <td style="border-right:solid 1pt">$p_Y(y)$</td> <td>$\frac{4}{16}$</td> <td>$\frac{6}{16}$</td> <td>$\frac{4}{16}$</td> <td>$\frac{2}{16}$</td>
  </tr>
</table>

:::

:::

:::


## 4. Vetores Aleat√≥rios Bidimensionais {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedades

Seja $(X,Y)$ vetor aleat√≥rio discreto com fmpc $p(x,y)$, ent√£o:

1. $p(x,y) \geq 0$, $\forall\ x,y$;
2. $\sum_{x \in \text{Im}(X)}\sum_{y \in \text{Im}(Y)} p(x,y) = 1$.
:::

::: {.callout-caution}
## Observa√ß√£o

Toda fun√ß√£o que satisfa√ßa as propriedades acima ser√° denominada fmpc. Assim, podemos especificar diretamente a fmpc, contornando a necessidade de criar um modelo probabil√≠stico em $\Omega$.
:::


## Covari√¢ncia e Correla√ß√£o

# Fun√ß√µes de Vari√°veis Aleat√≥rias

# FIM {.unnumbered .unlisted}

# APAGAR DPS 1 {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

:::

::: {.callout-note}
## Defini√ß√£o

:::

::: {.callout-warning}
## Propriedade

:::

::: {.callout-tip}
## Exerc√≠cios

:::

::: {.callout-important}
## Problema

:::


::: {style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo:** 

::: 

# APAGAR DPS 2 {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=45%}
1
:::

::: {.column #vcenter width=55%}
2

3

4
:::

:::



```{=latex}
\begin{align*}
\Omega &= \{(1,1), (1,2), \ldots, (4,4)\}\\
       &= \{(x,y) : x,y = 1,\ldots,4\}.
\end{align*}
```


# FIM {.unnumbered .unlisted}
