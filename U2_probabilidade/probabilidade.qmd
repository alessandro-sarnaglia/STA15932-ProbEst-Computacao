---
title: "Probabilidade e Estat√≠stica"
subtitle: "Probabilidade de Eventos"
author: "Prof. Dr. Alessandro JQ Sarnaglia"
lang: "pt"
format:
  revealjs:
    width: 1280
    height: 720
    min-scale: 0.1
    fig-width: 5.5
    fig-height: 5.5
    theme: [custom.scss]
    css: [fonts.css, style.css]
    callout-icon: false
    toc: true
    toc-depth: 3
    toc-expand: 3
    number-sections: true
    number-depth: 3
    footer: "[T√≥picos üîô](../index.html) | [Sum√°rio üìã](/probabilidade.html#/TOC)"
    menu:
      useTextContentForMissingTitles: false
editor: source
filters:
  - parse-latex
---

# Experimentos Aleat√≥rios

## 1 Experimentos Aleat√≥rios {.unnumbered .unlisted}

Ao medir a corrente em um fio, estamos conduzindo um **experimento**.

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Se repetirmos o experimento acima diversas vezes, observaremos que os resultados diferem levemente de uma repeti√ß√£o para outra.
:::

::: 

::: fragment

Isso ocorre, pois v√°rios fatores podem influenciar o resultado. Por exemplo:

:::

::: incremental

-   Varia√ß√µes na temperatura ambiente no momento da realiza√ß√£o;
-   Varia√ß√µes nos equipamentos utilizados para realizar a medi√ß√£o;
-   Impurezas na composi√ß√£o qu√≠mica do fio;
-   Impulsos na fonte da corrente.

:::

## 1 Experimentos Aleat√≥rios {.unnumbered .unlisted}

N√£o importa quanto cuidado teremos no planejamento e na condu√ß√£o do experimento, sempre existem vari√°veis de peturba√ß√£o (ou ru√≠do) que n√£o s√£o controladas.

::: fragment

Isso provoca aleatoriedade (ou incerteza) dos resultados obtidos em diferentes realiza√ß√µes do experimento.

:::

::: fragment

::: {.callout-note}
## Defini√ß√£o

Dizemos que um experimento √© aleat√≥rio se, mesmo quando repetido sob "condi√ß√µes id√™nticas", n√£o √© poss√≠vel predizer com absoluta certeza o seu resultado. Vamos denotar um experimento aleat√≥rio por $\mathcal{E}$.
:::

:::

## Espa√ßo Amostral

Devido a sua natureza, n√£o √© poss√≠vel antever com absoluta certeza o resultado de um experimento aleat√≥rio

::: fragment

Exemplos:

:::

::: incremental

-   $\mathcal{E}_1$ = "uma pe√ßa √© fabricada em uma linha de produ√ß√£o e, depois de inspecionada, √© classificada como *defeituosa* ($D$) ou *n√£o defeituosa* ($N$)";
-   $\mathcal{E}_2$ = "o n√∫mero de liga√ß√µes que chega em determinado dia a um call center √© observado";
-   $\mathcal{E}_3$ = "o tempo em minutos necess√°rio para realizar uma rea√ß√£o qu√≠mica √© observado".

:::

## 1.1 Espa√ßo Amostral {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Embora n√£o saibamos o resultado que um experimento fornecer√°, devemos poder listar todos os seus poss√≠veis resultados
:::

::: fragment

::: {.callout-note}
## Defini√ß√£o

O [conjunto de todos]{.underline} poss√≠veis resultados de um experimento aleat√≥rio √© denominado **espa√ßo amostral** e √© denotado por $\Omega$.
:::

:::

## 1.1 Espa√ßo Amostral {.unlisted .unnumbered}

Nos exemplos anteriores os espa√ßos amostrais seriam:

::: incremental
-   Em $\mathcal{E}_1$, ter√≠amos $\Omega_1 = \{D, N\}$;
-   Em $\mathcal{E}_2$, ter√≠amos $\Omega_2 = \{0, 1, 2, \ldots\}$;
-   Em $\mathcal{E}_3$, ter√≠amos $\Omega_3 = \{\omega : \omega > 0\} = (0, \infty)$
:::

::: fragment

Suponha que os exemplos anteriores sejam repetidos 2 vezes. Os espa√ßos amostrais agora passam a ser:

:::

::: incremental
-   $\Omega_1^* = \Omega_1 \times \Omega_1 = \{DD, DN, ND, NN\}$;
-   $\Omega_2^* = \Omega_2 \times \Omega_2 = \{(0,0), (0,1), (0,2), \ldots (1,0), (1,1), (1,2), \ldots\}$;
-   $\Omega_3^* = \Omega_3 \times \Omega_3 = \{\omega=(x,y) : x,y > 0\}$.
:::

## 1.1 Espa√ßo Amostral {.unlisted .unnumbered}

::: columns

::: {.column width="50%"}

![Ilustra√ß√£o de $\Omega_2^*$](figs/espaco_amostral1.png){width=80%}

:::

::: {.column width="50%"}

![Ilustra√ß√£o de $\Omega_3^*$](figs/espaco_amostral2.png){width=80%}

:::

:::

## Eventos

::: {.callout-note}
## Defini√ß√£o

Sejam $A, B$ dois conjuntos quaisquer, se todos elementos de $A$ pertencem a $B$, dizemos que $A$ est√° contido em $B$ ($A$ √© subconjunto de $B$). Neste caso, escrevemos $A \subset B$.
:::

::: {.callout-caution}
## Observa√ß√£o

Note que $A \subset B$ √© equivalente a $\forall \omega \in A,\ \omega \in B$.

:::

## 1.2 Eventos {.unlisted .unnumbered}

::: {style="font-size:80%;"}

Em geral, ao observar um experimento, n√£o estamos interessados apenas em um resultado, mas sim em uma cole√ß√£o destes. Isto √©, em um subconjunto do espa√ßo amostral.

:::

::: {.callout-note}
## Defini√ß√£o

Um **evento** √© qualquer subconjunto do espa√ßo amostral de um experimento aleat√≥rio. Frequentemente, eventos s√£o denotados por letras iniciais do alfabeto mai√∫sculas: $A, B, C, \ldots$.

:::

::: {style="font-size:80%;"}

Exemplos de eventos nos espa√ßos amostrais $\Omega_1^*$, $\Omega_2^*$ e $\Omega_3^*$:

::: incremental
-   $A_1 =$ "Pelo menos uma pe√ßa defeituosa" $= \{DD, DN, ND\}$;
-   $A_2 =$ "Receber 4 liga√ß√µes no total" $= \{(0, 4), (1, 3), (2, 2), (3, 1), (4, 0)\}$;
-   $A_3 =$ "As duas rea√ß√µes terminarem em 5 minutos ou mais no total" $= \{(x , y) \in \Omega_3^* : x + y \geq 5\}$.
::: 

:::

## 1.2 Eventos {.unlisted .unnumbered}

::: columns

::: {.column width="50%"}

![Ilustra√ß√£o de $A_2$ em $\Omega_2^*$](figs/espaco_amostral1_evento.png){width=80%}

:::

::: {.column width="50%"}

![Ilustra√ß√£o de $A_3$ em $\Omega_3^*$](figs/espaco_amostral2_evento.png){width=80%}

:::

:::

## 1.2 Eventos {.unlisted .unnumbered}


::: {.callout-note}
## Defini√ß√£o

O evento com nenhum elemento √© denominado **vazio** e √© denotado por $\emptyset$. Isto √© $\emptyset = \{\;\}$.
:::

::: {.callout-caution}
## Observa√ß√£o

Dois eventos $A, B \subset \Omega$ s√£o iguais se $A \subset B$ e $B \subset A$. Escrevemos $A = B$.
:::

## 1.2 Eventos {.unlisted .unnumbered}

Sejam $A, B \subset \Omega$ dois eventos. Podemos criar novos eventos a partir de $A$ e $B$ por meio de opera√ß√µes de conjuntos.


::: {.callout-note}
## Defini√ß√µes

-   **Interse√ß√£o** √© denotada por $A \cap B$ e definida por $A \cap B = \{\omega \in \Omega: \omega \in A$ e $\omega \in B$, simultaneamente$\}$.
-   **Uni√£o** √© denotada por $A \cup B$ e definida por $A \cup B = \{\omega \in \Omega: \omega \in A$, ou $\omega \in B$, ou $\omega \in A \cap B\}$.
-   **Complementar** √© denotado por $A^c$ e definido por  $A^c = \{\omega \in \Omega: \omega \not\in A\}$.
:::

::: {.callout-caution}
## Observa√ß√µes

-   $A \cap B$ representa a ocorr√™ncia **simult√¢nea** dos eventos $A$ e $B$;
-   $A \cup B$ representa a ocorr√™ncia de **ao menos um** dos eventos $A$ ou $B$;
-   $A^c$ representa a n√£o ocorr√™ncia do evento $A$.
:::

## 1.2 Eventos {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedades

1.    $[A^c]^c = A$;
2.    $[A \cap B]^c = A^c \cup B^c$;
3.    $[A \cup B]^c = A^c \cap B^c$;
4.    $A \cup A^c = \Omega$;
5.    $A \cap A^c = \emptyset$;
6.    $[\bigcap_{i=1}^n A_i]^c = [A_1 \cap \cdots \cap A_n]^c = [A_1^c \cup \cdots \cup A_n^c] = \bigcup_{i=1}^n A_i^c$;
7.    $[\bigcup_{i=1}^n A_i]^c = [A_1 \cup \cdots \cup A_n]^c = [A_1^c \cap \cdots \cap A_n^c] = \bigcap_{i=1}^n A_i^c$.
:::

## 1.2 Eventos {.unnumbered .unlisted}

As opera√ß√µes entre eventos podem ser ilustradas utilizando diagramas de Venn.

![Ilustra√ß√£o de $A \cap B$](figs/diagrama_de_venn_intersecao.png){width=80%}

## 1.2 Eventos {.unnumbered .unlisted}

As opera√ß√µes entre eventos podem ser ilustradas utilizando diagramas de Venn.

![Ilustra√ß√£o de $A \cup B$](figs/diagrama_de_venn_uniao.png){width=80%}

## 1.2 Eventos {.unnumbered .unlisted}

As opera√ß√µes entre eventos podem ser ilustradas utilizando diagramas de Venn.

![Ilustra√ß√£o de $A^c$](figs/diagrama_de_venn_complementar.png){width=80%}

## 1.2 Eventos {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=45%}

::: {.callout-note}
## Defini√ß√£o

Dois eventos $A, B \subset \Omega$ s√£o **disjuntos** se $A \cap B = \emptyset$.
:::

:::

::: {.column #vcenter width=5%}

:::

::: {.column #vcenter width=50%}

![](figs/diagrama_de_venn_disjuntos.png)

:::

:::


::: {.callout-note}
## Defini√ß√£o

Uma sequ√™ncia de eventos $A_1, A_2, \ldots \subset \Omega$ √© **mutuamente exclusiva** se os eventos s√£o disjuntos dois a dois, isto √©, se $A_i \cap A_j = \emptyset$, $i \neq j$.
:::

# Modelo Probabil√≠stico 

## Medida de Probabilidade

::: {.callout-note}
## Defini√ß√£o - Axiomas de Probabilidade

Uma medida de probabilidade √© qualquer fun√ß√£o de eventos $P(\cdot)$ que satisfa√ßa as seguintes propriedades:

1.    $P(\Omega) = 1$;
2.    $P(A) \geq 0$, para todo evento $A \subset \Omega$;
3.    $P(A \cup B) = P(A) + P(B)$, se $A, B \subset \Omega$ s√£o disjuntos, isto √©, se $A \cap B = \emptyset$.
:::

::: {.callout-caution}
## Observa√ß√µes

-   Os axiomas de probabilidade n√£o determinam probabilidades, mas servem como base te√≥rica para novas defini√ß√µes e propriedades.
-   O modelo probabil√≠stico deve ser concebido com base no nosso conhecimento sobre o experimento aleat√≥rio, de modo que obede√ßa os axiomas acima.
:::

## {.unnumbered .unlisted}

### Propriedades {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedades

Sejam $\Omega$ espa√ßo amostral, $A, B \subset \Omega$ eventos e $P(\cdot)$ medida de probabilidade. Temos que:

1.    $P(\emptyset) = 0$;
2.    $P(A^c) = 1 - P(A)$;
3.    Se $A \subset B$, ent√£o $P(A) \leq P(B)$;
4.    Definindo $B - A = B\cap A^c$, ent√£o $P(B - A) = P(B) - P(A \cap B)$;
5.    Se $A\subset B$, ent√£o $P(B - A) = P(B) - P(A)$;
6.    $P(A \cup B) = P(A) + P(B) - P(A \cap B)$;
:::

::: {.callout-tip}
## Exerc√≠cios

1.    Como o Item 6 se extende para $P(A \cup B \cup C)$?
2.    Mostre que $P(A \cup B \cup C) \leq P(A) + P(B) + P(C)$.
:::

## {.unnumbered .unlisted}

### Exemplo {.unnumbered .unlisted}

Discos de policarbonato pl√°stico s√£o analisados com rela√ß√£o a suas resist√™ncias a arranh√µes e a choque. Os resultados s√£o resumidos a seguir:

::: columns

::: {.column #vcenter width=45%}

![](figs/tabela_discos_policarbonato.png)
:::

::: {.column #vcenter width=55%}
Um disco ser√° selecionado. Sejam $A =$ "resist. a arranh√µes alta" e $B =$ "resist. a choques alta". Quais as probabilidades dos eventos:

-   $P(A \cap B)$;
-   $P(A \cup B)$;
-   $P(B - A)$.
:::

:::

## Espa√ßo Amostral Equiprov√°vel

::: {.callout-caution}
## Observa√ß√£o

Muitos experimentos aleat√≥rios satisfazem as seguintes caracter√≠sticas:

1.    O espa√ßo amostral $\Omega$ √© finito, isto √©, $\Omega = \{\omega_1, \dots, \omega_N\}$, $N<\infty$;
2.    √â razo√°vel assumir que todos os pontos de $\Omega$ ocorrem com a mesma probabilidade.

Exemplos:

-   lan√ßamento de uma moeda honesta;
-   arremesso de um dado n√£o viciado;
-   qualquer tipo de sorteio de $N$ "elementos" **ao acaso**.
:::

::: {.callout-note}
## Defini√ß√£o

Um espa√ßo amostral $\Omega$ satisfazendo as caracter√≠sticas acima √© dito ser **equiprov√°vel**.
:::

## 2.2 Espa√ßo Amostral Equiprov√°vel {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Em um experimento $\mathcal{E}$ com espa√ßo amostral $\Omega = \{\omega_1, \dots, \omega_N\}$ equiprov√°vel, se $N(A)$ representa o n√∫mero de elementos em $A$, ent√£o
$$P(A) = \frac{N(A)}{N}$$
√© uma medida de probabilidade em conson√¢ncia com os axiomas.
:::

::: {.callout-caution}
## Observa√ß√£o

A medida **equiprov√°vel** definida acima atribui a mesma probabilidade para todos pontos de $\Omega$, isto √©
$$P(\{\omega_i\}) = \frac{1}{N}, \ \ \ i=1, \ldots, N.$$
:::

## {.unnumbered .unlisted}

### Exemplo {.unnumbered .unlisted}

Dois dados [**honestos**]{style="color:red; "} de quatro faces s√£o arremessados e o n√∫mero de pontos voltados para cima s√£o registrados.

::: columns

::: {.column width=50%}

::: {.fragment fragment-index=1}

Nesse caso, temos:
```{=latex}
\begin{align*}
\Omega &= \{(1,1), (1,2), \ldots, (4,4)\}\\
       &= \{(x,y) : x,y = 1,\ldots,4\}.
\end{align*}
```

:::

:::

::: {.column width=50%}

::: {.fragment fragment-index=1}

![](figs/exemplo_dois_dados_4_faces_espaco_amostral.png){width=75%}

:::

:::

:::

## {.unnumbered .unlisted}

### Exemplo {.unnumbered .unlisted}

Dois dados [**honestos**]{style="color:red; "} de quatro faces s√£o arremessados e o n√∫mero de pontos voltados para cima s√£o registrados.

::: columns

::: {.column width=50%}

Nesse caso, temos:
```{=latex}
\begin{align*}
\Omega &= \{(1,1), (1,2), \ldots, (4,4)\}\\
       &= \{(x,y) : x,y = 1,\ldots,4\}.
\end{align*}
```

Se $A_j=$ "$j$ pontos no total", temos
$$N(A_j) = \begin{cases}
j-1, & j=2,\ldots,5;\\
8-j+1, & j=6,\ldots,8;\\
\end{cases}$$

:::

::: {.column width=50%}

![](figs/exemplo_dois_dados_4_faces_eventos.png){width=75%}

:::

:::

## {.unnumbered .unlisted}

### Exemplo {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Os eventos $A_2, A_3, \ldots, A_8$ formam o que chamamos de **parti√ß√£o** de $\Omega$.
:::

::: {.callout-note}
## Defini√ß√£o

A sequ√™ncia (possivelmente infinita) de eventos $A_1, A_2, \ldots \subset \Omega$ forma uma **parti√ß√£o** de $\Omega$ se
$$\bigcup_{i=1}^\infty A_i = \Omega \ \ \ \text{e} \ \ \ A_i \cap A_j = \emptyset, \ i \neq j.$$
:::

## {.unnumbered .unlisted}

### Exemplo {.unnumbered .unlisted}

Com base na equiprobabilidade de $\Omega$ (os dados s√£o **honestos**) e nos valores de $N(A_j)$ e $N$, podemos utilizar a medida de probabilidade definida anteriormente para obter

<table>
  <tr style="border-top:2px solid; border-bottom:1px solid; ">
    <td style="border-right:2px solid"> **Evento** ($A_j$) </td> <td> $A_2$ </td> <td> $A_3$
    </td> <td> $A_4$ </td> <td> $A_5$ </td> <td> $A_6$ </td> <td> $A_7$ </td> <td> $A_8$ </td>
  </tr>
  <tr style="border-bottom:2px solid; ">
    <td style="border-right:2px solid"> $P(A_j)$ </td> <td> $\frac{1}{16}$ </td> <td> $\frac{2}{16}$ </td>
    <td> $\frac{3}{16}$ </td> <td> $\frac{4}{16}$ </td> <td> $\frac{3}{16}$ </td> <td> $\frac{2}{16}$ </td>
    <td> $\frac{1}{16}$ </td>
  </tr>
</table>

::: {.callout-caution}
## Observa√ß√£o

Pelo fato de $A_2, A_3, \ldots, A_8$ formar uma **parti√ß√£o**, temos que
$$\textstyle P\left(\bigcup_{i=2}^8 A_i\right) = P(\Omega) = 1 \ \ \ \ \text{ou ainda} \ \ \ \ P\left(\bigcup_{i=2}^8 A_i\right) = \sum_{i=2}^8P(A_i) = \frac{1+2+3+4+3+2+1}{16} = \frac{16}{16} = 1.$$
:::

## 2.2 Espa√ßo Amostral Equiprov√°vel {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

A conclus√£o que se chega √© que, em [espa√ßos amostrais equiprov√°veis]{.underline}, a atribui√ß√£o de probabilidades se reduz a uma mera opera√ß√£o de contagem de elementos que comp√µem o evento em quest√£o.
:::

::: {.callout-important}
## Problema

Nos casos em que o tamanho $N$ do espa√ßo amostral equiprov√°vel √© muito grande, essa tarefa pode ser tediosa.
:::

:::{.callout-caution}
## Observa√ß√£o

Em alguns casos em que $N$ √© grande, [t√©cnicas de contagem]{.underline} podem ser bastante √∫teis.
:::


## T√©cnicas de Contagem {.smaller}

Como dito anteriormente, quando $\Omega$ √© **equiprov√°vel**, a probabilidade de um evento $A$ √© $P(A) = \frac{N(A)}{N}$. Existem v√°rias t√©cnicas de contagem que podem nos ajudar na determina√ß√£o de $N(A)$ e $N$.

:::{.callout-note}
## Defini√ß√£o - Regra do produto para pares ordenados

Suponha que os elementos de $\Omega$ s√£o dados pelos **pares ordenados** $\omega = (z_1, z_2)$. Se existirem:

1.    $N_1$ formas favor√°veis a $A$ de escolher $z_1$; e
2.    $N_2$ formas favor√°veis a $A$ de escolher $z_2$ para cada uma das $N_1$ formas de escolher $z_1$,

ent√£o
$$N(A) = N_1 \cdot N_2.$$
:::

::: {.callout-caution}
## Observa√ß√£o

A regra acima s√≥ √© v√°lida se o $N_2$ n√£o depende do valor espec√≠fico escolhido para $z_1$. Mais detalhes no exemplo a seguir.
:::

## {.unnumbered .unlisted}

### Exemplo {.unnumbered .unlisted}

Num conselho h√° 6 homens ($H$) e 8 mulheres ($M$), totalizando 14 pessoas. As pessoas que ocupar√£o os cargos de diretor e vice-diretor ser√£o escolhidas [**ao acaso**]{style="color:red;"}. Pergunta-se:

1.    H√° quantas maneiras poss√≠veis de escolhermos os cargos?
2.    Quantas configura√ß√µes tem um presidente e uma vice-presidente (evento $A$) e qual a probabilidade associada?
3.    Quantas configura√ß√µes tem um homem e uma mulher (evento $B$) e qual a probabilidade associada?
4.    Em quantas configura√ß√µes todos cargos s√£o ocupados por mulheres (evento $C$) e qual a probabilidade associada?

## {.unnumbered .unlisted .smaller}

### Exemplo {.unnumbered .unlisted}

Podemos escrever os elementos de $\Omega$ como $\omega = (z_1, z_2)$, em que $z_1$ √© pessoa escolhida para diretor e $z_2$ √© a pessoa escolhida para vice-diretor.

::: incremental

1.    Trata-se de determinar $N = N(\Omega)$. Note que $z_1$ e $z_2$ t√™m, respectivamente, $N_1 = 14$ e $N_2 = 13$ possibilidades, pois a mesma pessoa n√£o pode ocupar ambos os cargos. Assim, $N = N(\Omega) = N_1 \cdot N_2 = 14 \cdot 13 = 182$;
2.    Trata-se de determinar $N(A)$. Nesse caso, $z_1$ e $z_2$ t√™m, respectivamente, $N_1 = 6$ e $N_2 = 8$ possibilidades favor√°veis a $A$ ($z_1$ homem e $z_2$ mulher). Logo, $N(A) = 6 \cdot 8 = 48$. Da√≠, $P(A) = \frac{N(A)}{N} = \frac{48}{182} = 0\text{,}2637$;
3.    Trata-se de determinar $N(B)$. Os $\omega = (z_1, z_2)$ favor√°veis a $B$ podem ser divididos em: $z_1$ e $z_2$ t√™m $N_1 = 6$ e $N_2 = 8$ possibilidades ($z_1$ homem e $z_2$ mulher); [**ou**]{style="color:red;"} $z_1$ e $z_2$ t√™m $N_1 = 8$ e $N_2 = 6$ possibilidades ($z_1$ mulher e $z_2$ homem). Logo, $N(B) = 6 \cdot 8 \color{red}{+} 8 \cdot 6 = 2 \cdot 6 \cdot 8 = 96$. Da√≠, $P(B) = \frac{N(B)}{N} = \frac{96}{182} = 0\text{,}5275$;
4.    Trata-se de determinar $N(C)$. Nesse caso, $z_1$ e $z_2$ t√™m, respectivamente, $N_1 = 8$ e $N_2 = 7$ possibilidades favor√°veis a $C$ ($z_1$ mulher e $z_2$ mulher diferente de $z_1$). Logo, $N(C) = 8 \cdot 7 = 56$. Da√≠, $P(C) = \frac{N(C)}{N} = \frac{56}{182} = 0\text{,}3077$.

:::

## {.unnumbered .unlisted}

### Exemplo {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√µes

<ul>
  <li>Nos Itens:
    <ol>
      <li class=fragment>N√£o h√° restri√ß√£o para os elementos que comp√µem o evento, por isso se trata de $\Omega$;</li>
      <li class=fragment>A restri√ß√£o imposta por $A$ √© que $z_1$ deve ser homem e $z_2$ deve sere mulher, assim, para cada um dos $N_1 = 6$ homens no cargo de diretor, podemos escolher $N_2 = 8$ mulheres para vice-diretora;</li>
      <li class=fragment>O evento $B$ imp√µe que: se $z_1$ √© homem, ent√£o $z_2$ deve ser mulher; ou, se $z_1$ √© mulher, ent√£o $z_2$ deve ser homem. Se escolhemos $z_1 = H$ ($N_1 = 6$), devemos escolher $z_2 = M$ ($N_2 = 8$). Por outro lado, se escolhemos $z_1 = M$ ($N_1 = 8$), devemos escolher $z_2 = H$ ($N_2 = 6$);</li>
      <li class=fragment>A restri√ß√£o imposta por $C$ √© que $z_1$ e $z_2$ devem ser mulheres.Assim, $N_1 = 8$. Como $z_1$ n√£o pode se repetir, restam apenas $7$ possibilidades para $z_2$ ($N_2=7$).</li>
    </ol>
  </li>
  <li class=fragment>O c√°lculo de $N(B)$ no Item 3 equivale a calcular as possibilidades de $(z_1 = H, z_2 = M)$, equivalente a $N(A)$, e ent√£o multiplicar pelas permuta√ß√µes entre os (dois) cargos. Al√©m disso, o elemento escolhido para $z_1$ influenciou a quantidade $N_2$. Por isso separamos em dois casos.</li>
</ul>

:::


## 2.3 T√©cnicas de Contagem {.unnumbered .unlisted}

:::{.callout-note}
## Defini√ß√£o - Regra do produto para $k$-tuplas

Uma [$m$-tupla]{style="color:red;"} √© um conjunto ordenado $(z_1, z_2, \ldots, z_m)$ de $m$ objetos. Suponha que os elementos de $\Omega$ s√£o dados $k$-tuplas $\omega = (z_1, z_2, \ldots, z_m)$. Se:

1.    existirem $N_1$ formas favor√°veis a $A$ de escolher $z_1$;
2.    existirem $N_2$ formas favor√°veis a $A$ de escolher $z_2$ para cada uma das $N_1$ formas de escolher $z_1$;
3.    existirem $N_3$ formas favor√°veis a $A$ de escolher $z_3$ para cada uma das $N_1 \cdot N_2$ formas de escolher $(z_1, z_2)$;
4.    e, em geral, existirem $N_j$ formas favor√°veis a $A$ de escolher $z_j$ para cada uma das $N_1 \cdot N_2  \cdot \cdots \cdot N_{j-1}$ formas de escolher $(z_1, z_2, \ldots, z_{j-1})$, $j > 1$,

ent√£o
$$N(A) = N_1 \cdot N_2 \cdot N_3 \cdot \cdots \cdot N_m.$$
:::

## {.unnumbered .unlisted}

### Exemplo {.unnumbered .unlisted}

Como ficaria o exemplo anterior se, al√©m dos cargos de diretor ($z_1$) e vice-diretor ($z_2$), tiv√©ssemos o cargos de tesoureiro ($z_3$)?

::: incremental

1.    Agora $N = 14 \cdot 13 \cdot 12 = 2184$;
2.    Agora $N(A) = 6 \cdot 8 \cdot 12 = 576$ e $P(A) = \frac{576}{2184} = 0\text{,}2637$;
3.    Agora $N(B) = 6 \cdot 8 \cdot 12 + 8 \cdot 6 \cdot 12 = 1152$ e $P(B) = \frac{1152}{2184} = 0\text{,}5275$;
4.    Agora $N(C) = 8 \cdot 7 \cdot 6 = 336$ e $P(C) = \frac{336}{2184} = 0\text{,}1539$.
:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Novamente, no Item 3, o elemento escolhido para $z_1$ influenciou a quantidade $N_2$.
:::

:::

## 2.3 T√©cnicas de Contagem {.unnumbered .unlisted}

:::{.callout-note}
## Defini√ß√£o - Arranjo Sem Reposi√ß√£o

A quantidade de $m$-tuplas $(z_1, z_2, \ldots, z_m)$ formadas pela sele√ß√£o **sem reposi√ß√£o** de $m$ elementos de um conjunto de $M \geq m$ objetos √© chamada de **arranjo** de $M$ elementos tomados $m$ a $m$ e √© dada por
$$A_{m}^M = M (M-1) \cdots (M-(m-1)) = \frac{M (M-1) \cdots (M-(m-1))\color{red}{(M-m)!}}{\color{red}{(M-m)!}} = \frac{M!}{(M-m)!}.$$
:::

:::{.callout-note}
## Defini√ß√£o - Arranjo Com Reposi√ß√£o

Se as $m$-tuplas $(z_1, z_2, \ldots, z_m)$ forem formadas por sele√ß√£o **sem reposi√ß√£o**, ent√£o o arranjo √© dado por
$$A_{m}^M = M M \cdots M = M^m.$$
:::

## 2.3 T√©cnicas de Contagem {.unnumbered .unlisted}

:::{.callout-note}
## Defini√ß√£o - Permuta√ß√£o

A quantidade de $M$-tuplas $(z_1, z_2, \ldots, z_m)$ formadas pela sele√ß√£o **sem reposi√ß√£o** de todos $M$ elementos √© chamada de **permuta√ß√£o** e √© dada por
$$P_M = A_M^M = M!.$$
:::

::: {.callout-caution}
## Observa√ß√µes

1.    Em todas formas de arranjo, a ordem em que os itens s√£o selecionados importa;
2.    A permuta√ß√£o pode ser entendida como a quantidade de maneiras que podemos "**embaralhar**" os $M$ itens do conjunto, em vez de selecionarmos uma parcela dos mesmos.
:::

## 2.3 T√©cnicas de Contagem {.unnumbered .unlisted .smaller}

Em um arranjo, a ordem de sele√ß√£o dos itens importa. Se necessitarmos contar $m$-tuplas $(z_1, z_2, \ldots, z_m)$, em que a ordem de sele√ß√£o n√£o importa, devemos de descontar as $m$-tuplas formadas por mero "embaralhamento" de uma $m$-tupla original.

::: {.fragment style="border-style: solid; border-width: 3px; padding-right: 12px; padding-left: 12px;"}

**Exemplo:** Se a ordem n√£o importa, ent√£o a $3$-tupla $(1,2,3)$ √© equivalente a: $(1,3,2)$; $(2,1,3)$; $(2,3,1)$; $(3,1,2)$; e $(3,2,1)$. As seis $3$-tuplas s√£o resultado do "embaralhamento" de uma delas. No arranjo, todas as $3$-tuplas equivalentes aparecem "embaralhadas" seis vezes.

:::

::: fragment

A **combina√ß√£o** √© usada para descontar essas repeti√ß√µes.

:::

::: fragment

:::{.callout-note}
## Defini√ß√£o - Combina√ß√£o

A quantidade de $m$-tuplas $(z_1, z_2, \ldots, z_m)$ formadas pela sele√ß√£o **sem reposi√ß√£o** de $m$ elementos de um conjunto de $M \geq m$ objetos quando a ordem de sele√ß√£o n√£o importa √© chamada de **combina√ß√£o** de $M$ elementos tomados $m$ a $m$ e √© dada por
$$C_m^M = {M \choose m} = \frac{A_m^M}{m!} = \frac{M!}{m!(M-m)!}.$$
:::

:::

## {.unnumbered .unlisted .smaller}

### Exemplo {.unnumbered .unlisted}

Um armaz√©m tem 25 impressoras, das quais 10 s√£o a laser e 15 s√£o a jato de tinta. Se 6 das 25 forem selecionadas aleatoriamente, qual ser√° a probabilidade de exatamente 3 sejam a laser?

::: fragment

Seja $A$ o evento acima. Note que 

:::

::: incremental

-   H√° $N = {25 \choose 6}$ formas de escolher as $6$ impressoras das $25$;
-   H√° $N_1 = {10 \choose 3}$ formas de escolher as $3$ impressoras das $10$ a laser; e
-   H√° $N_2 = {15 \choose 3}$ formas de escolher as $3$ impressoras das $15$ a jato de tinta.

:::

::: fragment

Assim, $N(A) = N_1 N_2 = {10 \choose 3}{15 \choose 3}$ e
$$P(A) = \frac{N(A)}{N} = \frac{ {10 \choose 3} {15 \choose 3} }{{25 \choose 6}} = 0\text{,}3083.$$

:::


# Probabilidade Condicional

## 3 Probabilidade Condicional {.unnumbered .unlisted}

<div style="font-size:75%">

A atribui√ß√£o de probabilidades √© realizada com base em informa√ß√µes que se tem e em suposi√ß√µes acerca do experimento.

</div>

::: {.fragment style="font-size:75%"}

Para um evento $A$, ap√≥s a especificar $P(A)$, informa√ß√µes adicionais relevantes para o experimento podem estar dispon√≠veis. Essas informa√ß√µes s√£o representadas como a ocorr√™ncia de um evento $B$.

:::

::: {.fragment style="font-size:75%"}

A informa√ß√£o de que $B$ ocorreu pode fazer com que revisemos $P(A)$.

:::

::: {.fragment style="font-size:75%; border-style: solid; border-width: 3px; padding-right: 12px; padding-left: 12px;"}

**Exemplo:** Seja $A =$ "Indiv√≠duo tem uma doen√ßa". Apenas pelos sintomas, um m√©dico pode atribuir um valor $P(A)$. Seja $B =$ "Resultado negativo de um exame". A informa√ß√£o [$B$ ocorreu]{style="color:red;"} deveria reduzir a probabilidade de $A$.

:::

::: fragment

::: {.callout-caution}
## Observa√ß√µes

1.    Usaremos a nota√ß√£o $P(A|B)$ para representar a probabilidade **condicional** de $A$ dada a ocorr√™ncia de $B$;
2.    Nesse contexto, dizemos que $P(A)$ √© a probabilidade **incondicional** ou **marginal**.
:::

:::

## 3 Probabilidade Condicional {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo:** Uma f√°brica tem duas linhas de montagem, uma nova ($B$) e uma antiga, que produzem componentes que podem ser defeituosos ($A$) ou n√£o. Em um dia, a f√°brica produziu produtos com a seguinte distribui√ß√£o:

::: columns

::: {.column #vcenter width="30%"}

<table style="margin-left:auto; margin-right:auto;">
  <tr style="border-top: 2px solid; border-bottom: 2px solid">
    <td style="text-align: center; vertical-align:middle; border-right: 2px solid" rowspan="2">**Linha de Montagem**</td> <td colspan="2">**Condi√ß√£o**</td>
  </tr>
  <tr style="border-top: 2px solid; border-bottom: 2px solid">
    <td style="text-align: center;"> $A$ </td> <td style="text-align: center;"> $A^c$ </td>
  </tr>
  <tr>
    <td style="border-right: 2px solid; text-align: center;"> $B$ </td> <td style="text-align: center;"> 1 </td> <td style="text-align: center;"> 9 </td>
  </tr>
  <tr style="border-bottom: 2px solid">
    <td style="text-align: center; border-right: 2px solid"> $B^c$ </td> <td style="text-align: center;"> 2 </td> <td style="text-align: center;"> 6 </td>
  </tr>
</table>

:::

::: {.column #vcenter width="3%"}

:::

::: {.column #vcenter width="67%"}

<div style="margin-left:0px">

Ao selecionar um dos componentes ao acaso, determine as probabilidades:

</div>

1.    $P(A); \phantom{ = \frac{N(A)}{N} = \frac{3}{18} = 0\text{,}1667}$
2.    $P(A|B). \phantom{ = \frac{N(A \cap B)}{N(B)} = \frac{1}{10} = 0\text{,}1}$

:::

:::

:::

## 3 Probabilidade Condicional {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo:** Uma f√°brica tem duas linhas de montagem, uma nova ($B$) e uma antiga, que produzem componentes que podem ser defeituosos ($A$) ou n√£o. Em um dia, a f√°brica produziu produtos com a seguinte distribui√ß√£o:

::: columns

::: {.column #vcenter width="30%"}

<table style="margin-left:auto; margin-right:auto;">
  <tr style="border-top: 2px solid; border-bottom: 2px solid">
    <td style="text-align: center; vertical-align:middle; border-right: 2px solid" rowspan="2">**Linha de Montagem**</td> <td colspan="2">**Condi√ß√£o**</td>
  </tr>
  <tr style="border-top: 2px solid; border-bottom: 2px solid">
    <td style="text-align: center;"> $A$ </td> <td style="text-align: center;"> $A^c$ </td>
  </tr>
  <tr>
    <td style="border-right: 2px solid; text-align: center;"> $B$ </td> <td style="text-align: center;"> 1 </td> <td style="text-align: center;"> 9 </td>
  </tr>
  <tr style="border-bottom: 2px solid">
    <td style="text-align: center; border-right: 2px solid"> $B^c$ </td> <td style="text-align: center;"> 2 </td> <td style="text-align: center;"> 6 </td>
  </tr>
</table>

:::

::: {.column #vcenter width="3%"}

:::

::: {.column #vcenter width="67%"}

<div style="margin-left:0px">

Ao selecionar um dos componentes ao acaso, determine as probabilidades:

</div>

1.    $P(A) = \frac{N(A)}{N} = \frac{3}{18} = 0\text{,}1667$
2.    $P(A|B). \phantom{ = \frac{N(A \cap B)}{N(B)} = \frac{1}{10} = 0\text{,}1}$

:::

:::

:::

## 3 Probabilidade Condicional {.unnumbered .unlisted}

::: {style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo:** Uma f√°brica tem duas linhas de montagem, uma nova ($B$) e uma antiga, que produzem componentes que podem ser defeituosos ($A$) ou n√£o. Em um dia, a f√°brica produziu produtos com a seguinte distribui√ß√£o:

::: columns

::: {.column #vcenter width="30%"}

<table style="margin-left:auto; margin-right:auto;">
  <tr style="border-top: 2px solid; border-bottom: 2px solid">
    <td style="text-align: center; vertical-align:middle; border-right: 2px solid" rowspan="2">**Linha de Montagem**</td> <td colspan="2">**Condi√ß√£o**</td>
  </tr>
  <tr style="border-top: 2px solid; border-bottom: 2px solid">
    <td style="text-align: center;"> $A$ </td> <td style="text-align: center;"> $A^c$ </td>
  </tr>
  <tr>
    <td style="border-right: 2px solid; text-align: center;"> $B$ </td> <td style="text-align: center;"> 1 </td> <td style="text-align: center;"> 9 </td>
  </tr>
  <tr style="border-bottom: 2px solid">
    <td style="text-align: center; border-right: 2px solid"> $B^c$ </td> <td style="text-align: center;"> 2 </td> <td style="text-align: center;"> 6 </td>
  </tr>
</table>

:::

::: {.column #vcenter width="3%"}

:::

::: {.column #vcenter width="67%"}

<div style="margin-left:0px">

Ao selecionar um dos componentes ao acaso, determine as probabilidades:

</div>

1.    $P(A) = \frac{N(A)}{N} = \frac{3}{18} = 0\text{,}1667$;
2.    $P(A|B) = \frac{N(A \cap B)}{N(B)} = \frac{1}{10} = 0\text{,}1$.

:::

:::

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

No exemplo acima, no Item 2, notamos que $P(A|B) = \frac{N(A \cap B)}{N(B)} = \frac{\frac{N(A \cap B)}{N}}{\frac{N(B)}{N}} = \frac{P(A \cap B)}{P(B)}$.

:::

:::

## 3 Probabilidade Condicional {.unnumbered .unlisted}

::: {.callout-note}
## Defini√ß√£o

Sejam $A,B\in\Omega$ eventos tais que $P(B) > 0$. Ent√£o, a probabilidade condicional de $A$ dada a ocorr√™ncia de $B$ √© definida por
$$P(A|B) = \frac{P(A \cap B)}{P(B)}.$$
:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

Se $P(B) = 0$, alguns autores definem $P(A|B) = 0$, outros definem $P(A|B) = P(A)$. De qualquer maneira, em situa√ß√µes pr√°ticas, n√£o √© muito √∫til atualizar a probabilidade de $A$ para a hip√≥tese de $B$ ocorrer, quando $P(B) = 0$.
:::

:::

## 3 Probabilidade Condicional {.unnumbered .unlisted}

<figure style="width:60%; margin-left:auto; margin-right:auto;">
  <img src="figs/diagrama_de_venn_prob_condicional_1.png">
</figure>

## 3 Probabilidade Condicional {.unnumbered .unlisted}

<figure style="width:60%; margin-left:auto; margin-right:auto;">
  <img src="figs/diagrama_de_venn_prob_condicional_2.png">
</figure>

## 3 Probabilidade Condicional {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedade - Regra do Produto

Sejam $A,B\in\Omega$ eventos tais que $P(A\cap B) > 0$. Ent√£o
$$P(A\cap B) = P(A|B)P(B).$$
:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo:** Um lote com 5 pe√ßas tem apenas uma defeituosa. As pe√ßas s√£o selecionadas sem reposi√ß√£o at√© encontrar a primeira defeituosa. Qual a probabilidade de se ter que selecionar mais de duas pe√ßas?

Sejam $A_j =$ "$j$-√©sima pe√ßa n√£o defeituosa", $j=1,2$. Desejamos encontrar $P(A_2 \cap A_1)$. Da regra do produto, temos:
$$P(A_2 \cap A_1) = P(A_2|A_1)P(A_1) = \frac{3}{4}\cdot\frac{4}{5} = \frac{3}{5} = 0\text{,}6.$$
:::

## 3 Probabilidade Condicional {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedade - Regra do Produto para $n$ Eventos

Sejam $A_1,A_2,\ldots, A_n\in\Omega$ eventos tais que $P(A_1 \cap \cdots \cap A_n) > 0$. Ent√£o
$$P(A_1 \cap \cdots \cap A_n) = P(A_n|A_1 \cap \cdots \cap A_{n-1}) P(A_{n-1}|A_1 \cap \cdots \cap A_{n-2}) \cdots P(A_2|A_1) P(A_1).$$
:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo:** Um lote com 5 pe√ßas tem apenas uma defeituosa. As pe√ßas s√£o selecionadas sem reposi√ß√£o at√© encontrar a primeira defeituosa. Qual a probabilidade de se ter que selecionar exatamente tr√™s pe√ßas?

Sejam $A_j =$ "$j$-√©sima pe√ßa n√£o defeituosa", $j=1,2,3$. Desejamos encontrar $P(A_3^c \cap A_2 \cap A_1)$. Da regra do produto para 3 eventos, temos:
$$P(A_3^c \cap A_2 \cap A_1) = P(A_3^c|A_1\cap A_2) P(A_2|A_1) P(A_1) = \frac{1}{3} \cdot \frac{3}{4} \cdot \frac{4}{5} = \frac{1}{5} = 0\text{,}2.$$
:::

## {.unnumbered .unlisted}

### Exemplo {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width="35%"}

::: {style="font-size:80%;"}

Experimento:

-   Uma loja vende tr√™s marcas de um produto $A_1, A_2, A_3$;
-   A garantia do produto pode ser utilizada nos primeiros seis meses (evento $B$);
-   A garantia tamb√©m pode ser utilizada entre 7 e 12 meses (evento $C$).

::: {.fragment fragment-index=1}

A regra do produto pode ser visualizada por meio de um diagrama de √°rvore.

:::

:::

:::

::: {.column #vcenter width="65%"}

::: {.fragment fragment-index=1}

![](figs/diagrama_de_arvore.png)

:::

:::

:::

## Teorema da Probabilidade Total

::: {style="font-size:90%;"}

Em alguns casos, o comportamento probabil√≠stico do fen√¥meno pode mudar em circunst√¢ncias diferentes, sendo que a probabilidade de um evento √© conhecida em cada uma das situa√ß√µes.

Nesses casos, pode ser de interesse obter a probabilidade "global" do evento.

:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo:** Uma industria possui 3 linhas de montagem (eventos $B_1$, $B_2$ e $B_3$), correspondendo a 50%, 40% e 10% da produ√ß√£o. Essas linhas geram, respectivamente, 5%, 10% e 20% de produtos defeituosos (evento $A$). Ao sortear aleatoriamente um produto dessa industria, qual a probabilidade dele ser defeituoso?

Nesse caso, temos que:

-   $P(A|B_1) = 0\text{,}05$, $P(A|B_2) = 0\text{,}1$ e $P(A|B_3) = 0\text{,}2$ (probabilidade de $A$ em cada linha de montagem);
-   $P(B_1) = 0\text{,}5$, $P(B_2) = 0\text{,}4$ e $P(B_3) = 0\text{,}1$ (probabilidade de cada linha de montagem).

√â poss√≠vel combinar $P(A|B_j)$ e $P(B_j)$, $j=1,2,3$, para obter a probabilidade incondicional $P(A)$.
:::

## 3.1 Teorema da Probabilidade Total {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedade - Teorema da Probabilidade Total

Sejam $A\in\Omega$ evento e $B_1, B_2, \ldots, B_n \in \Omega$ parti√ß√£o de $\Omega$, tais que $P(B_j) > 0$, $j = 1, 2, \ldots, n$. Ent√£o
$$P(A) = \sum_{j=1}^n P(A | B_j) P(B_j).$$
:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo:** Aplicando o Teorema da Probabilidade Total no exemplo anterior, obtemos
$$\textstyle P(A) = \sum_{j=1}^3 P(A | B_j) P(B_j) = 0\text{,}05 \cdot 0\text{,}5 + 0\text{,}1 \cdot 0\text{,}4 + 0\text{,}2 \cdot 0\text{,}1 = 0\text{,}085.$$

Isto √©, a industria produz globalmente 8,5% de pe√ßas defeituosas.
:::

## 3.1 Teorema da Probabilidade Total {.unnumbered .unlisted}


<figure style="width:55%; margin-left:auto; margin-right:auto;">
  <img src="figs/diagrama_de_venn_teor_prob_total.png">
  <figcaption>Ilustra√ß√£o para parti√ß√£o com 5 eventos.</figcaption>
</figure>


## Teorema de Bayes

Em algumas situa√ß√µes, √© de interesse inverter a ordem do condicionamento.

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo:** Uma institui√ß√£o classifica as opera√ß√µes como regular, com fraude moderada e com fraude grave (eventos $B_1$, $B_2$ e $B_3$) e usa um mecanismo que emite um alerta de fraude (evento $A$).

Normalmente, de [**dados hist√≥ricos**]{style="color:red;"}, conhecemos as probabilidades $P(A|B_j)$, de emitir alerta apara cada tipo de opera√ß√£o, e $P(B_j)$, de cada tipo de opera√ß√£o.

Costuma ser de interesse descobrirmos $P(B_j | A)$, de cada tipo de opera√ß√£o quando um alerta √© emitido.

:::

::: fragment

::: {.callout-caution}
## Observa√ß√£o

O Teorema de Bayes nos permite realizar a invers√£o da ordem de condicionamento requisitada pelo problema acima, isto √©, de $P(A|B_j)$, obter $P(B_j|A)$.
:::

:::

## 3.2 Teorema de Bayes {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedade - Teorema de Bayes

Sejam $A\in\Omega$ evento e $B_1, B_2, \ldots, B_n \in \Omega$ parti√ß√£o de $\Omega$, com $P(A)>0$ e $P(B_i) > 0$, $\forall i$. Ent√£o
$$P(B_k | A) = \frac{P(B_k \cap A)}{P(A)} = \frac{P(A | B_k)P(B_k)}{\sum_{j=1}^n P(A | B_j)P(B_j)}.$$
:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 12px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo:** Suponha que o mecanismo emite alerta com probabilidades: $0\text{,}3$ em opera√ß√µes regulares; $0\text{,}7$ na presen√ßa de fraudes moderadas; $0\text{,}9$ na presen√ßa de fraudes graves. De dados hist√≥ricos sabe-se que $0\text{,}85$, $0\text{,}1$ e $0\text{,}05$ das opera√ß√µes s√£o, respectivamente, regulares e com fraudes moderadas e graves. Logo,
$$\textstyle P(B_1 | A) = \frac{P(A | B_1)P(B_1)}{\sum_{j=1}^3P(A | B_j)P(B_j)} = \frac{0\text{,}3 \cdot 0\text{,}85}{0\text{,}3 \cdot 0\text{,}85 + 0\text{,}7 \cdot 0\text{,}1 + 0\text{,}9 \cdot 0\text{,}05} \approx 0\text{,}6892.$$

:::

## 3.2 Teorema de Bayes {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√µes

<ol>
  <li>Note que:</li>
  <ul>
    <li class=fragment>o mecanismo emite alerta em 30% das opera√ß√µes regulares, isto √©, $P(A|B_1) = 0\text{,}3$;</li>
    <li class=fragment>dos alertas emitidos, 68,92% s√£o opera√ß√µes regulares, isto √©, $P(B_1|A) = 0\text{,}6892$,</li>
  </ul>
  [isto √©, a mudan√ßa da ordem de condicionamento, muda a probabilidade;]{.fragment}
  <li class=fragment>Normalmente, $P(A|B_1)$ √© mais f√°cil de ser obtida de dados hist√≥ricos, mas para novas opera√ß√µes, o mais interessante √© conhecer $P(B_1|A)$;</li>
  <li class=fragment>√â ainda importante notar que $P(B_1^c|A) = 1-P(B_1|A) = 1-0\text{,}6892 = 0\text{,}3108$;</li>
  <li class=fragment>Em outras palavras, quando o mecanismo emite um alerta, a probabilidade de fraude √© de apenas $0\text{,}3108$.</li>
</ol>

:::

## Independ√™ncia

::: {.callout-caution}
## Observa√ß√£o

O valor de $P(A|B)$ representa a atualiza√ß√£o da probabilidade de $A$ ap√≥s assumindo que $B$ ocorreu. Se $P(A|B)$ √© diferente de $P(A)$, ent√£o a probabilidade de $A$ **depende** da ocorr√™ncia de $B$.
:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo:** Arremessamos dois dados e verificamos as faces voltadas pra cima. Sejam $A =$ "Soma das faces $=$ 6", $B =$ "1¬™ face √≠mpar" e $C =$ "2¬™ face √≠mpar". Note que $P(A) = \frac{1}{5}$ e $P(B) = P(C) = \frac{1}{2}$.

Agora:

::: incremental

-   $P(A|C) = \frac{P(A \cap C)}{P(C)} = \frac{3/36}{18/36} = \frac{1}{6} \neq P(A) = \frac{5}{36}$; e
-   $P(B|C) = \frac{P(B \cap C)}{P(C)} = \frac{9/36}{18/36} = \frac{1}{2} = P(B)$.

:::

::: fragment

Assim, $A$ depende de $C$ (probabilidade alterada pela ocorr√™ncia de $C$), mas $B$ n√£o depende de $C$.

:::

:::

## 3.3 Independ√™ncia {.unnumbered .unlisted}

::: {.callout-caution}
## Defini√ß√£o

Dizemos que dois eventos $A,B\in \Omega$ s√£o **independentes** se:

1.   $P(A|B) = P(A)$, se $P(B) > 0$; ou
2.   $P(B|A) = P(B)$, se $P(A) > 0$.
:::

::: {.callout-warning}
## Propriedade

Na defini√ß√£o anterior, (1) $\Leftrightarrow$ (2).
:::

::: {.callout-caution}
## Observa√ß√£o

Portanto, para verificar independ√™ncia, basta mostrar apenas uma das duas condi√ß√µes.
:::

## 3.3 Independ√™ncia {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedade

Dois eventos $A,B\in \Omega$ s√£o independentes se, e s√≥ se, $P(A \cap B) = P(A)P(B)$.
:::

::: {.callout-caution}
## Observa√ß√£o

Assim, de maneira alternativa √† defini√ß√£o, a independ√™ncia entre dois eventos $A,B\in\Omega$ pode ser mostrada verificando que $P(A \cap B) = P(A)P(B)$.
:::

::: {.callout-warning}
## Propriedade

Se $A,B\in \Omega$ s√£o independentes, ent√£o: $A$ e $B^c$ s√£o independentes; $A^c$ e $B$ s√£o independentes; e $A^c$ e $B^c$ s√£o independentes.

:::

## 3.3 Independ√™ncia {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

As defini√ß√µes de eventos disjuntos e independentes s√£o completamente distintas.
:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo:** Sejam $A,B\in\Omega$ eventos disjuntos, tais que $P(A) > 0$ e $P(B) > 0$. Ent√£o

$$P(A | B) = \frac{P(A \cap B)}{P(B)} = \frac{0}{P(B)} = 0 \neq P(A).$$
Isto √©, a ocorr√™ncia de $B$ exclui completamente a possibilidade da ocorr√™ncia de $A$, reduzindo a sua probabilidade a zero, n√£o importando a probabilidade inicial $P(A)$.
:::

## 3.3 Independ√™ncia {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Em alguns casos, a natureza de um experimento permite supor que dois eventos $A$ e $B$ podem ser considerados independentes. [Nesses casos, a **independ√™ncia** pode ser muito √∫til na modelagem probabil√≠stica do experimento.]{.fragment}

:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:70%;"}

**Exemplo:** Um mesmo algoritmo √© executado por computadores diferentes, sem comunica√ß√£o entre si. √â razo√°vel assumir que ambos operam [**independentemente**]{style="color:red;"}. Sejam $P(A_1) = 0\text{,}1$ e $P(A_2) = 0\text{,}2$, em que $A_j =$ "execu√ß√£o durar mais de 1 min no computador $j$", $j=1,2$. [A **independ√™ncia** fornece as probabilidades:]{class=fragment}

::: incremental
-   $P(A_1 \cap A_2) = P(A_1) P(A_2) = 0\text{,}1 \cdot 0\text{,}2 = 0\text{,}02$ (tempo maior que 1 min em ambos);
-   $P(A_1 \cap A_2^c) = P(A_1) P(A_2^c) = 0\text{,}1 \cdot 0\text{,}8 = 0\text{,}08$ (tempo maior que 1 min apenas no computador 1);
-   $P(A_1^c \cap A_2) = P(A_1^c) P(A_2) = 0\text{,}9 \cdot 0\text{,}2 = 0\text{,}18$ (tempo maior que 1 min apenas no computador 2);
-   $P(A_1^c \cap A_2^c) = P(A_1^c) P(A_2^c) = 0\text{,}9 \cdot 0\text{,}8 = 0\text{,}72$ (tempo menor ou igual a 1 min em ambos).

:::

:::

## 3.3 Independ√™ncia {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

A no√ß√£o de independ√™ncia entre dois eventos pode ser extendida para cole√ß√µes de mais de dois eventos.

:::

::: {.callout-note}
## Defini√ß√£o

Dizemos que os eventos $A_1, A_2, \ldots, A_n \in \Omega$ s√£o **mutuamente independentes** se 

::: incremental

-   $P(A_{i} \cap A_{j}) = P(A_{i})P(A_{j})$, $i \neq j$;
-   $P(A_{i} \cap A_{j} \cap A_{l}) = P(A_{i})P(A_{j})P(A_{l})$, $i \neq j \neq l$;
-   $P(A_{i} \cap A_{j} \cap A_{l} \cap A_{m}) = P(A_{i})P(A_{j})P(A_{l})P(A_{m})$, $i \neq j \neq l \neq m$;
-   $\vdots$
-   $P(\bigcap_{i = 1}^n A_{i}) = P(A_1\cap A_2 \cap \cdots \cap A_n) = \prod_{i=1}^nP(A_{i}) = P(A_1)P(A_2)\cdots P(A_n)$.

:::

:::

## 3.3 Independ√™ncia {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

Assim, $A_1, A_2, \ldots, A_n$ s√£o mutuamente independentes se a probabilidade da interse√ß√£o de qualquer sobcole√ß√£o deles fatora no produto das probabilidades marginais.

:::

::: {.fragment style="border-style: solid; border-width: 3px; padding-bottom: 0px; padding-right: 12px; padding-left: 12px; font-size:65%;"}

**Exemplo:** Um dado √© arremessado at√© que se obtenha face 6. Qual a probabilidade do evento $A_n =$ "serem necess√°rios $n$ arremessos". [Seja $B_j =$ "face 6 no arremesso $j$". Ent√£o
$$A_n = B_1^c \cap B_2^c \cap \cdots \cap B_{n-1}^c \cap B_n.$$]{.fragment}
[Pela natureza do experimento, parece razo√°vel assumir que os eventos $B_1, B_2, \ldots, B_n$ (e seus complementares) s√£o **mutuamente independentes**.]{.fragment} [Logo
$$\textstyle P(A_n) = P(B_1^c \cap B_2^c \cap \cdots \cap B_{n-1}^c \cap B_n) = P(B_1^c)P(B_2^c)\cdots P(B_{n-1}^c)P(B_n) = \left(\frac{5}{6}\right)^{n-1}\frac{1}{6}.$$]{.fragment}

:::

## {.unnumbered .unlisted}

### Exemplo {.unnumbered .unlisted}

::: columns

::: {.column #vcenter width=42%}

Um sistema com seis componentes **independentes** admite as duas configura√ß√µes poss√≠veis ao lado.

:::

::: {.column #vcenter width=58%}
<figure style="width:95%; margin-left:auto; margin-right:auto;">
  <img src="figs/exemplo_independencia.png">
</figure>

:::

:::

::: fragment

Sendo $F_j =$ "falha em $C_j$", $j=1, \ldots, 6$, o sistema funciona se:

::: incremental

-   $(F_1^c \cap F_2^c) \cup (F_3^c \cap F_4^c) \cup (F_5^c \cap F_6^c)$ na configura√ß√£o 1;
-   $((F_1^c \cap F_2^c \cap F_5^c) \cup (F_3^c \cap F_4^c \cap F_5^c)) \cup F_6^c$ na configura√ß√£o 2.

:::

:::

## {.unnumbered .unlisted}

### Exemplo {.unnumbered .unlisted}

Agora, sendo $A =$ "Sistema funciona" e supondo $P(F_j) = 1-p$, $j = 1, \ldots, 6$. Pela suposi√ß√£o de independ√™ncia, temos que:

```{r}
p <- 0.9
p_A1 <- 3*p^2 - 3*p^4 + p^6
```

::: fragment

-   Na configura√ß√£o 1:
$$\begin{align*}
P(A) &= P(F_1^c \cap F_2^c) + P(F_3^c \cap F_4^c) + P(F_5^c \cap F_6^c)\\
&- P(F_1^c \cap F_2^c \cap F_3^c \cap F_4^c) - P(F_1^c \cap F_2^c \cap F_5^c \cap F_6^c)\\
&- P(F_3^c \cap F_4^c \cap F_5^c \cap F_6^c) + P(F_1^c \cap F_2^c \cap F_3^c \cap F_4^c \cap F_5^c \cap F_6^c)\\
&= 3p^2 - 3p^4 + p^6.
\end{align*}$$
[Se, por exemplo, a probabilidade de falha individual for $P(F_j) = 0\text{,}1$, ent√£o $p=0\text{,}9$ e $P(A) =$ `r gsub('\\.', ',', as.character(round(p_A1, 4)))`.]{.fragment}

:::

## {.unnumbered .unlisted}

### Exemplo {.unnumbered .unlisted}

Agora, sendo $A =$ "Sistema funciona" e supondo $P(F_j) = 1-p$, $j = 1, \ldots, 6$. Pela suposi√ß√£o de independ√™ncia, temos que:

```{r}
p <- 0.9
p_A2 <- 2*p^3 + p - p^5 - 2*p^4 + p^6
```

::: fragment

-   Na configura√ß√£o 2:
$$\begin{align*}
P(A) &= P(F_1^c \cap F_2^c \cap F_5^c) + P(F_3^c \cap F_4^c \cap F_5^c) + P(F_6^c)\\
&- P(F_1^c \cap F_2^c \cap F_3^c \cap F_4^c \cap F_5^c) - P(F_1^c \cap F_2^c \cap F_5^c \cap F_6^c)\\
&- P(F_3^c \cap F_4^c \cap F_5^c \cap F_6^c) + P(F_1^c \cap F_2^c \cap F_3^c \cap F_4^c \cap F_5^c \cap F_6^c)\\
&= 2p^3 + p - p^5 - 2p^4 + p^6.
\end{align*}$$
[Se, por exemplo, a probabilidade de falha individual for $P(F_j) = 0\text{,}1$, ent√£o $p=0\text{,}9$ e $P(A) =$ `r gsub('\\.', ',', as.character(round(p_A2, 4)))`.]{.fragment}

:::

## 3.3 Independ√™ncia {.unnumbered .unlisted}

::: {.callout-caution}
## Observa√ß√£o

No exerc√≠cio anterior, utilizamos a propriedade que
$$
P(A \cup B \cup C) = P(A) + P(B) + P(C) - P(A \cap B) - P(A \cap C) - P(B \cap C) + P(A \cap B \cap C).
$$
:::

::: {.callout-warning}
## Propriedades

Para uni√£o de 4 eventos, $A, B, C, D$, ter√≠amos
$$
\begin{align*}
P(A \cup B \cup C \cup D) &= P(A) + P(B) + P(C) + P(D)\\
&- P(A \cap B) - P(A \cap C) - P(A \cap D) - P(B \cap C) - P(B \cap D) - P(C \cap D)\\
&+ P(A \cap B \cap C) + P(A \cap B \cap D) + P(A \cap C \cap D) + P(B \cap C \cap D)\\
&- P(A \cap B \cap C \cap D).
\end{align*}
$$
:::

## 3.3 Independ√™ncia {.unnumbered .unlisted}

::: {.callout-warning}
## Propriedades

No geral, para uni√£o de $n$ eventos, $A_1, A_2, \ldots, A_n$, ter√≠amos
$$
\begin{align*}
\textstyle P(\bigcup_{i=1}^n A_i) &= \textstyle \sum_{i_1} P(A_{i_1}) &  \text{(soma as marginais)}\\
&\textstyle - \sum_{i_1}\sum_{i_2} P(A_{i_1} \cap A_{i_2}) &  \text{(subtrai as interse√ß√µes duplas)}\\
&\textstyle+ \sum_{i_1}\sum_{i_2}\sum_{i_3} P(A_{i_1} \cap A_{i_2} \cap A_{i_3}) &  \text{(soma as interse√ß√µes triplas)}\\
&\textstyle- \sum_{i_1}\sum_{i_2}\sum_{i_3}\sum_{i_4} P(A_{i_1} \cap A_{i_2} \cap A_{i_3} \cap A_{i_4}) &  \text{(subtrai as interse√ß√µes quadruplas)}\\
&\vdots & \\
&\textstyle(-1)^{k+1} \sum_{i_1}\cdots \sum_{i_k} P(A_{i_1} \cap \cdots \cap A_{i_k}) & \vdots \\
&\vdots & \\
&\textstyle(-1)^{n+1} P(A_{1} \cap \cdots \cap A_{n}). & \\
\end{align*}
$$
:::

# FIM {.unnumbered .unlisted}
